# Human-in-the-loop

!!! tip "This guide uses the new `interrupt` function."

    LangGraph 0.2.57ë¶€í„°ëŠ” **human-in-the-loop** íŒ¨í„´ì„ ë‹¨ìˆœí™”í•˜ë¯€ë¡œ [`interrupt` í•¨ìˆ˜][langgraph.types.interrupt]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¤‘ë‹¨ì (breakpoint)ì„ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

    ì •ì  ì¤‘ë‹¨ì (static breakpoint)ê³¼ `NodeInterrupt` ì˜ˆì™¸ì— ì˜ì¡´í–ˆë˜ ì´ì „ ë²„ì „ì˜ ì»¨ì…‰ ê°€ì´ë“œ(conceptual guide)ëŠ” [ì—¬ê¸°](v0-human-in-the-loop.md)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**Human-in-the-loop** (ë˜ëŠ” "on-the-loop") ì›Œí¬í”Œë¡œëŠ” ìë™í™”ëœ í”„ë¡œì„¸ìŠ¤ì— ì‚¬ëŒì˜ ì…ë ¥ì„ í†µí•©í•˜ì—¬ ì£¼ìš” ë‹¨ê³„ì—ì„œ ì˜ì‚¬ ê²°ì •, ìœ íš¨ì„± ê²€ì‚¬ ë˜ëŠ” ìˆ˜ì •ì´ ê°€ëŠ¥í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ëŠ” ê¸°ë³¸ ëª¨ë¸ì´ ê°€ë” ë¶€ì •í™•í•œ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” **LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜**ì—ì„œ íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤. ê·œì • ì¤€ìˆ˜, ì˜ì‚¬ ê²°ì • ë˜ëŠ” ì½˜í…ì¸  ìƒì„±ê³¼ ê°™ì´ ì˜¤ë¥˜ í—ˆìš© ë²”ìœ„ê°€ ë‚®ì€ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ëŒì˜ ì°¸ì—¬ëŠ” ëª¨ë¸ ì¶œë ¥ì˜ ê²€í† , ìˆ˜ì • ë˜ëŠ” ì¬ì •ì˜ë¥¼ í†µí•´ ì‹ ë¢°ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

## Use cases (ì‚¬ìš© ì‚¬ë¡€)

LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ **human-in-the-loop** ì›Œí¬í”Œë¡œì˜ ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

[**ğŸ› ï¸ Reviewing tool calls (ë„êµ¬ í˜¸ì¶œ ê²€í† )**](#review-tool-calls-ë„êµ¬-í˜¸ì¶œ-ê²€í† )
2. **âœ… Validating LLM outputs (LLM ì¶œë ¥ ìœ íš¨ì„± ê²€ì‚¬)**: LLMì´ ìƒì„±í•œ ì½˜í…ì¸ ë¥¼ ê²€í† , í¸ì§‘ ë˜ëŠ” ìŠ¹ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **ğŸ’¡ Providing context (ì»¨í…ìŠ¤íŠ¸ ì œê³µ)**: LLMì´ ëª…í™•ì„± ë˜ëŠ” ì¶”ê°€ ì„¸ë¶€ ì •ë³´ë¥¼ ìœ„í•´ ì‚¬ëŒì˜ ì…ë ¥ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•˜ê±°ë‚˜ ë‹¤ì¤‘ í„´ ëŒ€í™”(multi-turn conversation)ë¥¼ ì§€ì›í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

## `interrupt`

LangGraphì˜ [`interrupt` í•¨ìˆ˜][langgraph.types.interrupt]ëŠ” íŠ¹ì • ë…¸ë“œì—ì„œ ê·¸ë˜í”„ë¥¼ ì¼ì‹œ ì¤‘ì§€í•˜ê³ , ì‚¬ëŒì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ì‚¬ëŒì˜ ì…ë ¥ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ì¬ê°œí•˜ì—¬ human-in-the-loop ì›Œí¬í”Œë¡œë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ìŠ¹ì¸, í¸ì§‘ ë˜ëŠ” ì¶”ê°€ ì…ë ¥ ìˆ˜ì§‘ê³¼ ê°™ì€ ì‘ì—…ì— ìœ ìš©í•©ë‹ˆë‹¤. [`interrupt` í•¨ìˆ˜][langgraph.types.interrupt]ëŠ” ì‚¬ëŒì´ ì œê³µí•œ ê°’ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ì¬ê°œí•˜ê¸° ìœ„í•´ [`Command`](../reference/types.md#langgraph.types.Command) ê°ì²´ì™€ í•¨ê»˜ ì‚¬ìš©ë©ë‹ˆë‹¤.

```python
from langgraph.types import interrupt

def human_node(state: State):
    value = interrupt(
        # Any JSON serializable value to surface to the human.
        # For example, a question or a piece of text or a set of keys in the state
       {
          "text_to_revise": state["some_text"]
       }
    )
    # Update the state with the human's input or route the graph based on the input.
    return {
        "some_text": value
    }

graph = graph_builder.compile(
    checkpointer=checkpointer # Required for `interrupt` to work
)

# Run the graph until the interrupt
thread_config = {"configurable": {"thread_id": "some_id"}}
graph.invoke(some_input, config=thread_config)
    
# Resume the graph with the human's input
graph.invoke(Command(resume=value_from_human), config=thread_config)
```

```pycon
{'some_text': 'Edited text'}
```

!!! warning
      Interrupts are both powerful and ergonomic. However, while they may resemble Python's input() function in terms of developer experience, it's important to note that they do not automatically resume execution from the interruption point. Instead, they rerun the entire node where the interrupt was used.
[resuming from an interrupt](#how-does-resuming-from-an-interrupt-work-interruptì—ì„œ-ì¬ê°œí•˜ëŠ”-ë°©ë²•)

??? "Full Code"

      Here's a full example of how to use `interrupt` in a graph, if you'd like
      to see the code in action.

      ```python
      from typing import TypedDict
      import uuid

      from langgraph.checkpoint.memory import MemorySaver
      from langgraph.constants import START
      from langgraph.graph import StateGraph
      from langgraph.types import interrupt, Command

      class State(TypedDict):
         """The graph state."""
         some_text: str

      def human_node(state: State):
         value = interrupt(
            # Any JSON serializable value to surface to the human.
            # For example, a question or a piece of text or a set of keys in the state
            {
               "text_to_revise": state["some_text"]
            }
         )
         return {
            # Update the state with the human's input
            "some_text": value
         }


      # Build the graph
      graph_builder = StateGraph(State)
      # Add the human-node to the graph
      graph_builder.add_node("human_node", human_node)
      graph_builder.add_edge(START, "human_node")

      # A checkpointer is required for `interrupt` to work.
      checkpointer = MemorySaver()
      graph = graph_builder.compile(
         checkpointer=checkpointer
      )

      # Pass a thread ID to the graph to run it.
      thread_config = {"configurable": {"thread_id": uuid.uuid4()}}

      # Using stream() to directly surface the `__interrupt__` information.
      for chunk in graph.stream({"some_text": "Original text"}, config=thread_config):
         print(chunk)

      # Resume using Command
      for chunk in graph.stream(Command(resume="Edited text"), config=thread_config):
         print(chunk)
      ```

      ```pycon
      {'__interrupt__': (
            Interrupt(
               value={'question': 'Please revise the text', 'some_text': 'Original text'}, 
               resumable=True, 
               ns=['human_node:10fe492f-3688-c8c6-0d0a-ec61a43fecd6'], 
               when='during'
            ),
         )
      }
      {'human_node': {'some_text': 'Edited text'}}
      ```

## Requirements (ìš”êµ¬ ì‚¬í•­)

ê·¸ë˜í”„ì—ì„œ `interrupt`ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤.

1. ê° ë‹¨ê³„ í›„ì— ê·¸ë˜í”„ ìƒíƒœë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ [**Specify a checkpointer (ì²´í¬í¬ì¸í„° ì§€ì •)**](persistence.md#checkpoints)í•©ë‹ˆë‹¤.
[Design Patterns (ë””ìì¸ íŒ¨í„´)](#design-patterns-ë””ìì¸-íŒ¨í„´)
3. `interrupt`ê°€ ë°œìƒí•  ë•Œê¹Œì§€ [**thread ID (ìŠ¤ë ˆë“œ ID)**](./persistence.md#threads)ë¡œ **Run the graph (ê·¸ë˜í”„ ì‹¤í–‰)**í•©ë‹ˆë‹¤.
[**The `Command` primitive (`Command` ê¸°ë³¸ ìš”ì†Œ)**](#the-command-primitive-command-ê¸°ë³¸-ìš”ì†Œ)

## Design Patterns (ë””ìì¸ íŒ¨í„´)

ì¼ë°˜ì ìœ¼ë¡œ human-in-the-loop ì›Œí¬í”Œë¡œë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì„¸ ê°€ì§€ ë‹¤ë¥¸ **actions (ì‘ì—…)**ì´ ìˆìŠµë‹ˆë‹¤.

1. **Approve or Reject (ìŠ¹ì¸ ë˜ëŠ” ê±°ë¶€)**: API í˜¸ì¶œê³¼ ê°™ì€ ì¤‘ìš”í•œ ë‹¨ê³„ ì „ì— ê·¸ë˜í”„ë¥¼ ì¼ì‹œ ì¤‘ì§€í•˜ì—¬ ì‘ì—…ì„ ê²€í† í•˜ê³  ìŠ¹ì¸í•©ë‹ˆë‹¤. ì‘ì—…ì´ ê±°ë¶€ë˜ë©´ ê·¸ë˜í”„ê°€ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì§€ ëª»í•˜ë„ë¡ í•˜ê³  ì ì¬ì ìœ¼ë¡œ ëŒ€ì²´ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ íŒ¨í„´ì€ ì¢…ì¢… ì‚¬ëŒì˜ ì…ë ¥ì— ë”°ë¼ ê·¸ë˜í”„ë¥¼ **routing (ë¼ìš°íŒ…)**í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤.
2. **Edit Graph State (ê·¸ë˜í”„ ìƒíƒœ í¸ì§‘)**: ê·¸ë˜í”„ë¥¼ ì¼ì‹œ ì¤‘ì§€í•˜ì—¬ ê·¸ë˜í”„ ìƒíƒœë¥¼ ê²€í† í•˜ê³  í¸ì§‘í•©ë‹ˆë‹¤. ì´ëŠ” ì‹¤ìˆ˜ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€ ì •ë³´ë¡œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. ì´ íŒ¨í„´ì€ ì¢…ì¢… ì‚¬ëŒì˜ ì…ë ¥ìœ¼ë¡œ ìƒíƒœë¥¼ **updating (ì—…ë°ì´íŠ¸)**í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤.
3. **Get Input (ì…ë ¥ ë°›ê¸°)**: ê·¸ë˜í”„ì˜ íŠ¹ì • ë‹¨ê³„ì—ì„œ ì‚¬ëŒì˜ ì…ë ¥ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•©ë‹ˆë‹¤. ì´ëŠ” ì—ì´ì „íŠ¸ì˜ ì˜ì‚¬ ê²°ì • í”„ë¡œì„¸ìŠ¤ì— ì •ë³´ë¥¼ ì œê³µí•˜ê±°ë‚˜ **multi-turn conversations (ë‹¤ì¤‘ í„´ ëŒ€í™”)**ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ì¶”ê°€ ì •ë³´ ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.

ì•„ë˜ì—ì„œëŠ” ì´ëŸ¬í•œ **actions (ì‘ì—…)**ì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë””ìì¸ íŒ¨í„´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

### Approve or Reject (ìŠ¹ì¸ ë˜ëŠ” ê±°ë¶€)

<figure markdown="1">
![image](img/human_in_the_loop/approve-or-reject.png){: style="max-height:400px"}
<figcaption>Depending on the human's approval or rejection, the graph can proceed with the action or take an alternative path.</figcaption>
</figure>

API í˜¸ì¶œê³¼ ê°™ì€ ì¤‘ìš”í•œ ë‹¨ê³„ ì „ì— ê·¸ë˜í”„ë¥¼ ì¼ì‹œ ì¤‘ì§€í•˜ì—¬ ì‘ì—…ì„ ê²€í† í•˜ê³  ìŠ¹ì¸í•©ë‹ˆë‹¤. ì‘ì—…ì´ ê±°ë¶€ë˜ë©´ ê·¸ë˜í”„ê°€ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì§€ ëª»í•˜ë„ë¡ í•˜ê³  ì ì¬ì ìœ¼ë¡œ ëŒ€ì²´ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python

from typing import Literal
from langgraph.types import interrupt, Command

def human_approval(state: State) -> Command[Literal["some_node", "another_node"]]:
    is_approved = interrupt(
        {
            "question": "Is this correct?",
            # Surface the output that should be
            # reviewed and approved by the human.
            "llm_output": state["llm_output"]
        }
    )

    if is_approved:
        return Command(goto="some_node")
    else:
        return Command(goto="another_node")

# Add the node to the graph in an appropriate location
# and connect it to the relevant nodes.
graph_builder.add_node("human_approval", human_approval)
graph = graph_builder.compile(checkpointer=checkpointer)

# After running the graph and hitting the interrupt, the graph will pause.
# Resume it with either an approval or rejection.
thread_config = {"configurable": {"thread_id": "some_id"}}
graph.invoke(Command(resume=True), config=thread_config)
```

ìì„¸í•œ ì˜ˆì œëŠ” [how to review tool calls (ë„êµ¬ í˜¸ì¶œ ê²€í†  ë°©ë²•)](../how-tos/human_in_the_loop/review-tool-calls.ipynb)ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

### Review & Edit State (ìƒíƒœ ê²€í†  ë° í¸ì§‘)

<figure markdown="1">
![image](img/human_in_the_loop/edit-graph-state-simple.png){: style="max-height:400px"}
<figcaption>A human can review and edit the state of the graph. This is useful for correcting mistakes or updating the state with additional information.
</figcaption>
</figure>

```python
from langgraph.types import interrupt

def human_editing(state: State):
    ...
    result = interrupt(
        # Interrupt information to surface to the client.
        # Can be any JSON serializable value.
        {
            "task": "Review the output from the LLM and make any necessary edits.",
            "llm_generated_summary": state["llm_generated_summary"]
        }
    )

    # Update the state with the edited text
    return {
        "llm_generated_summary": result["edited_text"] 
    }

# Add the node to the graph in an appropriate location
# and connect it to the relevant nodes.
graph_builder.add_node("human_editing", human_editing)
graph = graph_builder.compile(checkpointer=checkpointer)

...

# After running the graph and hitting the interrupt, the graph will pause.
# Resume it with the edited text.
thread_config = {"configurable": {"thread_id": "some_id"}}
graph.invoke(
    Command(resume={"edited_text": "The edited text"}), 
    config=thread_config
)
```

ìì„¸í•œ ì˜ˆì œëŠ” [How to wait for user input using interrupt (interruptë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦¬ëŠ” ë°©ë²•)](../how-tos/human_in_the_loop/wait-user-input.ipynb)ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

### Review Tool Calls (ë„êµ¬ í˜¸ì¶œ ê²€í† )

<figure markdown="1">
![image](img/human_in_the_loop/tool-call-review.png){: style="max-height:400px"}
<figcaption>A human can review and edit the output from the LLM before proceeding. This is particularly
critical in applications where the tool calls requested by the LLM may be sensitive or require human oversight.
</figcaption>
</figure>

```python
def human_review_node(state) -> Command[Literal["call_llm", "run_tool"]]:
    # This is the value we'll be providing via Command(resume=<human_review>)
    human_review = interrupt(
        {
            "question": "Is this correct?",
            # Surface tool calls for review
            "tool_call": tool_call
        }
    )

    review_action, review_data = human_review

    # Approve the tool call and continue
    if review_action == "continue":
        return Command(goto="run_tool")

    # Modify the tool call manually and then continue
    elif review_action == "update":
        ...
        updated_msg = get_updated_msg(review_data)
        # Remember that to modify an existing message you will need
        # to pass the message with a matching ID.
        return Command(goto="run_tool", update={"messages": [updated_message]})

    # Give natural language feedback, and then pass that back to the agent
    elif review_action == "feedback":
        ...
        feedback_msg = get_feedback_msg(review_data)
        return Command(goto="call_llm", update={"messages": [feedback_msg]})
```

ìì„¸í•œ ì˜ˆì œëŠ” [how to review tool calls (ë„êµ¬ í˜¸ì¶œ ê²€í†  ë°©ë²•)](../how-tos/human_in_the_loop/review-tool-calls.ipynb)ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

### Multi-turn conversation (ë‹¤ì¤‘ í„´ ëŒ€í™”)

<figure markdown="1">
![image](img/human_in_the_loop/multi-turn-conversation.png){: style="max-height:400px"}
<figcaption>A <strong>multi-turn conversation</strong> architecture where an <strong>agent</strong> and <strong>human node</strong> cycle back and forth until the agent decides to hand off the conversation to another agent or another part of the system.
</figcaption>
</figure>

**Multi-turn conversation (ë‹¤ì¤‘ í„´ ëŒ€í™”)**ì€ ì—ì´ì „íŠ¸ì™€ ì‚¬ëŒ ê°„ì˜ ì—¬ëŸ¬ ë²ˆì˜ ìƒí˜¸ ì‘ìš©ì„ í¬í•¨í•˜ë©°, ì´ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ëŠ” ëŒ€í™” ë°©ì‹ìœ¼ë¡œ ì‚¬ëŒìœ¼ë¡œë¶€í„° ì¶”ê°€ ì •ë³´ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ë””ìì¸ íŒ¨í„´ì€ [multiple agents (ë‹¤ì¤‘ ì—ì´ì „íŠ¸)](./multi_agent.md)ë¡œ êµ¬ì„±ëœ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤. í•˜ë‚˜ ì´ìƒì˜ ì—ì´ì „íŠ¸ê°€ ì‚¬ëŒê³¼ ë‹¤ì¤‘ í„´ ëŒ€í™”ë¥¼ ìˆ˜í–‰í•´ì•¼ í•  ìˆ˜ ìˆìœ¼ë©°, ì—¬ê¸°ì„œ ì‚¬ëŒì€ ëŒ€í™”ì˜ ì—¬ëŸ¬ ë‹¨ê³„ì—ì„œ ì…ë ¥ ë˜ëŠ” í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¨ìˆœì„±ì„ ìœ„í•´ ì•„ë˜ ì—ì´ì „íŠ¸ êµ¬í˜„ì€ ë‹¨ì¼ ë…¸ë“œë¡œ ì„¤ëª…ë˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì—¬ëŸ¬ ë…¸ë“œë¡œ êµ¬ì„±ëœ ë” í° ê·¸ë˜í”„ì˜ ì¼ë¶€ì¼ ìˆ˜ ìˆìœ¼ë©° ì¡°ê±´ë¶€ ì—ì§€ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

=== "Using a human node per agent (ì—ì´ì „íŠ¸ë‹¹ íœ´ë¨¼ ë…¸ë“œ ì‚¬ìš©)"

    ì´ íŒ¨í„´ì—ì„œëŠ” ê° ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©ì ì…ë ¥ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ìì²´ íœ´ë¨¼ ë…¸ë“œë¥¼ ê°–ìŠµë‹ˆë‹¤.
    ì´ëŠ” íœ´ë¨¼ ë…¸ë“œì— ê³ ìœ í•œ ì´ë¦„("ì—ì´ì „íŠ¸ 1ìš© íœ´ë¨¼", "ì—ì´ì „íŠ¸ 2ìš© íœ´ë¨¼" ë“±)ì„ ì§€ì •í•˜ê±°ë‚˜
    ì„œë¸Œ ê·¸ë˜í”„ê°€ íœ´ë¨¼ ë…¸ë“œì™€ ì—ì´ì „íŠ¸ ë…¸ë“œë¥¼ í¬í•¨í•˜ëŠ” ì„œë¸Œ ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ```python
    from langgraph.types import interrupt

    def human_input(state: State):
        human_message = interrupt("human_input")
        return {
            "messages": [
                {
                    "role": "human",
                    "content": human_message
                }
            ]
        }

    def agent(state: State):
        # Agent logic
        ...

    graph_builder.add_node("human_input", human_input)
    graph_builder.add_edge("human_input", "agent")
    graph = graph_builder.compile(checkpointer=checkpointer)

    # After running the graph and hitting the interrupt, the graph will pause.
    # Resume it with the human's input.
    graph.invoke(
        Command(resume="hello!"),
        config=thread_config
    )
    ```


=== "Sharing human node across multiple agents (ì—¬ëŸ¬ ì—ì´ì „íŠ¸ì—ì„œ íœ´ë¨¼ ë…¸ë“œ ê³µìœ )"

    ì´ íŒ¨í„´ì—ì„œëŠ” ë‹¨ì¼ íœ´ë¨¼ ë…¸ë“œê°€ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ì— ëŒ€í•œ ì‚¬ìš©ì ì…ë ¥ì„ ìˆ˜ì§‘í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. í™œì„± ì—ì´ì „íŠ¸ëŠ” ìƒíƒœì—ì„œ ê²°ì •ë˜ë¯€ë¡œ ì‚¬ìš©ì ì…ë ¥ì´ ìˆ˜ì§‘ëœ í›„ ê·¸ë˜í”„ëŠ” ì˜¬ë°”ë¥¸ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ```python
    from langgraph.types import interrupt

    def human_node(state: MessagesState) -> Command[Literal["agent_1", "agent_2", ...]]:
        """A node for collecting user input."""
        user_input = interrupt(value="Ready for user input.")

        # Determine the **active agent** from the state, so 
        # we can route to the correct agent after collecting input.
        # For example, add a field to the state or use the last active agent.
        # or fill in `name` attribute of AI messages generated by the agents.
        active_agent = ... 

        return Command(
            update={
                "messages": [{
                    "role": "human",
                    "content": user_input,
                }]
            },
            goto=active_agent,
        )
    ```

ìì„¸í•œ ì˜ˆì œëŠ” [how to implement multi-turn conversations (ë‹¤ì¤‘ í„´ ëŒ€í™” êµ¬í˜„ ë°©ë²•)](../how-tos/multi-agent-multi-turn-convo.ipynb)ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

### Validating human input (ì‚¬ëŒì˜ ì…ë ¥ ìœ íš¨ì„± ê²€ì‚¬)

ê·¸ë˜í”„ ìì²´ ë‚´ì—ì„œ (í´ë¼ì´ì–¸íŠ¸ ì¸¡ì´ ì•„ë‹Œ) ì‚¬ëŒì´ ì œê³µí•œ ì…ë ¥ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•´ì•¼ í•˜ëŠ” ê²½ìš° ë‹¨ì¼ ë…¸ë“œ ë‚´ì—ì„œ ì—¬ëŸ¬ interrupt í˜¸ì¶œì„ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from langgraph.types import interrupt

def human_node(state: State):
    """Human node with validation."""
    question = "What is your age?"

    while True:
        answer = interrupt(question)

        # Validate answer, if the answer isn't valid ask for input again.
        if not isinstance(answer, int) or answer < 0:
            question = f"'{answer} is not a valid age. What is your age?"
            answer = None
            continue
        else:
            # If the answer is valid, we can proceed.
            break
            
    print(f"The human in the loop is {answer} years old.")
    return {
        "age": answer
    }
```

## The `Command` primitive (`Command` ê¸°ë³¸ ìš”ì†Œ)

`interrupt` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ê·¸ë˜í”„ê°€ interruptì—ì„œ ì¼ì‹œ ì¤‘ì§€ë˜ê³  ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.

Graph execution (ê·¸ë˜í”„ ì‹¤í–‰)ì€ `invoke`, `ainvoke`, `stream` ë˜ëŠ” `astream` ë©”ì„œë“œë¥¼ í†µí•´ ì „ë‹¬í•  ìˆ˜ ìˆëŠ” [Command](../reference/types.md#langgraph.types.Command) ê¸°ë³¸ ìš”ì†Œë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬ê°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

`Command` ê¸°ë³¸ ìš”ì†ŒëŠ” ì¬ê°œ ì¤‘ì— ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ì œì–´í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

1. **Pass a value to the `interrupt` (`interrupt`ì— ê°’ ì „ë‹¬)**: `Command(resume=value)`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì‘ë‹µê³¼ ê°™ì€ ë°ì´í„°ë¥¼ ê·¸ë˜í”„ì— ì œê³µí•©ë‹ˆë‹¤. ì‹¤í–‰ì€ `interrupt`ê°€ ì‚¬ìš©ëœ ë…¸ë“œì˜ ì‹œì‘ ë¶€ë¶„ë¶€í„° ì¬ê°œë˜ì§€ë§Œ ì´ë²ˆì—ëŠ” `interrupt(...)` í˜¸ì¶œì´ ê·¸ë˜í”„ë¥¼ ì¼ì‹œ ì¤‘ì§€í•˜ëŠ” ëŒ€ì‹  `Command(resume=value)`ì— ì „ë‹¬ëœ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

       ```python
       # Resume graph execution with the user's input.
       graph.invoke(Command(resume={"age": "25"}), thread_config)
       ```

2. **Update the graph state (ê·¸ë˜í”„ ìƒíƒœ ì—…ë°ì´íŠ¸)**: `Command(update=update)`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ ìƒíƒœë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ì¬ê°œê°€ `interrupt`ê°€ ì‚¬ìš©ëœ ë…¸ë“œì˜ ì‹œì‘ ë¶€ë¶„ë¶€í„° ì‹œì‘ëœë‹¤ëŠ” ì ì— ìœ ì˜í•˜ì‹­ì‹œì˜¤. ì‹¤í–‰ì€ `interrupt`ê°€ ì‚¬ìš©ëœ ë…¸ë“œì˜ ì‹œì‘ ë¶€ë¶„ë¶€í„° ì¬ê°œë˜ì§€ë§Œ ì—…ë°ì´íŠ¸ëœ ìƒíƒœë¡œ ì¬ê°œë©ë‹ˆë‹¤.

      ```python
      # Update the graph state and resume.
      # You must provide a `resume` value if using an `interrupt`.
      graph.invoke(Command(update={"foo": "bar"}, resume="Let's go!!!"), thread_config)
      ```

`Command`ë¥¼ í™œìš©í•˜ì—¬ ê·¸ë˜í”„ ì‹¤í–‰ì„ ì¬ê°œí•˜ê³ , ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³ , ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Using with `invoke` and `ainvoke` (`invoke` ë° `ainvoke`ì™€ í•¨ê»˜ ì‚¬ìš©)

`stream` ë˜ëŠ” `astream`ì„ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ë©´ `interrupt`ê°€ íŠ¸ë¦¬ê±°ë˜ì—ˆìŒì„ ì•Œë¦¬ëŠ” `Interrupt` ì´ë²¤íŠ¸ë¥¼ ë°›ê²Œ ë©ë‹ˆë‹¤.

`invoke` ë° `ainvoke`ëŠ” interrupt ì •ë³´ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ì •ë³´ì— ì•¡ì„¸ìŠ¤í•˜ë ¤ë©´ `invoke` ë˜ëŠ” `ainvoke`ë¥¼ í˜¸ì¶œí•œ í›„ [get_state](../reference/graphs.md#langgraph.graph.graph.CompiledGraph.get_state) ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ ìƒíƒœë¥¼ ê²€ìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤.

```python
# Run the graph up to the interrupt 
result = graph.invoke(inputs, thread_config)
# Get the graph state to get interrupt information.
state = graph.get_state(thread_config)
# Print the state values
print(state.values)
# Print the pending tasks
print(state.tasks)
# Resume the graph with the user's input.
graph.invoke(Command(resume={"age": "25"}), thread_config)
```

```pycon
{'foo': 'bar'} # State values
(
    PregelTask(
        id='5d8ffc92-8011-0c9b-8b59-9d3545b7e553', 
        name='node_foo', 
        path=('__pregel_pull', 'node_foo'), 
        error=None, 
        interrupts=(Interrupt(value='value_in_interrupt', resumable=True, ns=['node_foo:5d8ffc92-8011-0c9b-8b59-9d3545b7e553'], when='during'),), state=None, 
        result=None
    ),
) # Pending tasks. interrupts 
```

## How does resuming from an interrupt work? (interruptì—ì„œ ì¬ê°œí•˜ëŠ” ë°©ë²•)

!!! warning

    Resuming from an `interrupt` is **different** from Python's `input()` function, where execution resumes from the exact point where the `input()` function was called.

`interrupt` ì‚¬ìš©ì˜ ì¤‘ìš”í•œ ì¸¡ë©´ì€ ì¬ê°œ ì‘ë™ ë°©ì‹ì„ ì´í•´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. `interrupt` í›„ ì‹¤í–‰ì„ ì¬ê°œí•˜ë©´ ê·¸ë˜í”„ ì‹¤í–‰ì´ ë§ˆì§€ë§‰ `interrupt`ê°€ íŠ¸ë¦¬ê±°ëœ **graph node (ê·¸ë˜í”„ ë…¸ë“œ)**ì˜ **beginning (ì‹œì‘)**ë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤.

ë…¸ë“œì˜ ì‹œì‘ë¶€í„° `interrupt`ê¹Œì§€ì˜ **All (ëª¨ë“ )** ì½”ë“œê°€ ë‹¤ì‹œ ì‹¤í–‰ë©ë‹ˆë‹¤.

```python
counter = 0
def node(state: State):
    # All the code from the beginning of the node to the interrupt will be re-executed
    # when the graph resumes.
    global counter
    counter += 1
    print(f"> Entered the node: {counter} # of times")
    # Pause the graph and wait for user input.
    answer = interrupt()
    print("The value of counter is:", counter)
    ...
```

**resuming (ê·¸ë˜í”„ ì¬ê°œ)** ì‹œ ì¹´ìš´í„°ê°€ ë‘ ë²ˆì§¸ë¡œ ì¦ê°€í•˜ì—¬ ë‹¤ìŒ ì¶œë ¥ì´ ìƒì„±ë©ë‹ˆë‹¤.

```pycon
> Entered the node: 2 # of times
The value of counter is: 2
```

## Common Pitfalls (ì¼ë°˜ì ì¸ í•¨ì •)

### Side-effects (ë¶€ì‘ìš©)

ë…¸ë“œê°€ ì¬ê°œë  ë•Œë§ˆë‹¤ ë‹¤ì‹œ íŠ¸ë¦¬ê±°ë˜ë¯€ë¡œ API í˜¸ì¶œê³¼ ê°™ì€ side effect (ë¶€ì‘ìš©)ê°€ ìˆëŠ” ì½”ë“œë¥¼ ì¤‘ë³µì„ í”¼í•˜ê¸° ìœ„í•´ `interrupt` **after (ë’¤)**ì— ë°°ì¹˜í•˜ì‹­ì‹œì˜¤.

=== "Side effects before interrupt (BAD) (interrupt ì „ì˜ ë¶€ì‘ìš© (ë‚˜ì¨))"

    ì´ ì½”ë“œëŠ” `interrupt`ì—ì„œ ë…¸ë“œê°€ ì¬ê°œë  ë•Œ API í˜¸ì¶œì„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.

    API í˜¸ì¶œì´ idempotent (ë©±ë“±ì„±)ì´ ì•„ë‹ˆê±°ë‚˜ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ê²½ìš° ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ```python
    from langgraph.types import interrupt

    def human_node(state: State):
        """Human node with validation."""
        api_call(...) # This code will be re-executed when the node is resumed.
        answer = interrupt(question)
    ```

=== "Side effects after interrupt (OK) (interrupt í›„ì˜ ë¶€ì‘ìš© (ì¢‹ìŒ))"

    ```python
    from langgraph.types import interrupt

    def human_node(state: State):
        """Human node with validation."""
        
        answer = interrupt(question)
        
        api_call(answer) # OK as it's after the interrupt
    ```

=== "Side effects in a separate node (OK) (ë³„ë„ ë…¸ë“œì˜ ë¶€ì‘ìš© (ì¢‹ìŒ))"

    ```python
    from langgraph.types import interrupt

    def human_node(state: State):
        """Human node with validation."""
        
        answer = interrupt(question)
        
        return {
            "answer": answer
        }

    def api_call_node(state: State):
        api_call(...) # OK as it's in a separate node
    ```

### Subgraphs called as functions (í•¨ìˆ˜ë¡œ í˜¸ì¶œë˜ëŠ” ì„œë¸Œ ê·¸ë˜í”„)

[as a function (í•¨ìˆ˜)](low_level.md#as-a-function)ìœ¼ë¡œ ì„œë¸Œ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•  ë•Œ **parent graph (ìƒìœ„ ê·¸ë˜í”„)**ëŠ” ì„œë¸Œ ê·¸ë˜í”„ê°€ í˜¸ì¶œëœ (ê·¸ë¦¬ê³  `interrupt`ê°€ íŠ¸ë¦¬ê±°ëœ) **beginning of the node (ë…¸ë“œ ì‹œì‘)**ë¶€í„° ì‹¤í–‰ì„ ì¬ê°œí•©ë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ **subgraph (ì„œë¸Œ ê·¸ë˜í”„)**ëŠ” `interrupt()` í•¨ìˆ˜ê°€ í˜¸ì¶œëœ **beginning of the node (ë…¸ë“œ ì‹œì‘)**ë¶€í„° ì¬ê°œë©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´,

```python
def node_in_parent_graph(state: State):
    some_code()  # <-- This will re-execute when the subgraph is resumed.
    # Invoke a subgraph as a function.
    # The subgraph contains an `interrupt` call.
    subgraph_result = subgraph.invoke(some_input)
    ...
```

??? "**Example: Parent and Subgraph Execution Flow (ì˜ˆì œ: ìƒìœ„ ë° ì„œë¸Œ ê·¸ë˜í”„ ì‹¤í–‰ íë¦„)**"

      Say we have a parent graph with 3 nodes:

      **Parent Graph (ìƒìœ„ ê·¸ë˜í”„)**: `node_1` â†’ `node_2` (subgraph call (ì„œë¸Œ ê·¸ë˜í”„ í˜¸ì¶œ)) â†’ `node_3`

      And the subgraph has 3 nodes, where the second node contains an `interrupt`:

      **Subgraph (ì„œë¸Œ ê·¸ë˜í”„)**: `sub_node_1` â†’ `sub_node_2` (`interrupt`) â†’ `sub_node_3`

      When resuming the graph, the execution will proceed as follows:

      1. **Skip `node_1`** in the parent graph (already executed, graph state was saved in snapshot).
      2. **Re-execute `node_2`** in the parent graph from the start.
      3. **Skip `sub_node_1`** in the subgraph (already executed, graph state was saved in snapshot).
      4. **Re-execute `sub_node_2`** in the subgraph from the beginning.
      5. Continue with `sub_node_3` and subsequent nodes.

      Here is abbreviated example code that you can use to understand how subgraphs work with interrupts.
      It counts the number of times each node is entered and prints the count.

      ```python
      import uuid
      from typing import TypedDict

      from langgraph.graph import StateGraph
      from langgraph.constants import START
      from langgraph.types import interrupt, Command
      from langgraph.checkpoint.memory import MemorySaver


      class State(TypedDict):
         """The graph state."""
         state_counter: int


      counter_node_in_subgraph = 0

      def node_in_subgraph(state: State):
         """A node in the sub-graph."""
         global counter_node_in_subgraph
         counter_node_in_subgraph += 1  # This code will **NOT** run again!
         print(f"Entered `node_in_subgraph` a total of {counter_node_in_subgraph} times")

      counter_human_node = 0

      def human_node(state: State):
         global counter_human_node
         counter_human_node += 1 # This code will run again!
         print(f"Entered human_node in sub-graph a total of {counter_human_node} times")
         answer = interrupt("what is your name?")
         print(f"Got an answer of {answer}")


      checkpointer = MemorySaver()

      subgraph_builder = StateGraph(State)
      subgraph_builder.add_node("some_node", node_in_subgraph)
      subgraph_builder.add_node("human_node", human_node)
      subgraph_builder.add_edge(START, "some_node")
      subgraph_builder.add_edge("some_node", "human_node")
      subgraph = subgraph_builder.compile(checkpointer=checkpointer)


      counter_parent_node = 0

      def parent_node(state: State):
         """This parent node will invoke the subgraph."""
         global counter_parent_node

         counter_parent_node += 1 # This code will run again on resuming!
         print(f"Entered `parent_node` a total of {counter_parent_node} times")
  
         # Please note that we're intentionally incrementing the state counter
         # in the graph state as well to demonstrate that the subgraph update
         # of the same key will not conflict with the parent graph (until
         subgraph_state = subgraph.invoke(state)
         return subgraph_state


      builder = StateGraph(State)
      builder.add_node("parent_node", parent_node)
      builder.add_edge(START, "parent_node")

      # A checkpointer must be enabled for interrupts to work!
      checkpointer = MemorySaver()
      graph = builder.compile(checkpointer=checkpointer)

      config = {
         "configurable": {
            "thread_id": uuid.uuid4(),
         }
      }

      for chunk in graph.stream({"state_counter": 1}, config):
         print(chunk)

      print('--- Resuming ---')

      for chunk in graph.stream(Command(resume="35"), config):
         print(chunk)
      ```

      This will print out

      ```pycon
      --- First invocation ---
      In parent node: {'foo': 'bar'}
      Entered `parent_node` a total of 1 times
      Entered `node_in_subgraph` a total of 1 times
      Entered human_node in sub-graph a total of 1 times
      {'__interrupt__': (Interrupt(value='what is your name?', resumable=True, ns=['parent_node:0b23d72f-aaba-0329-1a59-ca4f3c8bad3b', 'human_node:25df717c-cb80-57b0-7410-44e20aac8f3c'], when='during'),)}

      --- Resuming ---
      In parent node: {'foo': 'bar'}
      Entered `parent_node` a total of 2 times
      Entered human_node in sub-graph a total of 2 times
      Got an answer of 35
      {'parent_node': None} 
      ```



### Using multiple interrupts (ì—¬ëŸ¬ interrupt ì‚¬ìš©)

**single (ë‹¨ì¼)** ë…¸ë“œ ë‚´ì—ì„œ ì—¬ëŸ¬ interruptë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ [validating human input (ì‚¬ëŒì˜ ì…ë ¥ ìœ íš¨ì„± ê²€ì‚¬)](#validating-human-input)ê³¼ ê°™ì€ íŒ¨í„´ì— ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë™ì¼í•œ ë…¸ë“œì—ì„œ ì—¬ëŸ¬ interruptë¥¼ ì‚¬ìš©í•˜ë©´ ì£¼ì˜í•´ì„œ ì²˜ë¦¬í•˜ì§€ ì•Šìœ¼ë©´ ì˜ˆê¸°ì¹˜ ì•Šì€ ë™ì‘ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë…¸ë“œì— ì—¬ëŸ¬ interrupt í˜¸ì¶œì´ í¬í•¨ëœ ê²½ìš° LangGraphëŠ” ë…¸ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ì‘ì—…ì— íŠ¹ì •ëœ resume ê°’ ëª©ë¡ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì‹¤í–‰ì´ ì¬ê°œë  ë•Œë§ˆë‹¤ ë…¸ë“œì˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤. ë°œìƒí•˜ëŠ” ê° interruptì— ëŒ€í•´ LangGraphëŠ” ì‘ì—…ì˜ resume ëª©ë¡ì— ì¼ì¹˜í•˜ëŠ” ê°’ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. Matching (ì¼ì¹˜)ì€ **strictly index-based (ì—„ê²©í•˜ê²Œ ì¸ë±ìŠ¤ ê¸°ë°˜)**ì´ë¯€ë¡œ ë…¸ë“œ ë‚´ì—ì„œ interrupt í˜¸ì¶œ ìˆœì„œê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.

ë¬¸ì œë¥¼ í”¼í•˜ë ¤ë©´ ì‹¤í–‰ ê°„ì— ë…¸ë“œì˜ êµ¬ì¡°ë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì—¬ê¸°ì—ëŠ” interrupt í˜¸ì¶œì„ ì¶”ê°€, ì œê±° ë˜ëŠ” ì¬ì •ë ¬í•˜ëŠ” ê²ƒì´ í¬í•¨ë˜ë©°, ì´ëŸ¬í•œ ë³€ê²½ìœ¼ë¡œ ì¸í•´ ì¸ë±ìŠ¤ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œëŠ” ì¢…ì¢… `Command(resume=..., update=SOME_STATE_MUTATION)`ì„ í†µí•´ ìƒíƒœë¥¼ ë³€ê²½í•˜ê±°ë‚˜ ì „ì—­ ë³€ìˆ˜ì— ì˜ì¡´í•˜ì—¬ ë…¸ë“œì˜ êµ¬ì¡°ë¥¼ ë™ì ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ë¹„ì •ìƒì ì¸ íŒ¨í„´ì—ì„œ ë°œìƒí•©ë‹ˆë‹¤.

??? "Example of incorrect code (ì˜ëª»ëœ ì½”ë“œ ì˜ˆì œ)"

    ```python
    import uuid
    from typing import TypedDict, Optional

    from langgraph.graph import StateGraph
    from langgraph.constants import START 
    from langgraph.types import interrupt, Command
    from langgraph.checkpoint.memory import MemorySaver


    class State(TypedDict):
        """The graph state."""

        age: Optional[str]
        name: Optional[str]


    def human_node(state: State):
        if not state.get('name'):
            name = interrupt("what is your name?")
        else:
            name = "N/A"

        if not state.get('age'):
            age = interrupt("what is your age?")
        else:
            age = "N/A"
            
        print(f"Name: {name}. Age: {age}")
        
        return {
            "age": age,
            "name": name,
        }


    builder = StateGraph(State)
    builder.add_node("human_node", human_node)
    builder.add_edge(START, "human_node")

    # A checkpointer must be enabled for interrupts to work!
    checkpointer = MemorySaver()
    graph = builder.compile(checkpointer=checkpointer)

    config = {
        "configurable": {
            "thread_id": uuid.uuid4(),
        }
    }

    for chunk in graph.stream({"age": None, "name": None}, config):
        print(chunk)

    for chunk in graph.stream(Command(resume="John", update={"name": "foo"}), config):
        print(chunk)
    ```

    ```pycon
    {'__interrupt__': (Interrupt(value='what is your name?', resumable=True, ns=['human_node:3a007ef9-c30d-c357-1ec1-86a1a70d8fba'], when='during'),)}
    Name: N/A. Age: John
    {'human_node': {'age': 'John', 'name': 'N/A'}}
    ```

## Additional Resources ğŸ“š

- [**Conceptual Guide: Persistence**](persistence.md#replay): Read the persistence guide for more context on replaying.
- [**How to Guides: Human-in-the-loop**](../how-tos/index.md#human-in-the-loop): Learn how to implement human-in-the-loop workflows in LangGraph.
- [**How to implement multi-turn conversations**](../how-tos/multi-agent-multi-turn-convo.ipynb): Learn how to implement multi-turn conversations in LangGraph.
