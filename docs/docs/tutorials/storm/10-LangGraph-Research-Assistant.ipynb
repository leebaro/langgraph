{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "635d8ebb",
      "metadata": {},
      "source": [
        "# LangGraph : Research Assistant with STORM\n",
        "\n",
        "- Author: [Secludor](https://github.com/Secludor)\n",
        "- Design: [LeeYuChul](https://github.com/LeeYuChul)\n",
        "- Peer Review: \n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "Research is often a labor-intensive task delegated to analysts, but AI holds tremendous potential to revolutionize this process. This tutorial explores **how to construct a customized AI-powered research and report generation workflow** using `LangGraph`, incorporating key concepts from Stanford's STORM framework.\n",
        "\n",
        "### Why This Approach?\n",
        "The STORM methodology has demonstrated significant improvements in research quality through two key innovations:\n",
        "- Outline creation through querying similar topics enhances coverage.\n",
        "- Multi-perspective conversation simulation increases reference usage and information density.\n",
        "\n",
        "The translation is accurate but can be enhanced for better clarity and technical precision. Here's the reviewed version:\n",
        "\n",
        "### Key Components\n",
        "\n",
        "**Core Themes**\n",
        "- Memory: State management and persistence across interactions.\n",
        "- Human-in-the-loop: Interactive feedback and validation mechanisms.\n",
        "- Controllability: Fine-grained control over agent workflows.\n",
        "\n",
        "**Research Framework**\n",
        "- Research Automation Objective: Building customized research processes tailored to user requirements.\n",
        "- Source Management: Strategic selection and integration of research input sources.\n",
        "- Planning Framework: Topic definition and AI analyst team assembly.\n",
        "\n",
        "### Process Implementation\n",
        "\n",
        "**Execution Flow**\n",
        "- LLM Integration: Conducting comprehensive expert AI interviews.\n",
        "- Parallel Processing: Simultaneous information gathering and interview execution.\n",
        "- Output Synthesis: Integration of research findings into comprehensive reports.\n",
        "\n",
        "**Technical Implementation**\n",
        "- Environment Setup: Configuration of runtime environment and API authentication.\n",
        "- Analyst Development: Human-supervised analyst creation and validation process.\n",
        "- Interview Management: Systematic question generation and response collection.\n",
        "- Parallel Processing: Implementation of Map-Reduce for interview parallelization.\n",
        "- Report Generation: Structured composition of introductory and concluding sections.\n",
        "\n",
        "\n",
        "AI has significant potential to support these research processes. However, research requires customization. Raw LLM outputs are often not suitable for real decision-making workflows.\n",
        "\n",
        "A customized AI-based [research and report generation](https://jxnl.co/writing/2024/06/05/predictions-for-the-future-of-rag/#reports-over-rag) workflow is a promising solution to address this issue.\n",
        "\n",
        "![10-LangGraph-Research-Assitant-concept](./assets/10-LangGraph-Research-Assitant-concept.png)\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Utilities](#utilities)\n",
        "- [Analysts Generation : Human in the Loop](#analysts-generation--human-in-the-loop)\n",
        "- [Interview Execution](#interview-execution)\n",
        "- [Report Writing](#report-writing)\n",
        "\n",
        "### References\n",
        "\n",
        "- [research and report generation](https://jxnl.co/writing/2024/06/05/predictions-for-the-future-of-rag/#reports-over-rag)\n",
        "- [LangGraph `Send()`](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)\n",
        "- [LangGraph - Multi-Agent](https://langchain-ai.github.io/langgraph/concepts/multi_agent/#custom-multi-agent-workflow)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c7aba4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Setting up your environment is the first step. See the [Environment Setup](https://wikidocs.net/257836) guide for more details.\n",
        "\n",
        "\n",
        "**[Note]**\n",
        "\n",
        "The langchain-opentutorial is a package of easy-to-use environment setup guidance, useful functions and utilities for tutorials.\n",
        "Check out the  [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21943adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f25ec196",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_community\",\n",
        "        \"langchain_openai\",\n",
        "        \"tavily-python\",\n",
        "        \"arxiv\",\n",
        "        \"pymupdf\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690a9ae0",
      "metadata": {},
      "source": [
        "You can set API keys in a `.env` file or set them manually.\n",
        "\n",
        "[Note] If you’re not using the `.env` file, no worries! Just enter the keys directly in the cell below, and you’re good to go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4d6fac1c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "# Attempt to load environment variables from a .env file; if unsuccessful, set them manually.\n",
        "if not load_dotenv():\n",
        "    set_env(\n",
        "        {\n",
        "            \"OPENAI_API_KEY\": \"\",\n",
        "            \"LANGCHAIN_API_KEY\": \"\",\n",
        "            \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "            \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "            \"TAVILY_API_KEY\": \"\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "# set the project name same as the title\n",
        "set_env(\n",
        "    {\n",
        "        \"LANGCHAIN_PROJECT\": \"LangGraph-Research-Assistant\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa00c3f4",
      "metadata": {},
      "source": [
        "## Utilities\n",
        "\n",
        "These are brief descriptions of the modules from `langchain-opentutorial` used for practice."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652f3f62",
      "metadata": {},
      "source": [
        "### `visualize_graph`\n",
        "for visualizing graph structure"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc51d6cb",
      "metadata": {},
      "source": [
        "### `random_uuid` , `invoke_graph`\n",
        "- `random_uuid` : for generating a random UUID (Universally Unique Identifier) and returns it as a string.\n",
        "- `invoke_graph` : for streaming and displays the results of executing a CompiledStateGraph instance in a visually appealing format. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c683ef59",
      "metadata": {},
      "source": [
        "### `TabilySearch`\n",
        "\n",
        "This code defines a tool for performing search queries using the Tavily Search API. It includes input validation, formatting of search results, and the ability to customize search parameters.\n",
        "**Methods** :\n",
        "- `__init__` : Initializes the TavilySearch instance, setting up the API client and input parameters.\n",
        "- `_run` : Implements the base tool's run method, calling the search method and returning results.\n",
        "- `search` : Performs the actual search using the Tavily API, taking various optional parameters to customize the query. It formats the output based on user preferences.\n",
        "- `get_search_context` : Retrieves relevant context based on a search query, returning a JSON string that includes search results formatted as specified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "786c076b",
      "metadata": {},
      "source": [
        "## Analysts Generation : Human in the Loop\n",
        "**Analyst Generation** : Create and review analysts using Human-In-The-Loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "188b28b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the model\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "13850b4f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_opentutorial.graphs import visualize_graph\n",
        "\n",
        "\n",
        "# Class defining analyst properties and metadata\n",
        "class Analyst(BaseModel):\n",
        "    # Primary affiliation information\n",
        "    affiliation: str = Field(\n",
        "        description=\"Primary affiliation of the analyst.\",\n",
        "    )\n",
        "    # Name\n",
        "    name: str = Field(description=\"Name of the analyst.\")\n",
        "\n",
        "    # Role\n",
        "    role: str = Field(\n",
        "        description=\"Role of the analyst in the context of the topic.\",\n",
        "    )\n",
        "    # Description of focus, concerns, and motives\n",
        "    description: str = Field(\n",
        "        description=\"Description of the analyst focus, concerns, and motives.\",\n",
        "    )\n",
        "\n",
        "    # Property that returns analyst's personal information as a string\n",
        "    @property\n",
        "    def persona(self) -> str:\n",
        "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
        "\n",
        "\n",
        "# Collection of analysts\n",
        "class Perspectives(BaseModel):\n",
        "    # List of analysts\n",
        "    analysts: List[Analyst] = Field(\n",
        "        description=\"Comprehensive list of analysts with their roles and affiliations.\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713f52d5",
      "metadata": {},
      "source": [
        "The following defines the state that tracks the collection of analysts generated through the Analyst class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "15e0b45b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# State Definition\n",
        "class GenerateAnalystsState(TypedDict):\n",
        "    # Research topic\n",
        "    topic: str\n",
        "    # Maximum number of analysts to generate\n",
        "    max_analysts: int\n",
        "    # Human feedback\n",
        "    human_analyst_feedback: str\n",
        "    # List of analysts\n",
        "    analysts: List[Analyst]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0d517e",
      "metadata": {},
      "source": [
        "### Defining the Analyst Generation Node\n",
        "\n",
        "Next, we will define the analyst generation node.\n",
        "\n",
        "The code below implements the logic for generating various analysts based on the provided research topic. Each analyst has a unique role and affiliation, offering professional perspectives on the topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ec68f06",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# Analyst generation prompt\n",
        "analyst_instructions = \"\"\"You are tasked with creating a set of AI analyst personas. \n",
        "\n",
        "Follow these instructions carefully:\n",
        "1. First, review the research topic:\n",
        "\n",
        "{topic}\n",
        "        \n",
        "2. Examine any editorial feedback that has been optionally provided to guide the creation of the analysts: \n",
        "        \n",
        "{human_analyst_feedback}\n",
        "    \n",
        "3. Determine the most interesting themes based upon documents and/or feedback above.\n",
        "                    \n",
        "4. Pick the top {max_analysts} themes.\n",
        "\n",
        "5. Assign one analyst to each theme.\"\"\"\n",
        "\n",
        "\n",
        "# Analyst generation node\n",
        "def create_analysts(state: GenerateAnalystsState):\n",
        "    \"\"\"Function to create analyst personas\"\"\"\n",
        "\n",
        "    topic = state[\"topic\"]\n",
        "    max_analysts = state[\"max_analysts\"]\n",
        "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
        "\n",
        "    # Apply structured output format to LLM\n",
        "    structured_llm = llm.with_structured_output(Perspectives)\n",
        "\n",
        "    # Construct system prompt for analyst creation\n",
        "    system_message = analyst_instructions.format(\n",
        "        topic=topic,\n",
        "        human_analyst_feedback=human_analyst_feedback,\n",
        "        max_analysts=max_analysts,\n",
        "    )\n",
        "\n",
        "    # Call LLM to generate analyst personas\n",
        "    analysts = structured_llm.invoke(\n",
        "        [SystemMessage(content=system_message)]\n",
        "        + [HumanMessage(content=\"Generate the set of analysts.\")]\n",
        "    )\n",
        "\n",
        "    # Store generated list of analysts in state\n",
        "    return {\"analysts\": analysts.analysts}\n",
        "\n",
        "\n",
        "# User feedback node (can be left empty since it will update state)\n",
        "def human_feedback(state: GenerateAnalystsState):\n",
        "    \"\"\"A checkpoint node for receiving user feedback\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "# Function to decide the next step in the workflow based on human feedback\n",
        "def should_continue(state: GenerateAnalystsState):\n",
        "    \"\"\"Function to determine the next step in the workflow\"\"\"\n",
        "\n",
        "    human_analyst_feedback = state.get(\"human_analyst_feedback\", None)\n",
        "    if human_analyst_feedback:\n",
        "        return \"create_analysts\"\n",
        "\n",
        "    return END"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb884f7",
      "metadata": {},
      "source": [
        "**Explanation of Code Components**\n",
        "\n",
        "- **Analyst Instructions**: A prompt that guides the LLM in creating AI analyst personas based on a specified research topic and any provided feedback.\n",
        "\n",
        "- **create_analysts Function**: This function is responsible for generating a set of analysts based on the current state, which includes the research topic, maximum number of analysts, and any human feedback.\n",
        "\n",
        "- **human_feedback Function**: A placeholder function that can be expanded to handle user feedback.\n",
        "\n",
        "- **should_continue Function**: This function evaluates whether there is human feedback available and determines whether to proceed with creating analysts or end the process. \n",
        "\n",
        "This structure allows for a dynamic approach to generating tailored analyst personas that can provide diverse insights into a given research topic."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77452ab5",
      "metadata": {},
      "source": [
        "### Building the Analyst Generation Graph\n",
        "\n",
        "Now we'll create the analyst generation graph that orchestrates the research workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a903259c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALEAAAF3CAIAAABljT2PAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXd4FMX/xz/XW3pvl94hlFASWkJTioAIAkGKIEX4ikoVFCmCKEVEBKQogvQuVXrvPaT3cpd2KXeX5Hr9/bH3O+ORhATushtuXg88z2Z2Zva9d++bmZ2dQtLr9YBA1IGMtwAE4UCeQJiCPIEwBXkCYQryBMIU5AmEKZTly5fjraGpPBWXPxYKNHrdxXK+SK30Z9vx5ZLTZflEPpZo1b4sW56sli+TONKZFBIJ70/x1RC9nEiqrlyf/fyxSFCjVj0XV1ao5DUatVSjrtWoq1QKsVpJ8ONqtUqoUpQqpGfK8rfnp6j1uhyJWKHR4P25NgaJsH1WmbUiP7btoaJsX7Zte3sXvOWYjYxa0cnSvEm+4W3snPHWUj9E9IRKp/0x80lvV5+2RP3U3pwiuSTYxj61WtjVyR1vLaYQzhM1alWhrFYLei7LBm8tFuevwowQW4ehHv54C/kPxPJEak0Vi0K1pzHwFtJyPBYK+rtzqSQCNewIJOWRUHCiOM+qDAEAXZzcM2rED4VleAv5FwKVE7UatUqnxVsFPlwUFNLIlFHewXgLAQJ54i9e+iB3PwqRitAWRqJReTA4DAoFbyHEqDv+LEhzoDKs2RAAwKJQS5VSvFUAIcoJlU6bVSv2ZHHwlUEEjhRnB7Pt33H3xVcG/j9NKomMDIEx0M0vR1aNtwoCeGL0owst3LQUlBVnpCe9SQ7paS/KBSXmU2TAjkYfzw03e7bNBWdPPBOVB3Hs6OSWa1hlZiQPH9ClpKjwtXM4sv+PSWMG0OgWeWbOk1Rn1IoskXPTwdkT7Rxc5odEt+QV01Ne6HS6tu06NTeh5v9fXKUkP+Ny/R0dLdLvrtZr/y7JtUTOTQf3uoNEttjr4/Nnjo0dHh/X2f+jEX2uXDwNAL+sXfrjd/MBYGj/6JgoD6wG0ev1xw7uSng/rmc0t2+30JmfjEhPewEAebmZMVEexw/t/mbetPguAZt/XgEAE0e9c/HcCT6/ICbKo2+3ULO30P3YdkwK1bx5NhecL//Fi5sz/Nt6s83/auPe7WvLv5k1bMRHE6d8fuPqeRabDQDDR024c+OSq4fXp7MWAkBwSCQArPl+4ZkTByZ+MiuqfZekxEe7ft9YXlYSEdk+PzcTAPbu3jLl07kJ46fb2NoCwKy5Sz6fPnrshOm9+7/HZLFI5jY0mUSaHtDWvHk2F5w9odRp2VSaJXJ+cPc6AMxd9D2LxR409EMs0IcbICgrGTh0VIfoGCzk5rXzfx/Z8+2KDUM/GAsAEmktAIRHtAOA/NxsAJi7cGVcn4HGbGl0OgDE9R1kzMHs3Kwo6unsaYdfHz/Odcdv7Xs7WqaxFhIWCQDLFs2qKC81BubmpKvUqvA27Ywhu37fyPULHDI8AfszI/WFo6Ozu6c3ABTkZbp7etc1BABkpL0AgLAIC/6UHwoFQpXCcvm/Epw9UamSa/U6S+Q8ZHjCvEXfP3l0Z9SQHqeO78cCM1KTACAsPAr7U1hVkZ6SOGDwB8YqICMjOSzScDYvN7tNW9P2b0Zakq9/EIdjawnNGJ0c3dyYbMvl/0pw9sQfBamZlnn0IpFIo8dNPXL6to9vwLpVi+RyGQBkpCc5u7i5unlgcYp4BQDg5W3oN5TLZSmJT8IiogBAq9XyC3IDg0NNss1ITQoLt2x9/64bl02xSH3aRHD2RLitk1CttETOKpUSAFxc3bv36qvRaHQ6HQDkZqe7unka49BoNAAw9jScOr5PqVS4u3sDQBEvX6VW+QeG/SdPtaqwIKduDmZHrFYeLs62XP5NAec25hifEEu8In/68M6PKxaMGPMxABw/vKdP/yEcjg0A2HDsUl5cP7BnG41Gj+szwC8wxM7e4fihXcEh4Wkpib/98gMAyOVSAMjPywSAoP+WEzQqjcXmXL10OigkvLpGPG7iDPPKBoDk6kq8X0DhXU7o9PoyhcTs2SpVKg7Hdtuvqw/t3THsg4RvV27Awj+ZMcfNw2vLhu/37Nyk1+nZbM7KNdvEIuEnHw0+tO/3GV8scnZxy8pMxRoTFAqF6xdUN1sSifTFvGVSqXTNyoU3rpwzu2wAcKazBuM9FA//96K/5CRG2Dp1dnTDVwZB4FCouPdZ4e+JYrnkTFlBI0OM/tzxy75dv70cHtEmKj01ud4kO/efDQg0bR5agukfD8vJyng53N3DU1BW+nK4g4PjifMPG8rtblWpHZXe29Xb3DKbB/6eAACtXi9uuKVZWyOural5OZxEalC8q7sn1n60NBXlpWqV+uVwtVpdrwAKhYJ1fryMSqddmvbw9+i+FpDZPAjhCblWs7swfbRPCN5C8ESn1zvRCTHYDH8F2LCzcFuHfbx6CmErQaRSClUKIhiCKOUEhlKrFasV1BYcS0EQCmU1FwW8r8M64y3EACGMicGgUBzozPNlBXgLaVHkWg2NRCaOIYjlCQBgkCl0CuVeVT0t9reSc6UFHAotimAzpInlCQAY7R0SZe/ModIeiwR4a7EsZ8vymRSKhV4LvwmE8wQA+LPtmGRKtVq1IPkONg4Kb0VmQ6fX36sqPVac40BjDPUIIOajFoHamC8jVCkc6IxatfqrlLtBHPsp/pEqnTa9VkQlk9vYOim0mpRaEYtCIfixVKN+ICxT63XvefjnSKqficvf8/D3JvCseSKWE0ac6EwykOxp9CVhXbo4ujnSGCwKNVsifi6usKPRKWTyncpicx1v+eeUXCgyb57YMZlEkmk1/mw7Bxqjs6Pb9IC2RDYE0cuJlmT48OGbNm3icrl4C8EfQpcTCFxAnkCYgjxhICgoqAmxrALkCQO5uTjPviIOyBMG7Ozs8JZAFJAnDNTUN0TDOkGeMODmhgb/GUCeMFBeXo63BKKAPGEgNDTU7BOCWynIEwaysrJQly4G8gTCFOQJA05OTnhLIArIEwaEQiHeEogC8oQBJycn1MbEQJ4wIBQKURsTA3kCYQryhAE/Pz9Ud2AgTxgoLCxEdQcG8gTCFOQJA8HBhNhPhQggTxjIycnBWwJRQJ5AmII8YQC9FzWCPGEAvRc1gjyBMAV5wgAay28EecIAGstvBHkCYQryhAE0v8MI8oQBNL/DCPKEAX9/f9Q/gYE8YaCgoAD1T2AgTyBMQZ4w4OLiguoODOQJA5WVlajuwECeMBASEkImo08DkCf+JTs7G9szDIE8YQCVE0bQp2AAlRNGkCcMeHpacIfI1oW1r5k6YMAAOp1OJpOrqqpsbW2pVCqJROJwOAcPHsRbGm7gvEUd7lAolNJSw9YQCoUCAOh0+pQpU/DWhSfWXnfExsaalJRcLvf999/HTxH+WLsnJkyY4O7ubvyTTqePHTsWV0X4Y+2eCAgI6Nz5332X/Pz8hg8fjqsi/LF2TwDA5MmTsYcOOp0+ZswYvOXgD/IEBAQEdO/eXa/X+/r6okLi9Z87pBp1nrS6Vqsxtx58iBwxxKWMFzto0D1hGd5azAOdTPZn2bowWK+R9nX6J37IfPxAKAixcdBZd98GkXGiM5JqqoLZ9rOC2jV3W6HmeUKt081Ouh3t4NLGzrn5OhEtTZVKfoifvbZtD08Wp+mpmueJ2Um3uzq4BdrYv5ZCBD4sT390rvuQpm983Yw25t2qUkcaHRmi1THcM+DPgvSmx2+GJ/Kk1XTr20z8LcCJznxRU9n0+M3whFitdKYzX0sVAk9c6Ex1c4YBNMMTMq1WC+hBo/WhA6hSK5oeH/VZIUxBnkCYgjyBMAV5AmEK8gTCFOQJhCnIEwhTkCcQpiBPIExBnkCYgjxhKXJSX+zd8EPa04d4C2k2rd4Tkmrxk5uX8FZRD9dPHb14ZE+1sBkvJOsi4BemP3tkblFNonV7okpQ8vnQuBM7f8NbiJl5cOWfeaMHPLl5BZert25PaFRqtVqFtwrzI5dKcLy6xeeLPrl55fzBXYXZ6WQKLbhN1OiZc/1DI6f17yKX1r4/eeadcydFVeUjpswaPnkmADy4euHMX9tLCnKZNjYde/RJ+N88O0cnAHhw5fzxP36tKC2hUWnBUe0TPpvvFxJRVV46b/QAAOBlZ4zvFg4AG09dd3bzbCSfRlApFb8unp2bmiiTSJzdPOOGjBg6cTqFQgGAaf27hES1d/XyeXrrmkqhCG3XceK8b928uI2nMiKTSj4f2gsANp+5w+JwsJD/De5BpVK3nL2dm5Z8aMtPRfnZbBvbtl26ffLVd4+uX9q5eikAXDyy5+KRPW7e3J+PXa4oLd67YVX6s8ckMjkwvM2EuYu9/S21QLhly4kLh//6ZdGsrKRnHtwAVw+vpAd3asUi49kze3aEdewc0TGm13vDscibv51dwssPjIxisTi3zh5fOXOcXCoFAI1apdVoQqM62Do6Jj+8u2b2VJVCzmCwOnSPBwC2jV1s/0Gx/QcxGKzG82kEOoNZWVbi4eMf3Ka9sLL82I6NF4/sMZ5NenDn/uXz7WJ7eQcGJ967uX7eDI1G88pUGGyOTUzfQUq5/OHVf7CQJzevaFTKLr3f1Wo16xfMyEtPjoju6uUXWJCRRmeyXL28AyLaAoCHr39s/0Ede/QBgK3fffXs9jUPX9/QqA75maksTvOGYjcLC5YT4sqKw1vWk0ikhRt3tu3SHQCKC3LruvvjuUv6jUjAjqurKg9vWc9kc1b+eczTL0Cv12/97qt7F8/cOHN0UMKkHgOH9RxkmNe7YeGsp7eupD171KF7/ITZ3yTeu+ni6TVr5Yam5NO44B/3nsKWvivISvv24xH3L58bPHay8ezKnUfcuX4AsGTyyPyM1NzUxLD2nV+ZCqP3+6NunTtx88zx3sNGAcCDy2cBoNeg98tLipRyuZsXd8H6HQCgkMkAIKx9577vj96ZntI+Nm7CnG+wHPg5WQDw5Q+/unh4K2QyJpttjq+ofizoiaRHd9VqVbvYnpghAMCkuIvpP8h4/OLhHbVa5eDqdv3UESwEq1Nz05IBQFQpOP3XjuRHd4XlAmzBwvISfr0XbTyfxnl47eLlo3tLePlqpRIAKkqK6p519vTGDvzD2+RnpAqKizBPNJ4KIzSqo09AcHZKYnFBrq2DY8rj+85unhGdYjRqlZsXt7yEv27utGEff4plWC8de/a+d/HMujnT3580I6b/4Ffey5tgQU9UV1YAgJu3b0MRmGyOSeSKkqJ/Du6qG4fOYEprq5d9MkZUKQiMiGoTHZObnlKYlaaUyRu5aL35NK723L4/Dm75icWxbd+tF4tjc+P0UYW8/kvQ6UwA0KpVzUoVP/TD/b+uvnnmuJsXV6fVdh84lEQi0eiMrzft+uPHpS/u335x/3anuP6frfipXqlTF61gcTjXTx39bfmCk7u2zv95O9agsQQW9ATb1g4ARBXlTYpsYwsAsf0Hz1r5s8mpG2eOiSoFnePfmb16EwCc3LW1MCut7rSUuutQNZJP41w6uh8Alm7bxw0O0+v1N88eJzVh5kvTU/Uc9P6RrT/fPn/Sw9sX+xMLd/Xy+XrTn+nPH29fuejprStXTxwaNNZQx+nr3BedyZq8YPngj6b8uXpZ6pN7+375ce5aSz2BW7CNGd6xMwAk3ruRlfwcC8nPTFUp6x8sGh7dBQCe3r5mLOTzM1OVchkAKGRSAHDz8sHCs5OfAYBOpwUAJscGAKrKSlUKOQCo1apG8mkcuUxqrCDy0pN1Wq22CbNhX5lK8/+PyrYOjp3i+9WKhNkpiQERbYzVqKCYDwARHbu8O2o8AJTy8wGAxbEFgFJePuZ4jUYjrBCoFHJ3b27CZ3ONpyyEBcsJb/+guCEjb509/v2Mcd6BISQSqSg3a9KCZX2H1zOf39s/qNeg4bfPn/xu2hjfkAiNRl2SnzP2868GJUwKa9cJAC4d2yco5gnLy/IzUgGglJcHAPZOzm7e3PJi/oIxg1m2tgNHT+g9bFRD+TSuNrxj52e3r303dYyHb0DakwfYl1FWxPPwabDuazwVk8UGgBf3b/Ua/AEWObb/ew+unAeAXoMMs9d1Ot3qLybTaHTvgOCMxEcAEBkdAwCBkW3JFEryo7uLxg+TS2q/2bT7712/JT+6G9ymfUlhHgBERHd9g2/mFVj2WXTKohVjZs5z9eaWFORWCUrDo2N8AkMaijx18apRM2a7evnwcjKqSkvCo7v6BYcDQEBE22mLVzm7eybdvw0k0oINv3v5Bealp2C9VZ+t+NkvNLJaVCmqENjYOzaST+NMWrCsU1x/YUV5VtKT+GEjJ85dzGCx0p8+eO1UMf0Gsm3tRRXlcmktFjmycywAUKjU2P7vYSFKuTwiOqZaVPX87nWOncPEuYtj+w8GADcv7tSvVzq7e5YW5ul1ehqT4eUXRKXRn9+9IZdK3xk57qNZC5v5VTSDZswXXZP1zI5G62jvajk1bzdZyc9XTB/bsWefeeu2tuR1JRr1toKUY10HNSEuWNe6d7t/+k5QxKv3VGhU9AdTPrPcpXnZGevnz6wqL6XSaFiPLZGxIk9kJT3nZWfUe+qVT6pviEqlVCrl0b36Dp/0v8DItha91ptjRZ74Yc9JvC4d3Kb9tguvaJoQh9b9XhRhCZAnEKYgTyBMQZ5AmII8gTAFeQJhCvIEwhTkCYQpyBMIU5AnEKY0wxPONAYZ0O7NrQ+dXh/Itmt6/GZ4wp3J5svxnIuCeD2KFRJ6c7ZObUbUaAfX2rdx0tVbT6lC1svZq+nxm+EJb5ZNPzfu0eKc1xKGwIfblcVqnW6Au1/TkzR7/45L5bxjxTnt7Vx82BwGmdZ8kYiWQK/XFSmklUq5UqddHhHTrLSvs6dLjkT8d0leiUJaqnzFhDsiI5VI2WwWqYGKtlpcbWtrS6a01ucyf7Y9i0zp4ezR362xMcb1YqX7EEskkvfee+/mzZv1ns3Ozp49e7aTk9PevXtbXBr+tNbfwRuSnp4eERHR0Nm0tDSRSJSZmfn111+3rC5CYKWeSEtLi4yMbOjs48ePVSqVTqe7d+/enj2m88TfeqzUE0KhsEOHDvWeUiqVGRmGobxSqfTw4cMPHrSaoZRmwUo9cePGjcDAwHpPpaamSiT/ds0JBIK1a9cKhcIWVIcz1ugJqVTq6urq4+NT79kXL15UVFTUDeHxePPnz28pdfhjjZ7IyMgwWV6oLo8fP8YOsCcyEonk4OBg4pK3Gyua32GksLAwJqbBbpycnBxXV1cajbZ9+/akpKSBAwe2rDr8sUZPvHjxokuXLg2dvXTJsNqmWCxet26dFXrCGusOuVweFhb2ymgODg4TJ06s2960EqyxHzM2Nvb27ds0GnpZUz9WV07w+XwPD48mGuLu3bvGJqf1YHWe4PF4sbGxTYxcXV19+vRpCysiHFbXxszNzWWxWE2MHBMTo9VqLayIcFhdOVFYWOjn19QBJs7OzkOHDrWwIsJhdZ4oKyvjcpuxsuSvv/4qfdW6zG8ZVueJwsJCL69mDE58+vRpfr4FFx4kINbVntDr9SqVytPTs+lJFi9e7OT0ijX93zKsyxMCgaC53RKhoaEWk0NQrKvuqKysdHFxaVaSixcvnjhxwmKKiIh1eUIkEgUFNW8rFIVCkZKSYjFFRMS66o7XGBrTs2dPa6s+rMsTNTU1dnbNmDmJdVE4OztbTBERsa66Q6/Xe3h4NCtJaWnpzp07LaaIiFiXJ6qqqrB9vJqORCK5fPmyxRQREevyhFqtbu6zqJub28iRIy2miIhYlyfs7e1tbW2bm2TUqFEWU0RErMsTIpGouS8vxGLxqVOnLKaIiFiXJ8hkct3Nw5pCaWnp0aNHLaaIiFiXJ5ycnKjU5j1+29nZDRkyxGKKiIh1eUKlUonF4mYl8fb2TkhIsJgiImJdnrC1tW3us2hxcTGaL/o2w2azq6qqmpXk8ePH1tY/YV192w4ODs2tOzw8POzt7S2miIhYlyecnJw4HE4TIv5L0wd5vzVYV93h4OCQnPzqzezrcvv27dzcXIspIiLW5QknJyd3d/dmJTlw4EBzmyCtHevyhL29fWJiokJR/57p9dKtW7fg4GBLiiIc1uUJrH1QXl7e9PgTJ060tjG6VucJlUpVVFTUxMgajebYsWMWVkQ4rM4TUVFRTW8f5OXlHT9+3MKKCIfVrTVw6NCh7du3s1gsiURCIpEaWjYVg8/n5+XlxcfHt6BA/LGW/omBAwdWVlYal6iqra3V6XSvHHzL5XKbNZHw7cBa6o6FCxfa29uTSCQSybAtDYlE6ty5c+OpEhMTra1zwoo80adPH5MqwN7evm/fvo2n2rlzp0AgsLA0wmEtngCApUuXGlcZ0Ov1rq6u0dHRjScZMWJEu3btWkQdgbAiT2A1iKOjI3bctWvXV8bv06ePjY2N5XURC+vyRNeuXQcNGkQmk+3t7V/5NCESiTZv3txS0ghEk547VDqt6G3ZCWzcZzPvpaXodDpuVBuBUt5IzKfpqSlFvMbjtC7oJLIjnfHKaK/on7gk4J0oyeXLJbbWt3KgVqvV6/RU2tvzuO7OYJcqZO+4cqcFtGkkWmOe2F2YllErjnPxcqIzLSMS0dLUqFU5UnFajWhj+zgKqf7dYhv0xO7C9ByJeIhngIVFInAgvVb4VFyxuX39Lar625hFstqMWhEyxNtKhK0Tl2VzUVBY79n6PZErq9Homzc3BtG6sKHSkmrqfxdYvycqVQpvVvPGLSJaFx4MjqyB5WDr94RMq5Fb3/qxVoUe9OUKWb2nrKvPCtEUkCcQpiBPIExBnkCYgjyBMAV5AmEK8gTCFOQJhCnIEwhTkCcQppjTEzVi4Z3zp57dvmbGPFsvhdnp5/b9USMSarXapId3zh/cba6cb507sWXZfMttXmdOT9y9cHrbioUZz1vZhpxqlfLAprWzhsZN6dvx4JafzJXt9pVfH9zyk1xSWysSrp099fLx/ebKee+GH+9fOmu5CXyo7oBjv2/658CfNDo9vGOXoMgovOXgz9sz2PC1uXvhNJXO+GHP3yxO85ZdflsxvycKsjOWTRnNz8tydHXvO3zM4LGTsel40/p3kUtrd99OwVYtPfDrmn8O7pq8YHm/EQnnD+0+8OuahP/Nu3Xu7/LSYhcPz77Dx1QUFz27e11SLQ6J6jBpwXJ3by4A8HOzdv64pCg/R6PR+AQED504LabvQAAoyEr79uMRAxM+LuXlZycl0pnMzvH9Ev63gMlmNyI1OyXxu2mGtS+n9e8S23/QrJUbAKBaWHV468/P71xVSGXegSFDJkyL7TcQi9bIKb1ef+7An9f+PiQqF7j7+AorK+peS1Jd/d20hPysdHtHp9h33hs5dRadwWzkjjCe3Lxy/uCuwux0MoUW3CZq9My5/qGRdbP948clN04fbdul+4INv1MoFLN8g+avO9Ke3K8qL/MOCBLwCw9uWnvt5JGmpNLr9Qe3/OTq5dO2S7fSwvz9G1dfO3U4vEMnn4Dg5Id3Ny+ZjUVj29oKSvh+oRE+AcEFmambv52Tl/bvxkwXDv0lKOLF9BvIYDKvHD+4/9fVjV+UY2PXoXs8tuZyh+7x2MctqRZ/Nz3h1tnjbBu7gMio4rzszd/OvnbqcOOnAGDvhh8ObV5XWVbiFRAsl0lltdV1ryWT1Agry7lBITVi0bl9f2z46jOsQdDIHV04/Ncvi2ZlJT3z4Aa4englPbhTKxbVzfPysQM3Th/19Av4fNUGcxnCIuVEVEyPueu20mj0m2eP/75q8a2zx/t9MKYpCXsMHDpz2ToAWDtnatKDOx9O+2LIhGkajWb2B33z01OFFQInV3dnN8/fzt3FCp7zh3bv37j64bXzgZFtsRzcuX6rdp9gsNg1YuGXw3rf/ufvSQuWNfJhefkHzl+/fXy3cBqDMX/9dizw712/lRfz+34wZvKC5SQSiZ+b9e2kEUe2bogf8mEjp0p5+ZeO7qUxmEu37QsIb6vVahd+9F4Zr8B4LWc3z5+PXaZQKJVlxcunjU1+dPf5nevRvfo2dEfiyorDW9aTSKSFG3e27dIdAIoLcr39/93MLOvF030bf2Db2s9bu5Vja87VGs3vCW5gKI1GB4Cufd79fdXiihJ+ExO6uBu2gnX28AIABxc3AKBSqe4+vuLK8urKCidXd5VCfvnY/jsXz1SWFOtBBwDlxf/mb+fozGCxAcDOwcnFy7u0MF9UUebi4d0s/diztEImO7hpLRbC4thIqsXlRbxGTr24ewMAuvUfHBDeFgAoFApWNRih0KiYO108vHsPGXFy97bUJw+ie/Vt6I6SHt1Vq1XtYntihgCAuoYAgM3fztZqNANGj/fw9W/WDb4SC7YxKVQaAKjVzVvL+GWw3xD25LVx8Zcv7t1y8fTu0ndAjagq8e4NZQMDyGh0BgBom391UWUFANy7eMYknM5kNHaqqgIA3LybtFiFnbMLAMilkkbuqLoSy9C3oUxqxCIAuHJ8/4BRE2zsHZp7m43Qcs8dJDIZAPRvMBxcUMx/ce+Wk6vHmv1nGCx25osniXdvmP0xnW1jUyNUrj34j5d/YNNPOTi5AICoskkLE1SVlQKAk6tbI3fEtrUDAFFFg8uxjftiUerTB4l3bxze+vOURSte617rp+X6J+ydnAAgPz0F6/FMfnyvuTkoZBIAsHc2VBDZSc8BQKs185yDiI5dsFaFWq0CAI1anZuW/MpTfmGRAHDvwll+bhbWZFarlHWz1ajUWM9jWRHv1j9/A0C7bnGN3FF4x84AkHjvRlbycyyH/MxUlfLfVRzfGTV+4tzFVDrj+qkjOakvzPgJtFw5EdWlR2lh/to5U7lBYfzcLIWsefvtAICnb4Cto1N+RuqqzyZSqbSUx/cAQMArMG9R8cEnnyXeu3n/0tm0pw/cvLgCfgGJQtlw/AqdwWzkVFTXHiHtorOTni3++APvgGBZbU2VoLRutsKKsnmj3mVxbEoL8zRqdWz/waHtolVKRUN35O0fFDdk5K2zx7+fMc47MIREIhXlZk2FGpN8AAAUVUlEQVRasKzv8H8b7G5e3GETp534Y/Outd+t+PMocZ9FG2Lk9M+7DxhKodKKC/I6x/eL6TewCYn+A53BnLNmS1Bku5zUJEERb8qiFd0HDJVJJUW5WWbU6RMYsmTb/g7d41VyRV56MpNt02PAML1O1/gpAJizenPPQcOYbJvKkmKfwGBnN8+62b774XgGg1lWmO/k6jFi6qwZy9a+8o6mLFoxZuY8V29uSUFulaA0PDrGJzDERO2Q8VPdvLiFWWlXzNd3Xv980b38TL6stq+rj7kugyAaRXLJ9YriLR3qmTL6lvdtK2Syjd983tDZfh8kdI5/p2UVtQLeck9oterkh3cbOtsutlfLymkdvOWe4Nja77ufgbeKVgZ6V44wBXkCYQryBMIU5AmEKcgTCFOQJxCmIE8gTEGeQJhinj6rrMs3WA7WtVkvAWExGC7tIpsQ8RWYqR9TpW4fYQY1iDfBiWOTA+o3z8c8nojqE6flNDZqHtECyMw0jsQ8nlCyGUo9WjsRZ6qbEKcpoDYmwhTkCYQpyBMIU5AnEKYgTyBMQZ5AmII8gTAFeQJhCvIEwhTkCYQpyBMIU5AnEKYgTyBMwc0TeWkp09/penL3tlfGtNzioJa7dEVp8fhu4af+evXdGbl17sSckf0/6dMhK+nZ613UXODmCT3odTqNTtvY2kJqlXLnmqU7vv+mBXUZeHH/9vKpYwqz018veVFeNgB4v7ScTUOkP3+84/tvgtq0/2jWQu+AoCaksCC4zRcNioz64+orfhD8nOzrJ4+M/Wx+07PV6/Wk/27D/XJIU7h8bF9Rfg43KKy5CTH4OVkA4OnX1G/3yvH9VDpj6qKVjS/oaeT1bqqJ4LP+RPqzR6s+mwgA837a1rFH7yWfjKTTmTb2junPHlFo1A+nftFvREJW8vMV08cak/x09JKHj2/Swzundm3Nz0ylUGid4vp88tV3dCZr55ql108e6RTXP/3ZI//wNt9s2rUgYZCkppobFJqdnPj+x58GhLVZN2/6p0t+7DX4AwD4Ylhvd67v4i17/ly9NPXZw8CIqMQ7Nxhsdu8hIz78dDYArPlySvIjw2x04wqNRuTS/6ywQ6GQ6UyWyQ3+tnzBvYtnfAKCBSVF3MCQSfOXYQs2lhbmH93+S8qTB2qVMigyauo3qzx8fL98v09VuWFRm6lfr+w9bFTSwzsnft9UkJ1hY2fXa/AHo2fMIZFI9y+f27J0XpvO3UsL86SS6m0XHlBp9MvH9l09cai8mM+xdxgwasLQidOa+BU0sv4EPnWHO9e3Q4/eAOAXGo6tEpGd/NzZ3XPclwspFMr+Tav1er2Lh1dYh840Gn3B+h0LNvzu4eP74Mr5tbOnSiW1kxcs6zXo/TvnTz+4dhEA+NmZAODo6vbFD78MmzhNKZeV8QoUEknn+P6ffbcutt+ggux0AOAGhwGAtLZaWFHmGxwOAKKqCgG/UK/Xj5rxJZtjc3L3Nmy1w56D3geAuCEjF/z8+wdT/rN8RY1YOK1/p7r/fvxyyss3yM/NYrFt4oaOHD55Zklh7oaFn6mUijJewbKpY1KePPhw2qyxs+ZnJT07vXsbACTMmg8A7bvHLfj59449+z65eXndnGkMFmfa1yvD2nc6s2fH/cvnAICXkwEAOp1m+pIfpn79PY3O+Gv9yj0/r/LwDZj6zfc+AcGHt643y7eDT93h5OqhUipsHRycXD10Ol2VoLRr34ET5y4GgEfXLqQ8vq/X651c3UUVgoDIqPbd4wBAp9Pt2/gDjUaf9s0qNscGWw7MwdlFp9Px87JCojpOmr8Uyzwn9YVerx80dtK7H47HQgqz0ilUqndAMPZtAYBvSBgAiKsqAiLazFqxHgC4weGr/jehMCs9uldfrOzs/u57xrUpjbBt7JZs2/efkJdW6dZoNKWFed0HDBs8djIASKvF/xzcVZyfc27/TpmkZvKC5R16xifeuanTau2dXYwrgUZEx7Tv1kur1f710/duPr4Lft5OpdGCIts9vHohLz25+7tDCrPSGSzW7NWbsBVSiwtyrxw/4OHr//H8JdWVFUqFnPbfFTlfG9zaE7zsDL+QSAAo5eWrFAq/kAgsvLSwwNMvkEwmV1dVlhfzu/QZgIWX8QrElRUAsGzKKABgcWw//HR2u5iepYX5SrkcK3WMOQNAh559jCGFWWle/kHYSq68HMwT4Tqdrjg/p+eAYVgcbJk6JocDAFnJz8hkclBk+5dlU6lU3+CIuiEUimlZW8Yv0KjV/mGGgewUGhUA9DpIf/4YAHatWw7rgEyh9Bg4dNjETwGgKDcbAHwCgrHCQFQpGD5pBpVGA4CaahG2BjQA8HIyQ6OijUvmZjx/gn0sXwyLBwBXL5/PV/5sjm8GJ08IK8ok1WKs4ijMTAMA39BwAJBJJeUlfKzozk55BgCBEYZ1k6l0GgAMHjsZO+vB9cNq8cLsDADwCwk3Zo49LHADQ7E/VQq5oIjX7d0h2J+pj++TKRSfgOAyXoFKofAPb4OF37t4GgCiuvYAgOzkRC+/QBaH87LyGrHwf4P+U3iEtItetv1A3ZD89FQA8A+NwKz26PolW0cn35AwKpUW3Kb9jKVrZBKJm7ePcaHTovwsAMCKMYVMBgBsO/u6qtp1i6sRCcWVFT3+38EAQKVRAeDzVb+4eHizOTbuXD8y2TwtAXw8wcvONH6RBVnpAOAfEgEAvOx0APALjTA25R5fvyiqEETF9PTyC/TyC7x57oSjmzuNxrh0bP/Ur1cak/jW8QQvO9Od61f3GyWRSLys9JTH9zKePXp664pPUCiNzuDlZgFATmqSTqtLfnTn6a2r/Ud+hC0sJ5dKpDU1V/8+DAAmi4U3pe7ISHwMAE9vXeXnZN04c7S8iPfFDxupNFq7br2unzxy4+xxT1//fw7++fG8JbYOjlg5wWCxXDy8sNKCzmRe/fuQrb1TfkbKleMH44aMDIqMwtq8da0fGR1DpTNO7to6cMzE6qoqMpk0ZEJTG5iNg48nDD/u0AjME/bOLljNysvBvBIBAJ3i+oVEdXx843Lq04dh7TuRSKQvV2/666cVR7f/QqUx4t4bjmXFy8m0dXBwcnXH/tTr9fzcrHYxPY3XojNZI6d/eXbv778unhPcJgoA/ELCAICfnU4mkzMTH9+9cMrVy2fcF4sGJnyMJRk+eeb+jWv2bfwxpu+7Jp6gUqlh7Ts3cmsajebprSs9Bg59eO1CtbAqMLzN17/uiuwcCwAfzVqgUaqunzqiVin9gsMxQwBAUX6Ol38g9mxp6+A4a8XPh39b/+fqJQ6ubqNmzBk6YZrxE6trfVcvny9W/XLkt/W71i63sXf86POvzPXtmOdZtEYsfDlQp9WRX6prAYBGY9RbLLcwP82fUVqYt/7oJXxlVJYVz/6gX9x7I6Z/+0NLXtfiayGaVLEY9k7O1cKql8Pjh3447ZvvzXLdN4GfnckNec0uKXNRIxL+tf57AIjpPwhfJXUxjycW/frny4FqtQpr6pvg+P/lPI5Iaqqryktx/yYqSovyM1Imzl3cnkirMqJ1dK0UwvVjIogM8gTCFOQJhCnIEwhTkCcQpiBPIExBnkCYgjyBMAV5AmEK8gTCFOQJhCnIEwhTkCcQptTvCTaFyiS/5dvHWTlkAE9m/fOL6veEO4NVpKi1sCoEnhQrpGxK/T/7+j0RynGgkVC18jYj1ag7OLjWe6r+L96Nye7s6H6iJNfCwhD48ERcLlKrGhozVf84K4yzpflXy/k9XbzcGGyameYOIPBFoJAVyGoqVYqVkbENxWnMEwDwQFh2ojg3tVZIfdurEo1GQ6W+5c1qLxZbrdO/68Yd7RPSSLRXeMKIRGuGzUKIzLhx49auXevt7Y23EAvCIFGaUt439ZdhQ6G9sSRCM+ydAe52Dm/9bTaFppYTCOvhLW8lNJ2LFy9KJBK8VRAC5AkDW7duFYlEeKsgBMgTBmbNmuXo6Ii3CkKA2hMIU1A5YeDs2bOoPYGBPGHgjz/+QO0JDOQJA5MmTXJwcMBbBSFA7QmEKaicMHDgwIHqanPt5Nu6QZ4wcOTIkZqaGrxVEALkCQMJCQl2dnZ4qyAEqD2BMAWVEwZ2794tFovxVkEIkCcMnDx5srYWDUsG5Il/Qf0TRlB7AmEKKicM7N27F7UnMJAnDBw/fhy1JzCQJwyMHj0a9U9goPYEwhRUThj4559/UN2BgTxhYMeOHaiNiYE8YaB79+4slumWkNYJak8gTEHlhIGsrCyVSoW3CkKAPGHgq6++EggEeKsgBMgTBgIDA2k0NFkUUHsCUQ+onDCA2hNGkCcMoPaEEeQJA7169WKz618b0NpA7QmEKaicMHDz5k2ZTIa3CkKAPGFgw4YNVVX17JpshSBPGEDtCSOoPYEwBZUTBu7cuYPaExjIEwZ++ukn1J7AQJ4w0Lt3b9SewLD29kR0dDSJRCKRSDqdjkwm6/V6vV4/evToRYsW4S0NN6y9nOjUqRN2QCaTAYBEIvn4+EyYMAFvXXhi7Z4YP368yZTAuLi4t3vV7Vdi7Z6Ij48PDg42/unj4zN27FhcFeGPtXsCAMaOHWtvb48d9+vXz8oLCeQJwJ44goOD9Xq9n5/fyJEj8ZaDP8gTAAAfffSRjY1NXFycl5cX3lrwp/U9iz4Qlt2qLOns6KbUaU+U5JQr5RqdfqR3MJVEOlGSq9bpXu/4QF4qmUb/0OdN8zlRkutCZw33CmSRqTcri3q6eL3r5ov3Z9Y8Wo0nciXVAqUsuabqn7ICuU5rCCVh//WA3QSJEMd6vZ70/7KpJFIvZ69Ojm52VHqsk4flPycz0Do8sbMg9byAV6NpxeMlWWRKO3uX5RExFBKpCdHxhOieuCDg3aosfiIux1uIefBicmIc3T8NjCJyO47QnjhTmr+fnylUK/EWYk7YZGoHe5flkTF4C2kQ4vq1UFa7qzDtLTMEAMh0moeisluVxXgLaRCCeqJKqViZ8Uii1eAtxCJoAdZkPb1SzsNbSP0Qse7IkoiWpz+qVCnwFmJZ2GTKOG7YqEa3f8UFIpYTf5fkv/WGAACZTvtQVC4nXllIOE+odNrkmkq8VbQQSTWVZQrCDfgjnCemP79erpTjraLlWJB8J7WGWGP+iOWJi2WFQgIbgnfs3JX4kTq1Obdur9GqT5bmmTHDN4dYnnCgMxV6Hd4qGqQ2K5fN9SSbe5mKIA6x1vkmlieSCVaKmlCTlW8T4Gf2bG9XFquMb3AIABVvAf+SUSu6WsG3XP7VGTl5fx4SJ6XrdTrH9pER82cy3V2ET5NSV/3adukc3tGzVY8TyTSq39jhAeMNoygk+bycHftFz1NIZHLgJwnSAr57fKzZheVIq48W5YzzDTN7zq8HgcqJfFm12mI/l4p7Tx7PXKQSVYfMnBj2+SfV6dmZm3YCAJBIivLKF4tXcwK4EfNnMFycc7bvUwgqAaAmI+fRpwulBfygqR8FfpKQs32vXqPhBHDNrk0PUKYk0NMHgcqJ3i4+fxakWyJndY0kZeUGu5DAzltWYa0BwY37yvIqANDI5ADQdskcl9hoLHLKig1yQTnD1Snl+19o9rZdd6yj2XIAQCuT5+zYZxNo/roDAIZ7BVoi29eDQOUEnUyu1ZizSW+k9PJNTa3ULT5WI5FJecV5fx0RPkl0i48FAGkBH8hkx45tsZhauQIAaHa2wqfJ0oKiwI9HY4YAALVESqbT2N4WGQORUUugLZAJVE7s4WUCWKSjvSY9h0Qh5+46nL11DwBQbW0CPxnrN3Y4AEjzeSwvdwqDjsWU8ktIFArb20Nw7S4AOHVqZ8xEWsBn+/qQKBRLKLxazn/Pw98SOb8GBPKEC53JpFBlFujr1Ws0dGfH7vs2Swv4FBaL7e1BphueJyX5fJuAf8fGSfN5bB9PMo2mEokBgOHsaMhBqxUnZ7h062R2bRj+HAJtE0GgumOoZ4Avy9YSOTPdXVVVIq1Mbh8ZahPANRpCr9NJC4s4/j7GmJI8HsefCwA0ezsAkBWXYuFFpy9paiU2gZYaWfmJf6SFcn4NCOQJnV7vy7axRM4e78brdfqnc5bzT5znn7yQsnIDFi4vEeiUKmM5oZZIlRVVmEVce3YFEin1h02C6/fy/jqStWkXANQtUcyIG4Ml0xDoTRiBPEEmkdIt09SyDfJr9/1XJDIpa/Ou/D1HGS5OWLgknwcAWMEAANJ8PgDY+HMBwD48uM3Xn6tralNWbqh6/MIv4X3LeYKkJ9LXQLTxE4eKsvfyMtQE7t62BP1duV+FRuOt4l8I1MYEgASfkFxp9c2Gx6WpxDV3E2bWe4rl7SEvLns53LVn17bffmkuhRX3nqSs2NAsAQETRvqPG9FQhk40xoKQjuaSZxaIVU4AwDNx+bepDzQNPJTqtVpFeQPvREj1P8lSmAy6o7255GkVSpWoulkCqLYcmg2noQz7u3G/CiFQIUG4cgIAgjkOTgxmQ0MoSBQKy9OtxUX9C4XJMKMAWyqtp5OnuXIzF4Rq3AAA2NHoS8K6eDMb/GG9NdBIpDlBHbo7I080gTBbxzVtu9vT6HgLsSzT/Nv0dCHilGUiegIA3BjsNrZORJ9E9wa40JlDPQn03qsuhGtj1uWHzCdJ1VVC9Vs1hpsEMMwjYEZgFGEnjhLaEwBQpZLPenGr6m0Z2k8nkReERMe7EnopHILWHUac6axvwjo70Rh2lNa9WReVRArh2CdwQwluiFZQThipVqsOF2VfEBRKtBYZY2E5GCSyJ4uzIjLWlkLjUFuBs1uNJzAeCEufiCu8mTbZEvFzcQWZBJ5MjlyrLVFKmWSKNzGOlTqtUKVgUWh9XX3saDQmmRLv4kMjE71INtLKPGFEp9fzZbV6Eviz7SRada6k2oZKC+LYE+G4VqOqVMrdmWx266zvWqsnEJaj1RRoiBYDeQJhCvIEwhTkCYQpyBMIU5AnEKb8H+aqz0bQtN9GAAAAAElFTkSuQmCC",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Create graph\n",
        "builder = StateGraph(GenerateAnalystsState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"create_analysts\", create_analysts)\n",
        "builder.add_node(\"human_feedback\", human_feedback)\n",
        "\n",
        "# Connect edges\n",
        "builder.add_edge(START, \"create_analysts\")\n",
        "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
        "\n",
        "# Add conditional edge: return to analyst creation node if human feedback exists\n",
        "builder.add_conditional_edges(\n",
        "    \"human_feedback\", should_continue, [\"create_analysts\", END]\n",
        ")\n",
        "\n",
        "# Create memory\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile graph (set breakpoints)\n",
        "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
        "\n",
        "# Visualize graph\n",
        "visualize_graph(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2299a1d0",
      "metadata": {},
      "source": [
        "**Graph Components**\n",
        "\n",
        "- **Nodes**\n",
        "    - `create_analysts`: Generates analyst personas based on the research topic\n",
        "    - `human_feedback`: Checkpoint for receiving user input and feedback\n",
        "\n",
        "- **Edges**\n",
        "    - Initial flow from START to analyst creation\n",
        "    - Connection from analyst creation to human feedback\n",
        "    - Conditional path back to analyst creation based on feedback\n",
        "\n",
        "- **Features**\n",
        "    - Memory persistence using `MemorySaver`\n",
        "    - Breakpoints before human feedback collection\n",
        "    - Visual representation of workflow through `visualize_graph`\n",
        "\n",
        "This graph structure enables an iterative research process with human oversight and feedback integration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b57868ee",
      "metadata": {},
      "source": [
        "### Running the Analyst Generation Graph\n",
        "Here's how to execute and manage the analyst generation workflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "823b806f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mcreate_analysts\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "affiliation='Tech Research Institute' name='Dr. Emily Chen' role='Modular RAG Specialist' description='Dr. Chen focuses on the architecture and implementation of Modular RAG systems. She is interested in exploring how modularity can enhance scalability and efficiency in production environments. Her motive is to identify best practices for integrating Modular RAG into existing infrastructures.'\n",
            "affiliation='Data Science Consulting Group' name='Alex Thompson' role='Naive RAG Analyst' description='Alex specializes in the analysis and application of Naive RAG systems. He examines the limitations and potential pitfalls of Naive RAG when scaled to production level. His concern is to ensure reliability and performance in large-scale deployments.'\n",
            "affiliation='University of Machine Learning' name='Prof. Linda Gomez' role='Production-Level RAG Expert' description='Prof. Gomez researches the benefits and challenges of deploying RAG systems at the production level. She focuses on comparative studies between modular and naive approaches to highlight efficiency gains and integration concerns. Her motive is to bridge theoretical RAG concepts with practical, industry-level applications.'\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36m__interrupt__\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_opentutorial.messages import random_uuid, invoke_graph\n",
        "\n",
        "\n",
        "# Configure graph execution settings\n",
        "\n",
        "\n",
        "config = RunnableConfig(\n",
        "    recursion_limit=10,\n",
        "    configurable={\"thread_id\": random_uuid()},\n",
        ")\n",
        "\n",
        "\n",
        "# Set number of analysts\n",
        "\n",
        "\n",
        "max_analysts = 3\n",
        "\n",
        "\n",
        "# Define research topic\n",
        "\n",
        "\n",
        "topic = \"What are the differences between Modular RAG and Naive RAG, and what are the benefits of using it at the production level\"\n",
        "\n",
        "\n",
        "# Configure input parameters\n",
        "\n",
        "\n",
        "inputs = {\n",
        "    \"topic\": topic,\n",
        "    \"max_analysts\": max_analysts,\n",
        "}\n",
        "\n",
        "\n",
        "# Execute graph\n",
        "\n",
        "\n",
        "invoke_graph(graph, inputs, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd057565",
      "metadata": {},
      "source": [
        "When `__interrupt__` is displayed, the system is ready to receive human feedback. At this point, you can retrieve the current state and provide feedback to guide the analyst generation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b6046767",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('human_feedback',)\n"
          ]
        }
      ],
      "source": [
        "# Get current graph state\n",
        "state = graph.get_state(config)\n",
        "\n",
        "# Check next node\n",
        "print(state.next)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a5981af",
      "metadata": {},
      "source": [
        "To inject human feedback into the graph, we use the `update_state` method with the following key components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bd46b1e2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '8271aa75-0521-4b13-a1db-e3b9d0d0e400',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1eff4b14-3820-6610-8002-181858b197d9'}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Update graph state with human feedback\n",
        "graph.update_state(\n",
        "    config,\n",
        "    {\n",
        "        \"human_analyst_feedback\": \"Add in someone named Teddy Lee from a startup to add an entrepreneur perspective\"\n",
        "    },\n",
        "    as_node=\"human_feedback\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346b11de",
      "metadata": {},
      "source": [
        "**Key Parameters**\n",
        "- `config` : Configuration object containing graph settings\n",
        "- `human_analyst_feedback` : Key for storing feedback content\n",
        "- `as_node` : Specifies the node that will process the feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b12bf66a",
      "metadata": {},
      "source": [
        "**[Note]** : Assigning `None` as input triggers the graph to continue its execution from the last checkpoint. This is particularly useful when you want to resume processing after providing human feedback."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e12a3a25",
      "metadata": {},
      "source": [
        "(Continue) To resume the graph execution after the `__interrupt__` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f0cf45e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mcreate_analysts\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "affiliation='AI Research Institute' name='Dr. Emily Carter' role='Research Scientist' description='Dr. Emily Carter focuses on the technical differences and advancements between Modular RAG and Naive RAG. Her interest is in how these models improve efficiency and accuracy in AI systems. She provides a deep dive into the underlying mechanisms and evaluates their potential for innovation in AI research.'\n",
            "affiliation='Tech Innovations Inc.' name='Michael Thompson' role='Production Engineer' description='Michael Thompson evaluates the practical applications and benefits of implementing Modular RAG over Naive RAG at the production level. He is concerned with scalability, stability, and integration into existing systems. His insights help bridge the gap between theoretical research and real-world deployment.'\n",
            "affiliation='AI Startup' name='Teddy Lee' role='Entrepreneur' description='Teddy Lee brings an entrepreneurial perspective, focusing on how choosing between Modular RAG and Naive RAG can impact business strategy and innovation. His concerns include cost-effectiveness, market competitiveness, and the potential for disruptive technologies in the startup ecosystem.'\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36m__interrupt__\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Continue execution\n",
        "invoke_graph(graph, None, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52730608",
      "metadata": {},
      "source": [
        "When `__interrupt__` appears again, you have two options: \n",
        "\n",
        "- Option 1: Provide Additional Feedback\n",
        "    - You can provide more feedback to further refine the analyst personas using the same method as before\n",
        "- Option 2: Complete the Process\n",
        "\n",
        "To finish the analyst generation process without additional feedback:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8a914e38",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '8271aa75-0521-4b13-a1db-e3b9d0d0e400',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1eff4b14-8954-6dd8-8004-556ac5896071'}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set feedback input to None to indicate completion\n",
        "human_feedback_input = None\n",
        "\n",
        "# Update graph state with no feedback\n",
        "graph.update_state(\n",
        "    config, {\"human_analyst_feedback\": human_feedback_input}, as_node=\"human_feedback\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7b879519",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continue final execution\n",
        "invoke_graph(graph, None, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7da31ff4",
      "metadata": {},
      "source": [
        "**Displaying Final Results**\n",
        "\n",
        "Get and display the final results from the graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b3623113",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of analysts generated: 3\n",
            "================================\n",
            "Name: Dr. Emily Carter\n",
            "Role: Research Scientist\n",
            "Affiliation: AI Research Institute\n",
            "Description: Dr. Emily Carter focuses on the technical differences and advancements between Modular RAG and Naive RAG. Her interest is in how these models improve efficiency and accuracy in AI systems. She provides a deep dive into the underlying mechanisms and evaluates their potential for innovation in AI research.\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Name: Michael Thompson\n",
            "Role: Production Engineer\n",
            "Affiliation: Tech Innovations Inc.\n",
            "Description: Michael Thompson evaluates the practical applications and benefits of implementing Modular RAG over Naive RAG at the production level. He is concerned with scalability, stability, and integration into existing systems. His insights help bridge the gap between theoretical research and real-world deployment.\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "Name: Teddy Lee\n",
            "Role: Entrepreneur\n",
            "Affiliation: AI Startup\n",
            "Description: Teddy Lee brings an entrepreneurial perspective, focusing on how choosing between Modular RAG and Naive RAG can impact business strategy and innovation. His concerns include cost-effectiveness, market competitiveness, and the potential for disruptive technologies in the startup ecosystem.\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "()\n"
          ]
        }
      ],
      "source": [
        "# Get final state\n",
        "final_state = graph.get_state(config)\n",
        "\n",
        "# Get generated analysts\n",
        "analysts = final_state.values.get(\"analysts\")\n",
        "\n",
        "# Print analyst count\n",
        "print(\n",
        "    f\"Number of analysts generated: {len(analysts)}\",\n",
        "    end=\"\\n================================\\n\",\n",
        ")\n",
        "\n",
        "# Print each analyst's persona\n",
        "for analyst in analysts:\n",
        "    print(analyst.persona)\n",
        "    print(\"- \" * 30)\n",
        "\n",
        "# Get next node state (empty tuple indicates completion)\n",
        "print(final_state.next)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b22fd5",
      "metadata": {},
      "source": [
        "**Key Components**\n",
        "- `final_state`: Contains the final state of the graph execution.\n",
        "- `analysts`: List of generated analyst personas.\n",
        "- `final_state.next`: Empty tuple indicating workflow completion.\n",
        "\n",
        "The output will display each analyst's complete persona information, including their name, role, affiliation, and description, followed by a separator line. The empty tuple printed at the end confirms that the graph execution has completed successfully."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2b277b6",
      "metadata": {},
      "source": [
        "## Interview Execution\n",
        "\n",
        "### Define Classes and `question_generation` Node\n",
        "Let's implement the interview execution components with proper state management and `question_generation` Node:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4c00e51f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import Annotated\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "\n",
        "class InterviewState(MessagesState):\n",
        "    \"\"\"State management for interview process\"\"\"\n",
        "\n",
        "    max_num_turns: int\n",
        "    context: Annotated[list, operator.add]  # Context list containing source documents\n",
        "    analyst: Analyst\n",
        "    interview: str  # String storing interview content\n",
        "    sections: list  # List of report sections\n",
        "\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    \"\"\"Data class for search queries\"\"\"\n",
        "\n",
        "    search_query: str = Field(None, description=\"Search query for retrieval.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6ab79654",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_question(state: InterviewState):\n",
        "    \"\"\"Node for generating interview questions\"\"\"\n",
        "\n",
        "    # System prompt for question generation\n",
        "    question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic. \n",
        "\n",
        "    Your goal is boil down to interesting and specific insights related to your topic.\n",
        "\n",
        "    1. Interesting: Insights that people will find surprising or non-obvious.\n",
        "            \n",
        "    2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
        "\n",
        "    Here is your topic of focus and set of goals: {goals}\n",
        "            \n",
        "    Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
        "\n",
        "    Continue to ask questions to drill down and refine your understanding of the topic.\n",
        "            \n",
        "    When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
        "\n",
        "    Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
        "\n",
        "    # Extract state components\n",
        "    analyst = state[\"analyst\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Generate question using LLM\n",
        "    system_message = question_instructions.format(goals=analyst.persona)\n",
        "    question = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
        "\n",
        "    # Return updated messages\n",
        "    return {\"messages\": [question]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6957dd0a",
      "metadata": {},
      "source": [
        "**State Management**\n",
        "- `InterviewState` tracks conversation turns, context, and interview content.\n",
        "- Annotated context list allows for document accumulation.\n",
        "- Maintains analyst persona and report sections.\n",
        "\n",
        "**Question Generation**\n",
        "- Structured system prompt for consistent interviewing style.\n",
        "- Persona-aware questioning based on analyst goals.\n",
        "- Progressive refinement of topic understanding.\n",
        "- Clear interview conclusion mechanism.\n",
        "\n",
        "The code provides a robust foundation for conducting structured interviews while maintaining conversation state and context."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf3a0fa5",
      "metadata": {},
      "source": [
        "### Defining Research Tools\n",
        "\n",
        "Experts collect information in parallel from multiple sources to answer questions.\n",
        "\n",
        "They can utilize various tools such as web document scraping, VectorDB, web search, and Wikipedia search.\n",
        "\n",
        "We'll focus on two main tools: **`Tavily`** for web search and **`ArxivRetriever`** for academic papers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ac99427",
      "metadata": {},
      "source": [
        "`Tavily Search`\n",
        "- Real-time web search capabilities\n",
        "- Configurable result count and content depth\n",
        "- Structured output formatting\n",
        "- Raw content inclusion option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "79aea221",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_opentutorial.tools.tavily import TavilySearch\n",
        "\n",
        "# Initialize TavilySearch with configuration\n",
        "\n",
        "\n",
        "tavily_search = TavilySearch(max_results=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "522b7832",
      "metadata": {},
      "source": [
        "`ArxivRetriever`\n",
        "- Access to academic papers and research\n",
        "- Full document retrieval\n",
        "- Comprehensive metadata access\n",
        "- Customizable document load limits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "16b9cbca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'Published': '2024-07-26', 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang', 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.', 'entry_id': 'http://arxiv.org/abs/2407.21059v1', 'published_first_time': '2024-07-26', 'comment': None, 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI', 'cs.IR'], 'links': ['http://arxiv.org/abs/2407.21059v1', 'http://arxiv.org/pdf/2407.21059v1']}, page_content='1\\nModular RAG: Transforming RAG Systems into\\nLEGO-like Reconfigurable Frameworks\\nYunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\\nAbstract—Retrieval-augmented\\nGeneration\\n(RAG)\\nhas\\nmarkedly enhanced the capabilities of Large Language Models\\n(LLMs) in tackling knowledge-intensive tasks. The increasing\\ndemands of application scenarios have driven the evolution\\nof RAG, leading to the integration of advanced retrievers,\\nLLMs and other complementary technologies, which in turn\\nhas amplified the intricacy of RAG systems. However, the rapid\\nadvancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process\\nof “retrieve-then-generate”. In this context, this paper examines\\nthe limitations of the existing RAG paradigm and introduces\\nthe modular RAG framework. By decomposing complex RAG\\nsystems into independent modules and specialized operators, it\\nfacilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a\\nmore advanced design that integrates routing, scheduling, and\\nfusion mechanisms. Drawing on extensive research, this paper\\nfurther identifies prevalent RAG patterns—linear, conditional,\\nbranching, and looping—and offers a comprehensive analysis\\nof their respective implementation nuances. Modular RAG\\npresents\\ninnovative\\nopportunities\\nfor\\nthe\\nconceptualization\\nand deployment of RAG systems. Finally, the paper explores\\nthe potential emergence of new operators and paradigms,\\nestablishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment\\nof RAG technologies.\\nIndex Terms—Retrieval-augmented generation, large language\\nmodel, modular system, information retrieval\\nI. INTRODUCTION\\nL\\nARGE Language Models (LLMs) have demonstrated\\nremarkable capabilities, yet they still face numerous\\nchallenges, such as hallucination and the lag in information up-\\ndates [1]. Retrieval-augmented Generation (RAG), by access-\\ning external knowledge bases, provides LLMs with important\\ncontextual information, significantly enhancing their perfor-\\nmance on knowledge-intensive tasks [2]. Currently, RAG, as\\nan enhancement method, has been widely applied in various\\npractical application scenarios, including knowledge question\\nanswering, recommendation systems, customer service, and\\npersonal assistants. [3]–[6]\\nDuring the nascent stages of RAG , its core framework is\\nconstituted by indexing, retrieval, and generation, a paradigm\\nreferred to as Naive RAG [7]. However, as the complexity\\nof tasks and the demands of applications have escalated, the\\nYunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\\nSystems, Tongji University, Shanghai, 201210, China.\\nYun Xiong is with Shanghai Key Laboratory of Data Science, School of\\nComputer Science, Fudan University, Shanghai, 200438, China.\\nMeng Wang and Haofen Wang are with College of Design and Innovation,\\nTongji University, Shanghai, 20092, China. (Corresponding author: Haofen\\nWang. E-mail: carter.whfcarter@gmail.com)\\nlimitations of Naive RAG have become increasingly apparent.\\nAs depicted in Figure 1, it predominantly hinges on the\\nstraightforward similarity of chunks, result in poor perfor-\\nmance when confronted with complex queries and chunks with\\nsubstantial variability. The primary challenges of Naive RAG\\ninclude: 1) Shallow Understanding of Queries. The semantic\\nsimilarity between a query and document chunk is not always\\nhighly consistent. Relying solely on similarity calculations\\nfor retrieval lacks an in-depth exploration of the relationship\\nbetween the query and the document [8]. 2) Retrieval Re-\\ndundancy and Noise. Feeding all retrieved chunks directly\\ninto LLMs is not always beneficial. Research indicates that\\nan excess of redundant and noisy information may interfere\\nwith the LLM’s identification of key information, thereby\\nincreasing the risk of generating erroneous and hallucinated\\nresponses. [9]\\nTo overcome the aforementioned limitations, '), Document(metadata={'Published': '2024-03-27', 'Title': 'Retrieval-Augmented Generation for Large Language Models: A Survey', 'Authors': 'Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang', 'Summary': \"Large Language Models (LLMs) showcase impressive capabilities but encounter\\nchallenges like hallucination, outdated knowledge, and non-transparent,\\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\\nemerged as a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the generation,\\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\\nupdates and integration of domain-specific information. RAG synergistically\\nmerges LLMs' intrinsic knowledge with the vast, dynamic repositories of\\nexternal databases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\\ntripartite foundation of RAG frameworks, which includes the retrieval, the\\ngeneration and the augmentation techniques. The paper highlights the\\nstate-of-the-art technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG systems.\\nFurthermore, this paper introduces up-to-date evaluation framework and\\nbenchmark. At the end, this article delineates the challenges currently faced\\nand points out prospective avenues for research and development.\", 'entry_id': 'http://arxiv.org/abs/2312.10997v5', 'published_first_time': '2023-12-18', 'comment': 'Ongoing Work', 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI'], 'links': ['http://arxiv.org/abs/2312.10997v5', 'http://arxiv.org/pdf/2312.10997v5']}, page_content='1\\nRetrieval-Augmented Generation for Large\\nLanguage Models: A Survey\\nYunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\\nWangc, and Haofen Wang a,c\\naShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\\nbShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\\ncCollege of Design and Innovation, Tongji University\\nAbstract—Large Language Models (LLMs) showcase impres-\\nsive capabilities but encounter challenges like hallucination,\\noutdated knowledge, and non-transparent, untraceable reasoning\\nprocesses. Retrieval-Augmented Generation (RAG) has emerged\\nas a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the\\ngeneration, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-\\nsic knowledge with the vast, dynamic repositories of external\\ndatabases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing\\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\\nIt meticulously scrutinizes the tripartite foundation of RAG\\nframeworks, which includes the retrieval, the generation and the\\naugmentation techniques. The paper highlights the state-of-the-\\nart technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG\\nsystems. Furthermore, this paper introduces up-to-date evalua-\\ntion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.\\nIndex Terms—Large language model, retrieval-augmented gen-\\neration, natural language processing, information retrieval\\nI. INTRODUCTION\\nL\\nARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing “hallucinations” [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown\\nCorresponding Author.Email:haofen.wang@tongji.edu.cn\\n1Resources\\nare\\navailable\\nat\\nhttps://github.com/Tongji-KGLLM/\\nRAG-Survey\\nin Figure 1. The development trajectory of RAG in the era\\nof large models exhibits several distinct stage characteristics.\\nInitially, RAG’s inception coincided with the rise of the\\nTransformer architecture, focusing on enhancing language\\nmodels by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques\\n[3]–[5].The subsequent arrival of ChatGPT [6] marked a\\npivotal moment, with LLM demonstrating powerful in context\\nlearning (ICL) capabilities. RAG research shifted towards\\nproviding better information for LLMs to answer more com-\\nplex and knowledge-intensive tasks during the inference stage,\\nleading to rapid development in RAG studies. As research\\nprogressed, the enhancement of RAG was no longer limited\\nto the inference stage but began to incorporate more with LLM\\nfine-tuning techniques.\\nThe burgeoning field of RAG has experienced swift growth,\\nyet it has not been accompanied by a systematic synthesis that\\ncould clarify its broader trajectory. Thi'), Document(metadata={'Published': '2025-02-04', 'Title': 'Plan*RAG: Efficient Test-Time Planning for Retrieval Augmented Generation', 'Authors': 'Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma', 'Summary': \"We introduce Plan*RAG, a novel framework that enables structured multi-hop\\nreasoning in retrieval-augmented generation (RAG) through test-time reasoning\\nplan generation. While existing approaches such as ReAct maintain reasoning\\nchains within the language model's context window, we observe that this often\\nleads to plan fragmentation and execution failures. Our key insight is that by\\nisolating the reasoning plan as a directed acyclic graph (DAG) outside the LM's\\nworking memory, we can enable (1) systematic exploration of reasoning paths,\\n(2) atomic subqueries enabling precise retrievals and grounding, and (3)\\nefficiency through parallel execution and bounded context window utilization.\\nMoreover, Plan*RAG's modular design allows it to be integrated with existing\\nRAG methods, thus providing a practical solution to improve current RAG\\nsystems. On standard multi-hop reasoning benchmarks, Plan*RAG consistently\\nachieves improvements over recently proposed methods such as RQ-RAG and\\nSelf-RAG, while maintaining comparable computational costs.\", 'entry_id': 'http://arxiv.org/abs/2410.20753v2', 'published_first_time': '2024-10-28', 'comment': '19 pages, preprint', 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.LG'], 'links': ['http://arxiv.org/abs/2410.20753v2', 'http://arxiv.org/pdf/2410.20753v2']}, page_content='Plan∗RAG: Efficient Test-Time Planning for Retrieval Augmented Generation\\nPrakhar Verma † 1 Sukruta Prakash Midigeshi 2 Gaurav Sinha 2 Arno Solin 1\\nNagarajan Natarajan 2 Amit Sharma 2\\nAbstract\\nWe introduce Plan∗RAG, a novel framework\\nthat enables structured multi-hop reasoning in\\nretrieval-augmented generation (RAG) through\\ntest-time reasoning plan generation. While exist-\\ning approaches such as ReAct maintain reason-\\ning chains within the language model’s context\\nwindow, we observe that this often leads to plan\\nfragmentation and execution failures. Our key\\ninsight is that by isolating the reasoning plan as\\na directed acyclic graph (DAG) outside the LM’s\\nworking memory, we can enable (1) systematic\\nexploration of reasoning paths, (2) atomic sub-\\nqueries enabling precise retrievals and ground-\\ning, and (3) efficiency through parallel execution\\nand bounded context window utilization. More-\\nover, Plan∗RAG’s modular design allows it to\\nbe integrated with existing RAG methods, thus\\nproviding a practical solution to improve current\\nRAG systems. On standard multi-hop reasoning\\nbenchmarks, Plan∗RAG consistently achieves im-\\nprovements over recently proposed methods such\\nas RQ-RAG and Self-RAG, while maintaining\\ncomparable computational costs.\\n1. Introduction\\nRetrieval-Augmented Generation (RAG, Lewis et al., 2020;\\nPetroni et al., 2020; Guu et al., 2020) has emerged as a\\npromising approach for grounding language model (LM)\\nresponses in external knowledge. However, RAG systems\\nstruggle with multi-hop queries that require reasoning across\\nmultiple retrieved documents (Tang & Yang, 2024; Wei\\net al., 2022). A key challenge lies in the initial retrieval step,\\nwhich often fails to retrieve sufficient relevant documents\\ndue to the query’s lack of full contextual information (Ma\\net al., 2023). This limitation has been highlighted in recent\\nsurveys (Torfi et al., 2020; Zhao et al., 2023) as a funda-\\n† Work done during an internship with Microsoft Research.\\n1Aalto University, Finland 2Microsoft Research. Correspondence\\nto: <prakhar.verma@aalto.fi>, <amshar@microsoft.com>.\\nRAG\\nSelf-RAG\\nReAct\\n20\\n25\\n30\\n35\\n40\\n45\\nTest-time planning improves RAG\\n25.51\\n34.09\\n33.15\\n31.12\\n37.31\\n40.44\\nAccuracy (%)\\nVanilla\\nWith Plan∗\\nFigure 1. Plan∗RAG improves performance on the HotpotQA\\nbenchmark substantially compared to various existing RAG meth-\\nods, demonstrating the value of externalizing planning as a directed\\nacyclic graph (DAG) outside of the LLM’s context.\\nmental barrier to reliable AI systems, particularly given the\\nwidespread deployment of large language models (Brown\\net al., 2020) across critical domains. Consider the query:\\n“Rumble Fish was a novel by the author of the coming-of-age\\nnovel published in what year by Viking Press?” Answering\\nthis requires an iterative retrieval process: identifying the\\nRumble Fish’s author, connecting to their coming-of-age\\nnovel, and determining its publication year. Single-step\\nretrieval in RAG systems often fails in such cases, as it\\nmay retrieve documents about Rumble Fish’s author and\\nViking Press without recognizing the intermediate fact—\\nthe author’s coming-of-age novel—must first be established.\\nFurthermore, Leng et al. (2024); Shuster et al. (2021) demon-\\nstrate that even when relevant documents are retrieved, LMs\\nstruggle to reason across them due to fixed context win-\\ndows, leading to information loss and broken reasoning\\nchain. These limitations pose risks in critical domains such\\nas healthcare and finance (Pal et al., 2023; Zhao et al., 2024),\\nwhere accurate multi-step reasoning is essential.\\nRecent research has attempted to address these limita-\\ntions through structured reasoning frameworks. Chain-of-\\nThought (CoT) prompting (Wei et al., 2022) and systematic\\nquery decomposition (Patel et al., 2022) have introduced\\nexplicit reasoning steps, enabling more granular thought\\nprocesses and targeted retrievals. Building upon these foun-\\ndations, Yao et al. (2023) proposed ReAct—a framework\\nthat creates a reasoning chain ')]\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.retrievers import ArxivRetriever\n",
        "\n",
        "# Initialize ArxivRetriever with configuration\n",
        "arxiv_retriever = ArxivRetriever(\n",
        "    load_max_docs=3, load_all_available_meta=True, get_full_documents=True\n",
        ")\n",
        "\n",
        "# Execute arxiv search and print results\n",
        "arxiv_search_results = arxiv_retriever.invoke(\"Modular RAG vs Naive RAG\")\n",
        "print(arxiv_search_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "731bab0a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Published': '2024-07-26',\n",
              " 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks',\n",
              " 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang',\n",
              " 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.',\n",
              " 'entry_id': 'http://arxiv.org/abs/2407.21059v1',\n",
              " 'published_first_time': '2024-07-26',\n",
              " 'comment': None,\n",
              " 'journal_ref': None,\n",
              " 'doi': None,\n",
              " 'primary_category': 'cs.CL',\n",
              " 'categories': ['cs.CL', 'cs.AI', 'cs.IR'],\n",
              " 'links': ['http://arxiv.org/abs/2407.21059v1',\n",
              "  'http://arxiv.org/pdf/2407.21059v1']}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# metadata of Arxiv\n",
        "arxiv_search_results[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9c4563b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "Modular RAG: Transforming RAG Systems into\n",
            "LEGO-like Reconfigurable Frameworks\n",
            "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
            "Abstract—Retrieval-augmented\n",
            "Generation\n",
            "(RAG)\n",
            "has\n",
            "markedly enhanced the capabilities of Large Language Models\n",
            "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
            "demands of application scenarios have driven the evolution\n",
            "of RAG, leading to the integration of advanced retrievers,\n",
            "LLMs and other complementary technologies, which in turn\n",
            "has amplified the intricacy of RAG systems. However, the rapid\n",
            "advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process\n",
            "of “retrieve-then-generate”. In this context, this paper examines\n",
            "the limitations of the existing RAG paradigm and introduces\n",
            "the modular RAG framework. By decomposing complex RAG\n",
            "systems into independent modules and specialized operators, it\n",
            "facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a\n",
            "more advanced design that integrates routing, scheduling, and\n",
            "fusion mechanisms. Drawing on extensive research, this paper\n",
            "further identifies prevalent RAG patterns—linear, conditional,\n",
            "branching, and looping—and offers a comprehensive analysis\n",
            "of their respective implementation nuances. Modular RAG\n",
            "presents\n",
            "innovative\n",
            "opportunities\n",
            "for\n",
            "the\n",
            "conceptualization\n",
            "and deployment of RAG systems. Finally, the paper explores\n",
            "the potential emergence of new operators and paradigms,\n",
            "establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment\n",
            "of RAG technologies.\n",
            "Index Terms—Retrieval-augmented generation, large language\n",
            "model, modular system, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE Language Models (LLMs) have demonstrated\n",
            "remarkable capabilities, yet they still face numerous\n",
            "challenges, such as hallucination and the lag in information up-\n",
            "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
            "ing external knowledge bases, provides LLMs with important\n",
            "contextual information, significantly enhancing their perfor-\n",
            "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
            "an enhancement method, has been widely applied in various\n",
            "practical application scenarios, including knowledge question\n",
            "answering, recommendation systems, customer service, and\n",
            "personal assistants. [3]–[6]\n",
            "During the nascent stages of RAG , its core framework is\n",
            "constituted by indexing, retrieval, and generation, a paradigm\n",
            "referred to as Naive RAG [7]. However, as the complexity\n",
            "of tasks and the demands of applications have escalated, the\n",
            "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
            "Systems, Tongji University, Shanghai, 201210, China.\n",
            "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
            "Computer Science, Fudan University, Shanghai, 200438, China.\n",
            "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
            "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
            "Wang. E-mail: carter.whfcarter@gmail.com)\n",
            "limitations of Naive RAG have become increasingly apparent.\n",
            "As depicted in Figure 1, it predominantly hinges on the\n",
            "straightforward similarity of chunks, result in poor perfor-\n",
            "mance when confronted with complex queries and chunks with\n",
            "substantial variability. The primary challenges of Naive RAG\n",
            "include: 1) Shallow Understanding of Queries. The semantic\n",
            "similarity between a query and document chunk is not always\n",
            "highly consistent. Relying solely on similarity calculations\n",
            "for retrieval lacks an in-depth exploration of the relationship\n",
            "between the query and the document [8]. 2) Retrieval Re-\n",
            "dundancy and Noise. Feeding all retrieved chunks directly\n",
            "into LLMs is not always beneficial. Research indicates that\n",
            "an excess of redundant and noisy information may interfere\n",
            "with the LLM’s identification of key information, thereby\n",
            "increasing the risk of generating erroneous and hallucinated\n",
            "responses. [9]\n",
            "To overcome the aforementioned limitations, \n"
          ]
        }
      ],
      "source": [
        "# content of Arxiv\n",
        "print(arxiv_search_results[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "088a306d",
      "metadata": {},
      "source": [
        " format and display Arxiv search results in a structured XML-like format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4894dbc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 문서 검색 결과를 포맷팅\n",
        "formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
        "    [\n",
        "        f'<Document source=\"{doc.metadata[\"entry_id\"]}\" date=\"{doc.metadata.get(\"Published\", \"\")}\" authors=\"{doc.metadata.get(\"Authors\", \"\")}\"/>\\n<Title>\\n{doc.metadata[\"Title\"]}\\n</Title>\\n\\n<Summary>\\n{doc.metadata[\"Summary\"]}\\n</Summary>\\n\\n<Content>\\n{doc.page_content}\\n</Content>\\n</Document>'\n",
        "        for doc in arxiv_search_results\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "143d6b5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
            "<Title>\n",
            "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
            "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
            "increasing demands of application scenarios have driven the evolution of RAG,\n",
            "leading to the integration of advanced retrievers, LLMs and other complementary\n",
            "technologies, which in turn has amplified the intricacy of RAG systems.\n",
            "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process of\n",
            "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
            "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
            "decomposing complex RAG systems into independent modules and specialized\n",
            "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a more advanced\n",
            "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
            "extensive research, this paper further identifies prevalent RAG\n",
            "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
            "analysis of their respective implementation nuances. Modular RAG presents\n",
            "innovative opportunities for the conceptualization and deployment of RAG\n",
            "systems. Finally, the paper explores the potential emergence of new operators\n",
            "and paradigms, establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment of RAG\n",
            "technologies.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "1\n",
            "Modular RAG: Transforming RAG Systems into\n",
            "LEGO-like Reconfigurable Frameworks\n",
            "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
            "Abstract—Retrieval-augmented\n",
            "Generation\n",
            "(RAG)\n",
            "has\n",
            "markedly enhanced the capabilities of Large Language Models\n",
            "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
            "demands of application scenarios have driven the evolution\n",
            "of RAG, leading to the integration of advanced retrievers,\n",
            "LLMs and other complementary technologies, which in turn\n",
            "has amplified the intricacy of RAG systems. However, the rapid\n",
            "advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process\n",
            "of “retrieve-then-generate”. In this context, this paper examines\n",
            "the limitations of the existing RAG paradigm and introduces\n",
            "the modular RAG framework. By decomposing complex RAG\n",
            "systems into independent modules and specialized operators, it\n",
            "facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a\n",
            "more advanced design that integrates routing, scheduling, and\n",
            "fusion mechanisms. Drawing on extensive research, this paper\n",
            "further identifies prevalent RAG patterns—linear, conditional,\n",
            "branching, and looping—and offers a comprehensive analysis\n",
            "of their respective implementation nuances. Modular RAG\n",
            "presents\n",
            "innovative\n",
            "opportunities\n",
            "for\n",
            "the\n",
            "conceptualization\n",
            "and deployment of RAG systems. Finally, the paper explores\n",
            "the potential emergence of new operators and paradigms,\n",
            "establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment\n",
            "of RAG technologies.\n",
            "Index Terms—Retrieval-augmented generation, large language\n",
            "model, modular system, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE Language Models (LLMs) have demonstrated\n",
            "remarkable capabilities, yet they still face numerous\n",
            "challenges, such as hallucination and the lag in information up-\n",
            "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
            "ing external knowledge bases, provides LLMs with important\n",
            "contextual information, significantly enhancing their perfor-\n",
            "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
            "an enhancement method, has been widely applied in various\n",
            "practical application scenarios, including knowledge question\n",
            "answering, recommendation systems, customer service, and\n",
            "personal assistants. [3]–[6]\n",
            "During the nascent stages of RAG , its core framework is\n",
            "constituted by indexing, retrieval, and generation, a paradigm\n",
            "referred to as Naive RAG [7]. However, as the complexity\n",
            "of tasks and the demands of applications have escalated, the\n",
            "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
            "Systems, Tongji University, Shanghai, 201210, China.\n",
            "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
            "Computer Science, Fudan University, Shanghai, 200438, China.\n",
            "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
            "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
            "Wang. E-mail: carter.whfcarter@gmail.com)\n",
            "limitations of Naive RAG have become increasingly apparent.\n",
            "As depicted in Figure 1, it predominantly hinges on the\n",
            "straightforward similarity of chunks, result in poor perfor-\n",
            "mance when confronted with complex queries and chunks with\n",
            "substantial variability. The primary challenges of Naive RAG\n",
            "include: 1) Shallow Understanding of Queries. The semantic\n",
            "similarity between a query and document chunk is not always\n",
            "highly consistent. Relying solely on similarity calculations\n",
            "for retrieval lacks an in-depth exploration of the relationship\n",
            "between the query and the document [8]. 2) Retrieval Re-\n",
            "dundancy and Noise. Feeding all retrieved chunks directly\n",
            "into LLMs is not always beneficial. Research indicates that\n",
            "an excess of redundant and noisy information may interfere\n",
            "with the LLM’s identification of key information, thereby\n",
            "increasing the risk of generating erroneous and hallucinated\n",
            "responses. [9]\n",
            "To overcome the aforementioned limitations, \n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2312.10997v5\" date=\"2024-03-27\" authors=\"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang\"/>\n",
            "<Title>\n",
            "Retrieval-Augmented Generation for Large Language Models: A Survey\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Large Language Models (LLMs) showcase impressive capabilities but encounter\n",
            "challenges like hallucination, outdated knowledge, and non-transparent,\n",
            "untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\n",
            "emerged as a promising solution by incorporating knowledge from external\n",
            "databases. This enhances the accuracy and credibility of the generation,\n",
            "particularly for knowledge-intensive tasks, and allows for continuous knowledge\n",
            "updates and integration of domain-specific information. RAG synergistically\n",
            "merges LLMs' intrinsic knowledge with the vast, dynamic repositories of\n",
            "external databases. This comprehensive review paper offers a detailed\n",
            "examination of the progression of RAG paradigms, encompassing the Naive RAG,\n",
            "the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\n",
            "tripartite foundation of RAG frameworks, which includes the retrieval, the\n",
            "generation and the augmentation techniques. The paper highlights the\n",
            "state-of-the-art technologies embedded in each of these critical components,\n",
            "providing a profound understanding of the advancements in RAG systems.\n",
            "Furthermore, this paper introduces up-to-date evaluation framework and\n",
            "benchmark. At the end, this article delineates the challenges currently faced\n",
            "and points out prospective avenues for research and development.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "1\n",
            "Retrieval-Augmented Generation for Large\n",
            "Language Models: A Survey\n",
            "Yunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\n",
            "Wangc, and Haofen Wang a,c\n",
            "aShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n",
            "bShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n",
            "cCollege of Design and Innovation, Tongji University\n",
            "Abstract—Large Language Models (LLMs) showcase impres-\n",
            "sive capabilities but encounter challenges like hallucination,\n",
            "outdated knowledge, and non-transparent, untraceable reasoning\n",
            "processes. Retrieval-Augmented Generation (RAG) has emerged\n",
            "as a promising solution by incorporating knowledge from external\n",
            "databases. This enhances the accuracy and credibility of the\n",
            "generation, particularly for knowledge-intensive tasks, and allows\n",
            "for continuous knowledge updates and integration of domain-\n",
            "specific information. RAG synergistically merges LLMs’ intrin-\n",
            "sic knowledge with the vast, dynamic repositories of external\n",
            "databases. This comprehensive review paper offers a detailed\n",
            "examination of the progression of RAG paradigms, encompassing\n",
            "the Naive RAG, the Advanced RAG, and the Modular RAG.\n",
            "It meticulously scrutinizes the tripartite foundation of RAG\n",
            "frameworks, which includes the retrieval, the generation and the\n",
            "augmentation techniques. The paper highlights the state-of-the-\n",
            "art technologies embedded in each of these critical components,\n",
            "providing a profound understanding of the advancements in RAG\n",
            "systems. Furthermore, this paper introduces up-to-date evalua-\n",
            "tion framework and benchmark. At the end, this article delineates\n",
            "the challenges currently faced and points out prospective avenues\n",
            "for research and development 1.\n",
            "Index Terms—Large language model, retrieval-augmented gen-\n",
            "eration, natural language processing, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE language models (LLMs) have achieved remark-\n",
            "able success, though they still face significant limitations,\n",
            "especially in domain-specific or knowledge-intensive tasks [1],\n",
            "notably producing “hallucinations” [2] when handling queries\n",
            "beyond their training data or requiring current information. To\n",
            "overcome challenges, Retrieval-Augmented Generation (RAG)\n",
            "enhances LLMs by retrieving relevant document chunks from\n",
            "external knowledge base through semantic similarity calcu-\n",
            "lation. By referencing external knowledge, RAG effectively\n",
            "reduces the problem of generating factually incorrect content.\n",
            "Its integration into LLMs has resulted in widespread adoption,\n",
            "establishing RAG as a key technology in advancing chatbots\n",
            "and enhancing the suitability of LLMs for real-world applica-\n",
            "tions.\n",
            "RAG technology has rapidly developed in recent years, and\n",
            "the technology tree summarizing related research is shown\n",
            "Corresponding Author.Email:haofen.wang@tongji.edu.cn\n",
            "1Resources\n",
            "are\n",
            "available\n",
            "at\n",
            "https://github.com/Tongji-KGLLM/\n",
            "RAG-Survey\n",
            "in Figure 1. The development trajectory of RAG in the era\n",
            "of large models exhibits several distinct stage characteristics.\n",
            "Initially, RAG’s inception coincided with the rise of the\n",
            "Transformer architecture, focusing on enhancing language\n",
            "models by incorporating additional knowledge through Pre-\n",
            "Training Models (PTM). This early stage was characterized\n",
            "by foundational work aimed at refining pre-training techniques\n",
            "[3]–[5].The subsequent arrival of ChatGPT [6] marked a\n",
            "pivotal moment, with LLM demonstrating powerful in context\n",
            "learning (ICL) capabilities. RAG research shifted towards\n",
            "providing better information for LLMs to answer more com-\n",
            "plex and knowledge-intensive tasks during the inference stage,\n",
            "leading to rapid development in RAG studies. As research\n",
            "progressed, the enhancement of RAG was no longer limited\n",
            "to the inference stage but began to incorporate more with LLM\n",
            "fine-tuning techniques.\n",
            "The burgeoning field of RAG has experienced swift growth,\n",
            "yet it has not been accompanied by a systematic synthesis that\n",
            "could clarify its broader trajectory. Thi\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2410.20753v2\" date=\"2025-02-04\" authors=\"Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma\"/>\n",
            "<Title>\n",
            "Plan*RAG: Efficient Test-Time Planning for Retrieval Augmented Generation\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "We introduce Plan*RAG, a novel framework that enables structured multi-hop\n",
            "reasoning in retrieval-augmented generation (RAG) through test-time reasoning\n",
            "plan generation. While existing approaches such as ReAct maintain reasoning\n",
            "chains within the language model's context window, we observe that this often\n",
            "leads to plan fragmentation and execution failures. Our key insight is that by\n",
            "isolating the reasoning plan as a directed acyclic graph (DAG) outside the LM's\n",
            "working memory, we can enable (1) systematic exploration of reasoning paths,\n",
            "(2) atomic subqueries enabling precise retrievals and grounding, and (3)\n",
            "efficiency through parallel execution and bounded context window utilization.\n",
            "Moreover, Plan*RAG's modular design allows it to be integrated with existing\n",
            "RAG methods, thus providing a practical solution to improve current RAG\n",
            "systems. On standard multi-hop reasoning benchmarks, Plan*RAG consistently\n",
            "achieves improvements over recently proposed methods such as RQ-RAG and\n",
            "Self-RAG, while maintaining comparable computational costs.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "Plan∗RAG: Efficient Test-Time Planning for Retrieval Augmented Generation\n",
            "Prakhar Verma † 1 Sukruta Prakash Midigeshi 2 Gaurav Sinha 2 Arno Solin 1\n",
            "Nagarajan Natarajan 2 Amit Sharma 2\n",
            "Abstract\n",
            "We introduce Plan∗RAG, a novel framework\n",
            "that enables structured multi-hop reasoning in\n",
            "retrieval-augmented generation (RAG) through\n",
            "test-time reasoning plan generation. While exist-\n",
            "ing approaches such as ReAct maintain reason-\n",
            "ing chains within the language model’s context\n",
            "window, we observe that this often leads to plan\n",
            "fragmentation and execution failures. Our key\n",
            "insight is that by isolating the reasoning plan as\n",
            "a directed acyclic graph (DAG) outside the LM’s\n",
            "working memory, we can enable (1) systematic\n",
            "exploration of reasoning paths, (2) atomic sub-\n",
            "queries enabling precise retrievals and ground-\n",
            "ing, and (3) efficiency through parallel execution\n",
            "and bounded context window utilization. More-\n",
            "over, Plan∗RAG’s modular design allows it to\n",
            "be integrated with existing RAG methods, thus\n",
            "providing a practical solution to improve current\n",
            "RAG systems. On standard multi-hop reasoning\n",
            "benchmarks, Plan∗RAG consistently achieves im-\n",
            "provements over recently proposed methods such\n",
            "as RQ-RAG and Self-RAG, while maintaining\n",
            "comparable computational costs.\n",
            "1. Introduction\n",
            "Retrieval-Augmented Generation (RAG, Lewis et al., 2020;\n",
            "Petroni et al., 2020; Guu et al., 2020) has emerged as a\n",
            "promising approach for grounding language model (LM)\n",
            "responses in external knowledge. However, RAG systems\n",
            "struggle with multi-hop queries that require reasoning across\n",
            "multiple retrieved documents (Tang & Yang, 2024; Wei\n",
            "et al., 2022). A key challenge lies in the initial retrieval step,\n",
            "which often fails to retrieve sufficient relevant documents\n",
            "due to the query’s lack of full contextual information (Ma\n",
            "et al., 2023). This limitation has been highlighted in recent\n",
            "surveys (Torfi et al., 2020; Zhao et al., 2023) as a funda-\n",
            "† Work done during an internship with Microsoft Research.\n",
            "1Aalto University, Finland 2Microsoft Research. Correspondence\n",
            "to: <prakhar.verma@aalto.fi>, <amshar@microsoft.com>.\n",
            "RAG\n",
            "Self-RAG\n",
            "ReAct\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n",
            "45\n",
            "Test-time planning improves RAG\n",
            "25.51\n",
            "34.09\n",
            "33.15\n",
            "31.12\n",
            "37.31\n",
            "40.44\n",
            "Accuracy (%)\n",
            "Vanilla\n",
            "With Plan∗\n",
            "Figure 1. Plan∗RAG improves performance on the HotpotQA\n",
            "benchmark substantially compared to various existing RAG meth-\n",
            "ods, demonstrating the value of externalizing planning as a directed\n",
            "acyclic graph (DAG) outside of the LLM’s context.\n",
            "mental barrier to reliable AI systems, particularly given the\n",
            "widespread deployment of large language models (Brown\n",
            "et al., 2020) across critical domains. Consider the query:\n",
            "“Rumble Fish was a novel by the author of the coming-of-age\n",
            "novel published in what year by Viking Press?” Answering\n",
            "this requires an iterative retrieval process: identifying the\n",
            "Rumble Fish’s author, connecting to their coming-of-age\n",
            "novel, and determining its publication year. Single-step\n",
            "retrieval in RAG systems often fails in such cases, as it\n",
            "may retrieve documents about Rumble Fish’s author and\n",
            "Viking Press without recognizing the intermediate fact—\n",
            "the author’s coming-of-age novel—must first be established.\n",
            "Furthermore, Leng et al. (2024); Shuster et al. (2021) demon-\n",
            "strate that even when relevant documents are retrieved, LMs\n",
            "struggle to reason across them due to fixed context win-\n",
            "dows, leading to information loss and broken reasoning\n",
            "chain. These limitations pose risks in critical domains such\n",
            "as healthcare and finance (Pal et al., 2023; Zhao et al., 2024),\n",
            "where accurate multi-step reasoning is essential.\n",
            "Recent research has attempted to address these limita-\n",
            "tions through structured reasoning frameworks. Chain-of-\n",
            "Thought (CoT) prompting (Wei et al., 2022) and systematic\n",
            "query decomposition (Patel et al., 2022) have introduced\n",
            "explicit reasoning steps, enabling more granular thought\n",
            "processes and targeted retrievals. Building upon these foun-\n",
            "dations, Yao et al. (2023) proposed ReAct—a framework\n",
            "that creates a reasoning chain \n",
            "</Content>\n",
            "</Document>\n"
          ]
        }
      ],
      "source": [
        "print(formatted_search_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "678568f9",
      "metadata": {},
      "source": [
        "### Defining Search Tool Nodes\n",
        "\n",
        "The code implements two main search tool nodes for gathering research information: web search via `Tavily` and academic paper search via `ArXiv`. Here's a breakdown of the key components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "621173b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "# Search query instruction\n",
        "search_instructions = SystemMessage(\n",
        "    content=f\"\"\"You will be given a conversation between an analyst and an expert. \n",
        "\n",
        "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
        "        \n",
        "First, analyze the full conversation.\n",
        "\n",
        "Pay particular attention to the final question posed by the analyst.\n",
        "\n",
        "Convert this final question into a well-structured web search query\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "def search_web(state: InterviewState):\n",
        "    \"\"\"Performs web search using Tavily\"\"\"\n",
        "\n",
        "    # Generate search query\n",
        "    structured_llm = llm.with_structured_output(SearchQuery)\n",
        "    search_query = structured_llm.invoke([search_instructions] + state[\"messages\"])\n",
        "\n",
        "    # Execute search\n",
        "    search_docs = tavily_search.invoke(search_query.search_query)\n",
        "\n",
        "    # Format results - handle both string and dict responses\n",
        "    if isinstance(search_docs, list):\n",
        "        formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
        "            [\n",
        "                f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
        "                for doc in search_docs\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    return {\"context\": [formatted_search_docs]}\n",
        "\n",
        "\n",
        "def search_arxiv(state: InterviewState):\n",
        "    \"\"\"Performs academic paper search using ArXiv\"\"\"\n",
        "\n",
        "    # Generate search query\n",
        "    structured_llm = llm.with_structured_output(SearchQuery)\n",
        "    search_query = structured_llm.invoke([search_instructions] + state[\"messages\"])\n",
        "\n",
        "    try:\n",
        "        # Execute search\n",
        "        arxiv_search_results = arxiv_retriever.invoke(\n",
        "            search_query.search_query,\n",
        "            load_max_docs=2,\n",
        "            load_all_available_meta=True,\n",
        "            get_full_documents=True,\n",
        "        )\n",
        "\n",
        "        # Format results\n",
        "        formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
        "            [\n",
        "                f'<Document source=\"{doc.metadata[\"entry_id\"]}\" date=\"{doc.metadata.get(\"Published\", \"\")}\" authors=\"{doc.metadata.get(\"Authors\", \"\")}\"/>\\n<Title>\\n{doc.metadata[\"Title\"]}\\n</Title>\\n\\n<Summary>\\n{doc.metadata[\"Summary\"]}\\n</Summary>\\n\\n<Content>\\n{doc.page_content}\\n</Content>\\n</Document>'\n",
        "                for doc in arxiv_search_results\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return {\"context\": [formatted_search_docs]}\n",
        "    except Exception as e:\n",
        "        print(f\"ArXiv search error: {str(e)}\")\n",
        "        return {\"context\": [\"<Error>Failed to retrieve ArXiv search results.</Error>\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86155692",
      "metadata": {},
      "source": [
        "**Key Features**\n",
        "- Query Generation: Uses LLM to create structured search queries from conversation context\n",
        "- Error Handling: Robust error management for ArXiv searches\n",
        "- Result Formatting: Consistent XML-style formatting for both web and academic results\n",
        "- Metadata Integration: Comprehensive metadata inclusion for academic papers\n",
        "- State Management: Maintains conversation context through InterviewState"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e666219e",
      "metadata": {},
      "source": [
        "### Define `generate_answer`, `save_interview`, `route_messages`, `write_section` Nodes\n",
        "\n",
        "- The `generate_answer` node is responsible for creating expert responses during the interview process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4509e48e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import get_buffer_string\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "\n",
        "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
        "\n",
        "Here is analyst area of focus: {goals}. \n",
        "        \n",
        "You goal is to answer a question posed by the interviewer.\n",
        "\n",
        "To answer question, use this context:\n",
        "        \n",
        "{context}\n",
        "\n",
        "When answering questions, follow these guidelines:\n",
        "        \n",
        "1. Use only the information provided in the context. \n",
        "        \n",
        "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
        "\n",
        "3. The context contain sources at the topic of each individual document.\n",
        "\n",
        "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1]. \n",
        "\n",
        "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
        "        \n",
        "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list: \n",
        "        \n",
        "[1] assistant/docs/llama3_1.pdf, page 7 \n",
        "        \n",
        "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\"\n",
        "\n",
        "\n",
        "def generate_answer(state: InterviewState):\n",
        "    \"\"\"Generates expert responses to analyst questions\"\"\"\n",
        "\n",
        "    # Get analyst and messages from state\n",
        "    analyst = state[\"analyst\"]\n",
        "    messages = state[\"messages\"]\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    # Generate answer for the question\n",
        "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
        "    answer = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
        "\n",
        "    # Name the message as expert response\n",
        "    answer.name = \"expert\"\n",
        "\n",
        "    # Add message to state\n",
        "    return {\"messages\": [answer]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4d878d4",
      "metadata": {},
      "source": [
        "- `save_interview`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "42706ff4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_interview(state: InterviewState):\n",
        "    \"\"\"Saves the interview content\"\"\"\n",
        "\n",
        "    # Get messages from state\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Convert interview to string\n",
        "    interview = get_buffer_string(messages)\n",
        "\n",
        "    # Store under interview key\n",
        "    return {\"interview\": interview}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f8aa4df",
      "metadata": {},
      "source": [
        "### Define `generate_answer`, `save_interview`, `route_messages`, `write_section` Nodes\n",
        "- `route_messages`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "10bb1677",
      "metadata": {},
      "outputs": [],
      "source": [
        "def route_messages(state: InterviewState, name: str = \"expert\"):\n",
        "    \"\"\"Routes between questions and answers in the conversation\"\"\"\n",
        "\n",
        "    # Get messages from state\n",
        "    messages = state[\"messages\"]\n",
        "    max_num_turns = state.get(\"max_num_turns\", 2)\n",
        "\n",
        "    # Count expert responses\n",
        "    num_responses = len(\n",
        "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
        "    )\n",
        "\n",
        "    # End interview if maximum turns reached\n",
        "    if num_responses >= max_num_turns:\n",
        "        return \"save_interview\"\n",
        "\n",
        "    # This router runs after each question-answer pair\n",
        "    # Get the last question to check for conversation end signal\n",
        "    last_question = messages[-2]\n",
        "\n",
        "    # Check for conversation end signal\n",
        "    if \"Thank you so much for your help\" in last_question.content:\n",
        "        return \"save_interview\"\n",
        "    return \"ask_question\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfaaef36",
      "metadata": {},
      "source": [
        "- The `write_section` function and its associated instructions implement a structured report generation system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ca2e1be1",
      "metadata": {},
      "outputs": [],
      "source": [
        "section_writer_instructions = \"\"\"You are an expert technical writer. \n",
        "\n",
        "Your task is to create a detailed and comprehensive section of a report, thoroughly analyzing a set of source documents.\n",
        "This involves extracting key insights, elaborating on relevant points, and providing in-depth explanations to ensure clarity and understanding. Your writing should include necessary context, supporting evidence, and examples to enhance the reader's comprehension. Maintain a logical and well-organized structure, ensuring that all critical aspects are covered in detail and presented in a professional tone.\n",
        "\n",
        "Please follow these instructions:\n",
        "1. Analyze the content of the source documents: \n",
        "- The name of each source document is at the start of the document, with the <Document tag.\n",
        "        \n",
        "2. Create a report structure using markdown formatting:\n",
        "- Use ## for the section title\n",
        "- Use ### for sub-section headers\n",
        "        \n",
        "3. Write the report following this structure:\n",
        "a. Title (## header)\n",
        "b. Summary (### header)\n",
        "c. Comprehensive analysis (### header)\n",
        "d. Sources (### header)\n",
        "\n",
        "4. Make your title engaging based upon the focus area of the analyst: \n",
        "{focus}\n",
        "\n",
        "5. For the summary section:\n",
        "- Set up summary with general background / context related to the focus area of the analyst\n",
        "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
        "- Create a numbered list of source documents, as you use them\n",
        "- Do not mention the names of interviewers or experts\n",
        "- Aim for approximately 400 words maximum\n",
        "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
        "\n",
        "6. For the Comprehensive analysis section:\n",
        "- Provide a detailed examination of the information from the source documents.\n",
        "- Break down complex ideas into digestible segments, ensuring a logical flow of ideas.\n",
        "- Use sub-sections where necessary to cover multiple perspectives or dimensions of the analysis.\n",
        "- Support your analysis with data, direct quotes, and examples from the source documents.\n",
        "- Clearly explain the relevance of each point to the overall focus of the report.\n",
        "- Use bullet points or numbered lists for clarity when presenting multiple related ideas.\n",
        "- Ensure the tone remains professional and objective, avoiding bias or unsupported opinions.\n",
        "- Aim for at least 800 words to ensure the analysis is thorough.\n",
        "\n",
        "7. In the Sources section:\n",
        "- Include all sources used in your report\n",
        "- Provide full links to relevant websites or specific document paths\n",
        "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
        "- It will look like:\n",
        "\n",
        "### Sources\n",
        "[1] Link or Document name\n",
        "[2] Link or Document name\n",
        "\n",
        "8. Be sure to combine sources. For example this is not correct:\n",
        "\n",
        "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "\n",
        "There should be no redundant sources. It should simply be:\n",
        "\n",
        "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "        \n",
        "9. Final review:\n",
        "- Ensure the report follows the required structure\n",
        "- Include no preamble before the title of the report\n",
        "- Check that all guidelines have been followed\"\"\"\n",
        "\n",
        "\n",
        "def write_section(state: InterviewState):\n",
        "    \"\"\"Generates a structured report section based on interview content\"\"\"\n",
        "\n",
        "    # Get context and analyst from state\n",
        "    context = state[\"context\"]\n",
        "    analyst = state[\"analyst\"]\n",
        "\n",
        "    # Define system prompt for section writing\n",
        "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
        "    section = llm.invoke(\n",
        "        [\n",
        "            SystemMessage(content=system_message),\n",
        "            HumanMessage(content=f\"Use this source to write your section: {context}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Add section to state\n",
        "    return {\"sections\": [section.content]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc292ede",
      "metadata": {},
      "source": [
        "### Building the Interview Graph\n",
        "Here's how to create and configure the interview execution graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "343f74be",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Add nodes and edges\n",
        "interview_builder = StateGraph(InterviewState)\n",
        "\n",
        "# Define nodes\n",
        "interview_builder.add_node(\"ask_question\", generate_question)\n",
        "interview_builder.add_node(\"search_web\", search_web)\n",
        "interview_builder.add_node(\"search_arxiv\", search_arxiv)\n",
        "interview_builder.add_node(\"answer_question\", generate_answer)\n",
        "interview_builder.add_node(\"save_interview\", save_interview)\n",
        "interview_builder.add_node(\"write_section\", write_section)\n",
        "\n",
        "# Configure flow\n",
        "interview_builder.add_edge(START, \"ask_question\")\n",
        "interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
        "interview_builder.add_edge(\"ask_question\", \"search_arxiv\")\n",
        "interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
        "interview_builder.add_edge(\"search_arxiv\", \"answer_question\")\n",
        "interview_builder.add_conditional_edges(\n",
        "    \"answer_question\", route_messages, [\"ask_question\", \"save_interview\"]\n",
        ")\n",
        "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
        "interview_builder.add_edge(\"write_section\", END)\n",
        "\n",
        "# Create interview graph with memory\n",
        "memory = MemorySaver()\n",
        "interview_graph = interview_builder.compile(checkpointer=memory).with_config(\n",
        "    run_name=\"Conduct Interviews\"\n",
        ")\n",
        "\n",
        "# Visualize the graph\n",
        "visualize_graph(interview_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bf40202",
      "metadata": {},
      "source": [
        "**Graph Structure**\n",
        "\n",
        "The interview process follows this flow:\n",
        "1. Question Generation\n",
        "2. Parallel Search (Web and ArXiv)\n",
        "3. Answer Generation\n",
        "4. Conditional Routing\n",
        "5. Interview Saving\n",
        "6. Section Writing\n",
        "\n",
        "**Key Components**\n",
        "- State Management: Uses InterviewState for tracking\n",
        "- Memory Persistence: Implements MemorySaver\n",
        "- Conditional Logic: Routes between questions and interview completion\n",
        "- Parallel Processing: Conducts simultaneous web and academic searches\n",
        "\n",
        "Note: Ensure the langgraph module is installed before running this code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6c487bf",
      "metadata": {},
      "source": [
        "### Executing the Interview Graph\n",
        "Here's how to execute the graph and display the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cbced19b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Analyst(affiliation='AI Research Institute', name='Dr. Emily Carter', role='Research Scientist', description='Dr. Emily Carter focuses on the technical differences and advancements between Modular RAG and Naive RAG. Her interest is in how these models improve efficiency and accuracy in AI systems. She provides a deep dive into the underlying mechanisms and evaluates their potential for innovation in AI research.')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select first analyst from the list\n",
        "analysts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6377d8b5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello, I'm Alex, an analyst delving into the technical intricacies of AI models. Dr. Carter, could you please explain the fundamental differences between Modular RAG and Naive RAG? How do these differences impact the efficiency and accuracy of AI systems?\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_web\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
            "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. Modular RAG is an advanced form of Retrieval-Augmented Generation that leverages a modular design to separate and optimize various components of the system. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. Seamless Integration: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\"/>\n",
            "Retrieval-augmented generation (RAG) has emerged as a promising solution incorporating knowledge from external databases. RAG enhances LLMs by retrieving relevant document chunks from the external knowledge base through semantic similarity calculation. The Naive RAG follows a traditional process that includes indexing, retrieval, and generation, also characterized as a “Retrieve-Read” framework. Retrieval: Upon receipt of a user query, the RAG system employs the same encoding model utilized during the indexing phase to transform the query into a vector representation. RAG enhances LLMs by retrieving relevant document chunks from the external knowledge base through semantic similarity calculation. Naive RAG has several limitations, including Retrieval Challenges and Generation Difficulties.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\"/>\n",
            "Naive RAG established the groundwork for retrieval-augmented systems by combining document retrieval with language model generation. For example, in a question-answering task, RECALL ensures that a RAG system accurately incorporates all relevant points from retrieved documents into the generated answer. Vector databases play a crucial role in the operation of RAG systems, providing the infrastructure required for storing and retrieving high-dimensional embeddings of contextual information needed for LLMs. These embeddings capture the semantic and contextual meaning of unstructured data, enabling precise similarity searches that underpin the effectiveness of retrieval-augmented generation. By integrating retrieval into generation, RAG systems deliver more accurate and context-aware outputs, making them effective for applications requiring current or specialized knowledge.\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document source=\"http://arxiv.org/abs/2406.00944v2\" date=\"2024-10-17\" authors=\"Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng\"/>\n",
            "<Title>\n",
            "A Theory for Token-Level Harmonization in Retrieval-Augmented Generation\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance\n",
            "large language models (LLMs). Studies show that while RAG provides valuable\n",
            "external information (benefit), it may also mislead LLMs (detriment) with noisy\n",
            "or incorrect retrieved texts. Although many existing methods attempt to\n",
            "preserve benefit and avoid detriment, they lack a theoretical explanation for\n",
            "RAG. The benefit and detriment in the next token prediction of RAG remain a\n",
            "black box that cannot be quantified or compared in an explainable manner, so\n",
            "existing methods are data-driven, need additional utility evaluators or\n",
            "post-hoc. This paper takes the first step towards providing a theory to explain\n",
            "and trade off the benefit and detriment in RAG. First, we model RAG as the\n",
            "fusion between distribution of LLMs knowledge and distribution of retrieved\n",
            "texts. Then, we formalize the trade-off between the value of external knowledge\n",
            "(benefit) and its potential risk of misleading LLMs (detriment) in next token\n",
            "prediction of RAG by distribution difference in this fusion. Finally, we prove\n",
            "that the actual effect of RAG on the token, which is the comparison between\n",
            "benefit and detriment, can be predicted without any training or accessing the\n",
            "utility of retrieval. Based on our theory, we propose a practical novel method,\n",
            "Tok-RAG, which achieves collaborative generation between the pure LLM and RAG\n",
            "at token level to preserve benefit and avoid detriment. Experiments in\n",
            "real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\n",
            "effectiveness of our method and support our theoretical findings.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "A THEORY FOR TOKEN-LEVEL HARMONIZATION IN\n",
            "RETRIEVAL-AUGMENTED GENERATION\n",
            "Shicheng Xu\n",
            "Liang Pang∗Huawei Shen\n",
            "Xueqi Cheng\n",
            "CAS Key Laboratory of AI Safety, Institute of Computing Technology, CAS\n",
            "{xushicheng21s,pangliang,shenhuawei,cxq}@ict.ac.cn\n",
            "ABSTRACT\n",
            "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance large\n",
            "language models (LLMs). Studies show that while RAG provides valuable external\n",
            "information (benefit), it may also mislead LLMs (detriment) with noisy or incorrect\n",
            "retrieved texts. Although many existing methods attempt to preserve benefit and\n",
            "avoid detriment, they lack a theoretical explanation for RAG. The benefit and\n",
            "detriment in the next token prediction of RAG remain a ’black box’ that cannot\n",
            "be quantified or compared in an explainable manner, so existing methods are data-\n",
            "driven, need additional utility evaluators or post-hoc. This paper takes the first step\n",
            "towards providing a theory to explain and trade off the benefit and detriment in\n",
            "RAG. First, we model RAG as the fusion between distribution of LLM’s knowledge\n",
            "and distribution of retrieved texts. Then, we formalize the trade-off between the\n",
            "value of external knowledge (benefit) and its potential risk of misleading LLMs\n",
            "(detriment) in next token prediction of RAG by distribution difference in this\n",
            "fusion. Finally, we prove that the actual effect of RAG on the token, which is the\n",
            "comparison between benefit and detriment, can be predicted without any training or\n",
            "accessing the utility of retrieval. Based on our theory, we propose a practical novel\n",
            "method, Tok-RAG, which achieves collaborative generation between the pure\n",
            "LLM and RAG at token level to preserve benefit and avoid detriment. Experiments\n",
            "in real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\n",
            "effectiveness of our method and support our theoretical findings.\n",
            "1\n",
            "INTRODUCTION\n",
            "Retrieval-augmented generation (RAG) has shown promising performance in enhancing Large\n",
            "Language Models (LLMs) by integrating retrieved texts (Xu et al., 2023; Shi et al., 2023; Asai et al.,\n",
            "2023; Ram et al., 2023). Studies indicate that while RAG provides LLMs with valuable additional\n",
            "knowledge (benefit), it also poses a risk of misleading them (detriment) due to noisy or incorrect\n",
            "retrieved texts (Ram et al., 2023; Xu et al., 2024b;a; Jin et al., 2024a; Xie et al., 2023; Jin et al.,\n",
            "2024b). Existing methods attempt to preserve benefit and avoid detriment by adding utility evaluators\n",
            "for retrieval, prompt engineering, or fine-tuning LLMs (Asai et al., 2023; Ding et al., 2024; Xu et al.,\n",
            "2024b; Yoran et al., 2024; Ren et al., 2023; Feng et al., 2023; Mallen et al., 2022; Jiang et al., 2023).\n",
            "However, existing methods are data-driven, need evaluator for utility of retrieved texts or post-hoc. A\n",
            "theory-based method, focusing on core principles of RAG is urgently needed, which is crucial for\n",
            "consistent and reliable improvements without relying on additional training or utility evaluators and\n",
            "improving our understanding for RAG.\n",
            "This paper takes the first step in providing a theoretical framework to explain and trade off the benefit\n",
            "and detriment at token level in RAG and proposes a novel method to preserve benefit and avoid\n",
            "detriment based on our theoretical findings. Specifically, this paper pioneers in modeling next token\n",
            "prediction in RAG as the fusion between the distribution of LLM’s knowledge and the distribution\n",
            "of retrieved texts as shown in Figure 1. Our theoretical derivation based on this formalizes the core\n",
            "of this fusion as the subtraction between two terms measured by the distribution difference: one is\n",
            "distribution completion and the other is distribution contradiction. Further analysis indicates that\n",
            "the distribution completion measures how much out-of-distribution knowledge that retrieved texts\n",
            "∗Corresponding author\n",
            "1\n",
            "arXiv:2406.00944v2  [cs.CL]  17 Oct 2024\n",
            "Query\n",
            "Wole\n",
            "Query\n",
            "Ernst\n",
            "Soyinka\n",
            "…\n",
            "LLM’s \n",
            "Distribution\n",
            "Retrieved \n",
            "Distribution \n",
            "Fusion\n",
            "Distribution\n",
            "Difference\n",
            "Olanipekun\n",
            "LLM’s \n",
            "Dis\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2501.15098v1\" date=\"2025-01-25\" authors=\"Zihang Li, Yangdong Ruan, Wenjun Liu, Zhengyang Wang, Tong Yang\"/>\n",
            "<Title>\n",
            "CFT-RAG: An Entity Tree Based Retrieval Augmented Generation Algorithm With Cuckoo Filter\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Although retrieval-augmented generation(RAG) significantly improves\n",
            "generation quality by retrieving external knowledge bases and integrating\n",
            "generated content, it faces computational efficiency bottlenecks, particularly\n",
            "in knowledge retrieval tasks involving hierarchical structures for Tree-RAG.\n",
            "This paper proposes a Tree-RAG acceleration method based on the improved Cuckoo\n",
            "Filter, which optimizes entity localization during the retrieval process to\n",
            "achieve significant performance improvements. Tree-RAG effectively organizes\n",
            "entities through the introduction of a hierarchical tree structure, while the\n",
            "Cuckoo Filter serves as an efficient data structure that supports rapid\n",
            "membership queries and dynamic updates. The experiment results demonstrate that\n",
            "our method is much faster than naive Tree-RAG while maintaining high levels of\n",
            "generative quality. When the number of trees is large, our method is hundreds\n",
            "of times faster than naive Tree-RAG. Our work is available at\n",
            "https://github.com/TUPYP7180/CFT-RAG-2025.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "CFT-RAG: An Entity Tree Based Retrieval Augmented Generation Algorithm\n",
            "With Cuckoo Filter\n",
            "Zihang Li 1 Yangdong Ruan 2 Wenjun Liu 3 Zhengyang Wang 4 Tong Yang 5\n",
            "Abstract\n",
            "Although retrieval-augmented generation(RAG)\n",
            "significantly improves generation quality by re-\n",
            "trieving external knowledge bases and integrat-\n",
            "ing generated content, it faces computational effi-\n",
            "ciency bottlenecks, particularly in knowledge re-\n",
            "trieval tasks involving hierarchical structures for\n",
            "Tree-RAG. This paper proposes a Tree-RAG ac-\n",
            "celeration method based on the improved Cuckoo\n",
            "Filter, which optimizes entity localization dur-\n",
            "ing the retrieval process to achieve significant\n",
            "performance improvements.\n",
            "Tree-RAG effec-\n",
            "tively organizes entities through the introduc-\n",
            "tion of a hierarchical tree structure, while the\n",
            "Cuckoo Filter serves as an efficient data struc-\n",
            "ture that supports rapid membership queries\n",
            "and dynamic updates. The experiment results\n",
            "demonstrate that our method is much faster than\n",
            "naive Tree-RAG while maintaining high lev-\n",
            "els of generative quality.\n",
            "When the number\n",
            "of trees is large, our method is hundreds of\n",
            "times faster than naive Tree-RAG. Our work is\n",
            "available at https://github.com/TUPYP7180/CFT-\n",
            "RAG-2025.\n",
            "1. Introduction\n",
            "In the era of information explosion, Retrieval-Augmented\n",
            "Generation (RAG), a technology integrating retrieval\n",
            "mechanisms with generative models, has gained significant\n",
            "attention. It allows models to draw on external knowledge\n",
            "bases during text generation, effectively overcoming the\n",
            "limitations of traditional generative models in knowledge-\n",
            "intensive tasks (Lewis et al., 2020). The knowledge base, a\n",
            "vital part of the RAG system, stores a wealth of structured\n",
            "and unstructured knowledge, acting as the main source\n",
            "of external information for the model. However, with the\n",
            "1Peking University\n",
            "2Beihang University\n",
            "3Peking Univer-\n",
            "sity 4Peking University 5Peking University.\n",
            "Correspondence\n",
            "to:\n",
            "Tong Yang <yangtong@pku.edu.cn>, Zihang Li <liz-\n",
            "ihang@stu.pku.edu.cn>.\n",
            "Preprint.\n",
            "continuous expansion of the knowledge base and the rapid\n",
            "pace of knowledge update, the challenge of efficiently\n",
            "retrieving relevant and accurate information from it has\n",
            "become a major obstacle to improving the performance of\n",
            "RAG system. Enhancing the retrieval speed and accuracy\n",
            "of the knowledge base is crucial for boosting the overall\n",
            "performance of the RAG system. Faster and more accurate\n",
            "retrieval enables the model to access relevant knowledge\n",
            "promptly, improving response speed and the quality of\n",
            "generated content. In contrast, inefficient or inaccurate\n",
            "retrieval can result in incorrect or irrelevant outputs,\n",
            "degrading user experience and system usability. Therefore,\n",
            "exploring ways to optimize the knowledge base retrieval\n",
            "mechanism is of great theoretical and practical importance,\n",
            "and this paper will focus on this key issue.\n",
            "Knowledge\n",
            "bases\n",
            "in\n",
            "Retrieval-Augmented\n",
            "Genera-\n",
            "tion (RAG) systems are mainly of three types: text-based,\n",
            "graph-based, and tree-based.\n",
            "Text-based ones store\n",
            "information as text, easy to manage but slow in retrieval due\n",
            "to complex language processing. Graph-based knowledge\n",
            "bases represent knowledge as graphs, excelling in handling\n",
            "complex relationships with relatively fast retrieval for\n",
            "certain queries, thanks to graph neural networks. Tree-\n",
            "based knowledge bases structure knowledge hierarchically.\n",
            "Despite text-based and graph-based knowledge bases\n",
            "having made good progress, the retrieval speed of all three\n",
            "types, especially tree-based ones, needs improvement.\n",
            "For RAG systems to provide faster and more accurate\n",
            "responses, optimizing retrieval from these knowledge bases,\n",
            "particularly tree-RAG, is a key research challenge.\n",
            "Tree-RAG, an extension of RAG, improves on tradi-\n",
            "tional RAG frameworks by using a hierarchical tree\n",
            "structure to organize the retrieved knowledge, thus pro-\n",
            "viding richer context and capturing complex relationships\n",
            "among entities.\n",
            "In Tree-RAG, entities are arranged\n",
            "hierarchically, allowing the retrieval process to more\n",
            "effec\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2410.13085v1\" date=\"2024-10-16\" authors=\"Peng Xia, Kangyu Zhu, Haoran Li, Tianze Wang, Weijia Shi, Sheng Wang, Linjun Zhang, James Zou, Huaxiu Yao\"/>\n",
            "<Title>\n",
            "MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Artificial Intelligence (AI) has demonstrated significant potential in\n",
            "healthcare, particularly in disease diagnosis and treatment planning. Recent\n",
            "progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new\n",
            "possibilities for interactive diagnostic tools. However, these models often\n",
            "suffer from factual hallucination, which can lead to incorrect diagnoses.\n",
            "Fine-tuning and retrieval-augmented generation (RAG) have emerged as methods to\n",
            "address these issues. However, the amount of high-quality data and distribution\n",
            "shifts between training data and deployment data limit the application of\n",
            "fine-tuning methods. Although RAG is lightweight and effective, existing\n",
            "RAG-based approaches are not sufficiently general to different medical domains\n",
            "and can potentially cause misalignment issues, both between modalities and\n",
            "between the model and the ground truth. In this paper, we propose a versatile\n",
            "multimodal RAG system, MMed-RAG, designed to enhance the factuality of\n",
            "Med-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an\n",
            "adaptive retrieved contexts selection method, and a provable RAG-based\n",
            "preference fine-tuning strategy. These innovations make the RAG process\n",
            "sufficiently general and reliable, significantly improving alignment when\n",
            "introducing retrieved contexts. Experimental results across five medical\n",
            "datasets (involving radiology, ophthalmology, pathology) on medical VQA and\n",
            "report generation demonstrate that MMed-RAG can achieve an average improvement\n",
            "of 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available\n",
            "in https://github.com/richard-peng-xia/MMed-RAG.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "Preprint.\n",
            "MMED-RAG: VERSATILE MULTIMODAL RAG SYS-\n",
            "TEM FOR MEDICAL VISION LANGUAGE MODELS\n",
            "Peng Xia1, Kangyu Zhu5, Haoran Li6, Tianze Wang3, Weijia Shi4, Sheng Wang4,\n",
            "Linjun Zhang3, James Zou2, Huaxiu Yao1\n",
            "1UNC-Chapel Hill, 2Stanford University, 3Rutgers University, 4University of Washington,\n",
            "5Brown University, 6PloyU\n",
            "{pxia,huaxiu}@cs.unc.edu\n",
            "ABSTRACT\n",
            "Artificial Intelligence (AI) has demonstrated significant potential in healthcare,\n",
            "particularly in disease diagnosis and treatment planning. Recent progress in Med-\n",
            "ical Large Vision-Language Models (Med-LVLMs) has opened up new possibil-\n",
            "ities for interactive diagnostic tools. However, these models often suffer from\n",
            "factual hallucination, which can lead to incorrect diagnoses.\n",
            "Fine-tuning and\n",
            "retrieval-augmented generation (RAG) have emerged as methods to address these\n",
            "issues. However, the amount of high-quality data and distribution shifts between\n",
            "training data and deployment data limit the application of fine-tuning methods.\n",
            "Although RAG is lightweight and effective, existing RAG-based approaches are\n",
            "not sufficiently general to different medical domains and can potentially cause\n",
            "misalignment issues, both between modalities and between the model and the\n",
            "ground truth.\n",
            "In this paper, we propose a versatile multimodal RAG system,\n",
            "MMed-RAG, designed to enhance the factuality of Med-LVLMs. Our approach\n",
            "introduces a domain-aware retrieval mechanism, an adaptive retrieved contexts se-\n",
            "lection method, and a provable RAG-based preference fine-tuning strategy. These\n",
            "innovations make the RAG process sufficiently general and reliable, significantly\n",
            "improving alignment when introducing retrieved contexts. Experimental results\n",
            "across five medical datasets (involving radiology, ophthalmology, pathology) on\n",
            "medical VQA and report generation demonstrate that MMed-RAG can achieve an\n",
            "average improvement of 43.8% in the factual accuracy of Med-LVLMs. Our data\n",
            "and code are available in https://github.com/richard-peng-xia/MMed-RAG.\n",
            "1\n",
            "INTRODUCTION\n",
            "Artificial Intelligence (AI) has already transformed healthcare and still has a lot of potential for\n",
            "further advancements (T˘aut¸an et al., 2021; Wang et al., 2019; Ye et al., 2021; Tu et al., 2024; Xia\n",
            "et al., 2024b; Hu et al., 2024a;b; Li et al., 2024). Recently, Medical Large Vision-Language Mod-\n",
            "els (Med-LVLMs) have shown great promise for advancing interactive and intelligent diagnosis (Li\n",
            "et al., 2023a; Moor et al., 2023; Zhang et al., 2023b; Wu et al., 2023b). Despite this potential (Li\n",
            "et al., 2023b; Wu et al., 2023a; Shi et al., 2024), current Med-LVLMs still face significant reliabil-\n",
            "ity issues, particularly their tendency to generate non-factual medical responses (Xia et al., 2024a;\n",
            "Royer et al., 2024; Chen et al., 2024a; Jiang et al., 2024), making them unreliable in critical medical\n",
            "applications. These factuality issues raise serious concerns when deploying such models in clinical\n",
            "settings, where even small diagnostic errors could lead to severe consequences for patient care.\n",
            "Recently, researchers have begun to focus on improving the factuality of Med-LVLMs through var-\n",
            "ious techniques, including fine-tuning (Li et al., 2023a; Moor et al., 2023; Thawkar et al., 2023;\n",
            "Zhang et al., 2023b; Chen et al., 2024b) and retrieval-augmented generation (RAG) (Xia et al.,\n",
            "2024c; He et al., 2024; Sun et al., 2024). Fine-tuning is a direct method to improve model per-\n",
            "formance, but it faces several limitations in the medical field. First, there is a lack of sufficient\n",
            "high-quality labeled data for fine-tuning in the medical domain. Additionally, a distribution gap\n",
            "often exists between the training data and the real-world deployment data (Schrouff et al., 2022),\n",
            "leading to significantly worse model performance during deployment. Hence, RAG has emerged\n",
            "as a viable alternative by providing external references during the inference stage, enhancing the\n",
            "factuality of Med-LVLMs (Wu et al., 2023c; Gao et al., 2023). However, despite its advantages, cur-\n",
            "rent RAG impl\n",
            "</Content>\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36manswer_question\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: expert\n",
            "\n",
            "Certainly, Dr. Carter. The key differences between Modular RAG and Naive RAG lie in their structural and operational approaches:\n",
            "\n",
            "1. **Structural Design**:\n",
            "   - **Naive RAG** operates as a monolithic entity. It follows a straightforward \"Retrieve-Read\" framework where relevant documents are retrieved from an external knowledge base and used directly to inform the generative process [3].\n",
            "   - **Modular RAG**, on the other hand, employs a modular design that separates the retrieval and generation processes into distinct, interchangeable modules. This modularity allows for seamless integration with various retrieval modules, enhancing the coherence and relevance of generated responses [3].\n",
            "\n",
            "2. **Flexibility and Optimization**:\n",
            "   - **Naive RAG** has a relatively static retrieval process, often leading to inefficiencies and suboptimal integration with the generative model [3].\n",
            "   - **Modular RAG** leverages its modular design to optimize various components of the system individually, allowing for more flexible and efficient operations [3].\n",
            "\n",
            "3. **Integration with Generative Models**:\n",
            "   - **Naive RAG's** integration between retrieval and generation is less dynamic, which can affect the quality of the output, particularly in complex or nuanced tasks [3].\n",
            "   - **Modular RAG**, by design, allows for better integration and coordination between its modules, leading to improved coherence and relevance in the generated responses [3].\n",
            "\n",
            "**Benefits at Production Level**:\n",
            "- **Efficiency**: The modular approach allows for targeted improvements and optimizations of individual components, resulting in a more efficient system overall [3].\n",
            "- **Scalability**: Modular RAG's design makes it easier to scale and adapt to different use cases or domains by swapping or upgrading specific modules without overhauling the entire system [3].\n",
            "- **Accuracy**: By enhancing the integration and coordination between retrieval and generation, Modular RAG can produce more accurate and context-aware outputs, which is crucial for applications requiring current or specialized knowledge [3].\n",
            "\n",
            "These differences and benefits make Modular RAG a more advanced and adaptable solution compared to Naive RAG, especially in production environments where efficiency, scalability, and accuracy are critical.\n",
            "\n",
            "Sources:\n",
            "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
            "[3] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\n",
            "[3] https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Thank you for that detailed explanation, Dr. Carter. Could you provide a specific example of a situation where Modular RAG has significantly outperformed Naive RAG, particularly in terms of efficiency or accuracy?\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document source=\"http://arxiv.org/abs/2502.09304v1\" date=\"2025-02-13\" authors=\"Yiqian Huang, Shiqi Zhang, Xiaokui Xiao\"/>\n",
            "<Title>\n",
            "KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Graph-RAG constructs a knowledge graph from text chunks to improve retrieval\n",
            "in Large Language Model (LLM)-based question answering. It is particularly\n",
            "useful in domains such as biomedicine, law, and political science, where\n",
            "retrieval often requires multi-hop reasoning over proprietary documents. Some\n",
            "existing Graph-RAG systems construct KNN graphs based on text chunk relevance,\n",
            "but this coarse-grained approach fails to capture entity relationships within\n",
            "texts, leading to sub-par retrieval and generation quality. To address this,\n",
            "recent solutions leverage LLMs to extract entities and relationships from text\n",
            "chunks, constructing triplet-based knowledge graphs. However, this approach\n",
            "incurs significant indexing costs, especially for large document collections.\n",
            "  To ensure a good result accuracy while reducing the indexing cost, we propose\n",
            "KET-RAG, a multi-granular indexing framework. KET-RAG first identifies a small\n",
            "set of key text chunks and leverages an LLM to construct a knowledge graph\n",
            "skeleton. It then builds a text-keyword bipartite graph from all text chunks,\n",
            "serving as a lightweight alternative to a full knowledge graph. During\n",
            "retrieval, KET-RAG searches both structures: it follows the local search\n",
            "strategy of existing Graph-RAG systems on the skeleton while mimicking this\n",
            "search on the bipartite graph to improve retrieval quality. We evaluate eight\n",
            "solutions on two real-world datasets, demonstrating that KET-RAG outperforms\n",
            "all competitors in indexing cost, retrieval effectiveness, and generation\n",
            "quality. Notably, it achieves comparable or superior retrieval quality to\n",
            "Microsoft's Graph-RAG while reducing indexing costs by over an order of\n",
            "magnitude. Additionally, it improves the generation quality by up to 32.4%\n",
            "while lowering indexing costs by around 20%.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework\n",
            "for Graph-RAG\n",
            "Yiqian Huang\n",
            "National University of Singapore\n",
            "Singapore\n",
            "yiqian@comp.nus.edu.sg\n",
            "Shiqi Zhang\n",
            "National University of Singapore\n",
            "Singapore\n",
            "PyroWis AI\n",
            "Singapore\n",
            "shiqi@pyrowis.ai\n",
            "Xiaokui Xiao\n",
            "National University of Singapore\n",
            "Singapore\n",
            "xkxiao@nus.edu.sg\n",
            "Abstract\n",
            "Graph-RAG constructs a knowledge graph from text chunks to\n",
            "improve retrieval in Large Language Model (LLM)-based question\n",
            "answering. It is particularly useful in domains such as biomedicine,\n",
            "law, and political science, where retrieval often requires multi-hop\n",
            "reasoning over proprietary documents. Some existing Graph-RAG\n",
            "systems construct KNN graphs based on text chunk relevance, but\n",
            "this coarse-grained approach fails to capture entity relationships\n",
            "within texts, leading to sub-par retrieval and generation quality. To\n",
            "address this, recent solutions leverage LLMs to extract entities and\n",
            "relationships from text chunks, constructing triplet-based knowl-\n",
            "edge graphs. However, this approach incurs significant indexing\n",
            "costs, especially for large document collections.\n",
            "To ensure a good result accuracy while reducing the indexing\n",
            "cost, we propose KET-RAG, a multi-granular indexing framework.\n",
            "KET-RAG first identifies a small set of key text chunks and leverages\n",
            "an LLM to construct a knowledge graph skeleton. It then builds\n",
            "a text-keyword bipartite graph from all text chunks, serving as a\n",
            "lightweight alternative to a full knowledge graph. During retrieval,\n",
            "KET-RAG searches both structures: it follows the local search strat-\n",
            "egy of existing Graph-RAG systems on the skeleton while mimick-\n",
            "ing this search on the bipartite graph to improve retrieval quality.\n",
            "We evaluate eight solutions on two real-world datasets, demonstrat-\n",
            "ing that KET-RAG outperforms all competitors in indexing cost,\n",
            "retrieval effectiveness, and generation quality. Notably, it achieves\n",
            "comparable or superior retrieval quality to Microsoft’s Graph-RAG\n",
            "while reducing indexing costs by over an order of magnitude. Ad-\n",
            "ditionally, it improves the generation quality by up to 32.4% while\n",
            "lowering indexing costs by around 20%.\n",
            "Keywords\n",
            "Retrieval-Augmented Generation, GraphRAG, Indexing\n",
            "Permission to make digital or hard copies of all or part of this work for personal or\n",
            "classroom use is granted without fee provided that copies are not made or distributed\n",
            "for profit or commercial advantage and that copies bear this notice and the full citation\n",
            "on the first page. Copyrights for components of this work owned by others than the\n",
            "author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\n",
            "republish, to post on servers or to redistribute to lists, requires prior specific permission\n",
            "and/or a fee. Request permissions from permissions@acm.org.\n",
            "Conference acronym ’XX, Woodstock, NY\n",
            "© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n",
            "ACM ISBN 978-1-4503-XXXX-X/2018/06\n",
            "https://doi.org/XXXXXXX.XXXXXXX\n",
            "ACM Reference Format:\n",
            "Yiqian Huang, Shiqi Zhang, and Xiaokui Xiao. 2018. KET-RAG: A Cost-\n",
            "Efficient Multi-Granular Indexing Framework for Graph-RAG. In Proceed-\n",
            "ings of Make sure to enter the correct conference title from your rights confir-\n",
            "mation email (Conference acronym ’XX). ACM, New York, NY, USA, 9 pages.\n",
            "https://doi.org/XXXXXXX.XXXXXXX\n",
            "1\n",
            "Introduction\n",
            "Given a set of text chunks T, Graph-based Retrieval-Augmented\n",
            "Generation (Graph-RAG) [8, 23] enhances generative model infer-\n",
            "ence by structuring T into a Text-Attributed Graph (TAG) G and\n",
            "retrieving relevant information from it. Compared to Text-RAG [16],\n",
            "which retrieves independent text chunks from T, Graph-RAG cap-\n",
            "tures relationships within and across text snippets to enhance\n",
            "multi-hop reasoning [7, 14, 26]. Graph-RAG has gained widespread\n",
            "adoption across domains such as e-commerce [31, 33], biomedical\n",
            "research [7, 17], healthcare [4], political science [21], legal applica-\n",
            "tions [5, 15], and many others [1, 27].\n",
            "Some studies [18, 32] instantiate TAG G as a K-\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2407.19994v3\" date=\"2024-09-13\" authors=\"Cheonsu Jeong\"/>\n",
            "<Title>\n",
            "A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "This study aims to improve knowledge-based question-answering (QA) systems by\n",
            "overcoming the limitations of existing Retrieval-Augmented Generation (RAG)\n",
            "models and implementing an advanced RAG system based on Graph technology to\n",
            "develop high-quality generative AI services. While existing RAG models\n",
            "demonstrate high accuracy and fluency by utilizing retrieved information, they\n",
            "may suffer from accuracy degradation as they generate responses using\n",
            "pre-loaded knowledge without reprocessing. Additionally, they cannot\n",
            "incorporate real-time data after the RAG configuration stage, leading to issues\n",
            "with contextual understanding and biased information. To address these\n",
            "limitations, this study implemented an enhanced RAG system utilizing Graph\n",
            "technology. This system is designed to efficiently search and utilize\n",
            "information. Specifically, it employs LangGraph to evaluate the reliability of\n",
            "retrieved information and synthesizes diverse data to generate more accurate\n",
            "and enhanced responses. Furthermore, the study provides a detailed explanation\n",
            "of the system's operation, key implementation steps, and examples through\n",
            "implementation code and validation results, thereby enhancing the understanding\n",
            "of advanced RAG technology. This approach offers practical guidelines for\n",
            "implementing advanced RAG systems in corporate services, making it a valuable\n",
            "resource for practical application.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            " \n",
            "* Corresponding Author: Cheonsu Jeong; paripal@korea.ac.kr \n",
            " \n",
            " \n",
            "1  \n",
            " \n",
            "A Study on the Implementation Method \n",
            "of an Agent-Based Advanced RAG  \n",
            "System Using Graph \n",
            "Cheonsu Jeong1 \n",
            " \n",
            " \n",
            " \n",
            "1 Dr. Jeong is Principal Consultant & the Technical Leader for AI Automation at SAMSUNG SDS; \n",
            " \n",
            "Abstract  \n",
            "This study aims to improve knowledge-based question-answering (QA) systems by overcoming the limitations of \n",
            "existing Retrieval-Augmented Generation (RAG) models and implementing an advanced RAG system based on \n",
            "Graph technology to develop high-quality generative AI services. While existing RAG models demonstrate high ac-\n",
            "curacy and fluency by utilizing retrieved information, they may suffer from accuracy degradation as they generate \n",
            "responses using pre-loaded knowledge without reprocessing. Additionally, they cannot incorporate real-time data \n",
            "after the RAG configuration stage, leading to issues with contextual understanding and biased information. \n",
            "To address these limitations, this study implemented an enhanced RAG system utilizing Graph technology. This system \n",
            "is designed to efficiently search and utilize information. Specifically, it employs LangGraph to evaluate the reliability \n",
            "of retrieved information and synthesizes diverse data to generate more accurate and enhanced responses. Furthermore, \n",
            "the study provides a detailed explanation of the system's operation, key implementation steps, and examples through \n",
            "implementation code and validation results, thereby enhancing the understanding of advanced RAG technology. This \n",
            "approach offers practical guidelines for implementing advanced RAG systems in corporate services, making it a valu-\n",
            "able resource for practical application. \n",
            " \n",
            "Keywords \n",
            "Advance RAG; Agent RAG; LLM; Generative AI; LangGraph \n",
            " \n",
            " \n",
            "I. Introduction \n",
            "Recent advancements in AI technology have brought sig-\n",
            "nificant attention to Generative AI. Generative AI, a form \n",
            "of artificial intelligence that can create new content such \n",
            "as text, images, audio, and video based on vast amounts \n",
            "of trained data models (Jeong, 2023d), is being applied in \n",
            "various fields, including daily conversations, finance, \n",
            "healthcare, education, and entertainment (Ahn & Park, \n",
            "2023). As generative AI services become more accessible \n",
            "to the general public, the role of generative AI-based chat-\n",
            "bots is becoming increasingly important (Adam et al., \n",
            "2021; Przegalinska et al., 2019; Park, 2024). A chatbot is \n",
            "an intelligent agent that allows users to have conversa-\n",
            "tions typically through text or voice (Sánchez-Díaz et al., \n",
            "2018; Jeong & Jeong, 2020). Recently, generative AI \n",
            "chatbots have advanced to the level of analyzing human \n",
            "emotions and intentions to provide responses (Jeong, \n",
            "2023a). With the advent of large language models \n",
            "(LLMs), these chatbots can now be utilized for automatic \n",
            " \n",
            "Cheonsu Jeong \n",
            " \n",
            "2  \n",
            " \n",
            "dialogue generation and translation (Jeong, 2023b). How-\n",
            "ever, they may generate responses that conflict with the \n",
            "latest information and have a low understanding of new \n",
            "problems or domains as they rely on previously trained \n",
            "data (Jeong, 2023c). While 2023 was marked by the re-\n",
            "lease of foundational large language models (LLMs) like \n",
            "ChatGPT and Llama-2, experts predict that 2024 will be \n",
            "the year of Retrieval Augmented Generation (RAG) and \n",
            "AI Agents (Skelter Labs, 2024). \n",
            "However, there are several considerations for companies \n",
            "looking to adopt generative AI services. Companies must \n",
            "address concerns such as whether the AI can provide ac-\n",
            "curate responses based on internal data, the potential risk \n",
            "of internal data leakage, and how to integrate generative \n",
            "AI with corporate systems. Solutions include using do-\n",
            "main-specific fine-tuned LLMs and enhancing reliability \n",
            "with RAG that utilizes internal information (Jung, 2024). \n",
            "When domain-specific information is fine-tuned on GPT-\n",
            "4 LLM, accuracy improves from 75% to 81%, and adding \n",
            "RAG can further increase accuracy to 86% (Angels et al., \n",
            "2024). RAG models are known for effectively combinin\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2312.10997v5\" date=\"2024-03-27\" authors=\"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang\"/>\n",
            "<Title>\n",
            "Retrieval-Augmented Generation for Large Language Models: A Survey\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Large Language Models (LLMs) showcase impressive capabilities but encounter\n",
            "challenges like hallucination, outdated knowledge, and non-transparent,\n",
            "untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\n",
            "emerged as a promising solution by incorporating knowledge from external\n",
            "databases. This enhances the accuracy and credibility of the generation,\n",
            "particularly for knowledge-intensive tasks, and allows for continuous knowledge\n",
            "updates and integration of domain-specific information. RAG synergistically\n",
            "merges LLMs' intrinsic knowledge with the vast, dynamic repositories of\n",
            "external databases. This comprehensive review paper offers a detailed\n",
            "examination of the progression of RAG paradigms, encompassing the Naive RAG,\n",
            "the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\n",
            "tripartite foundation of RAG frameworks, which includes the retrieval, the\n",
            "generation and the augmentation techniques. The paper highlights the\n",
            "state-of-the-art technologies embedded in each of these critical components,\n",
            "providing a profound understanding of the advancements in RAG systems.\n",
            "Furthermore, this paper introduces up-to-date evaluation framework and\n",
            "benchmark. At the end, this article delineates the challenges currently faced\n",
            "and points out prospective avenues for research and development.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "1\n",
            "Retrieval-Augmented Generation for Large\n",
            "Language Models: A Survey\n",
            "Yunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\n",
            "Wangc, and Haofen Wang a,c\n",
            "aShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n",
            "bShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n",
            "cCollege of Design and Innovation, Tongji University\n",
            "Abstract—Large Language Models (LLMs) showcase impres-\n",
            "sive capabilities but encounter challenges like hallucination,\n",
            "outdated knowledge, and non-transparent, untraceable reasoning\n",
            "processes. Retrieval-Augmented Generation (RAG) has emerged\n",
            "as a promising solution by incorporating knowledge from external\n",
            "databases. This enhances the accuracy and credibility of the\n",
            "generation, particularly for knowledge-intensive tasks, and allows\n",
            "for continuous knowledge updates and integration of domain-\n",
            "specific information. RAG synergistically merges LLMs’ intrin-\n",
            "sic knowledge with the vast, dynamic repositories of external\n",
            "databases. This comprehensive review paper offers a detailed\n",
            "examination of the progression of RAG paradigms, encompassing\n",
            "the Naive RAG, the Advanced RAG, and the Modular RAG.\n",
            "It meticulously scrutinizes the tripartite foundation of RAG\n",
            "frameworks, which includes the retrieval, the generation and the\n",
            "augmentation techniques. The paper highlights the state-of-the-\n",
            "art technologies embedded in each of these critical components,\n",
            "providing a profound understanding of the advancements in RAG\n",
            "systems. Furthermore, this paper introduces up-to-date evalua-\n",
            "tion framework and benchmark. At the end, this article delineates\n",
            "the challenges currently faced and points out prospective avenues\n",
            "for research and development 1.\n",
            "Index Terms—Large language model, retrieval-augmented gen-\n",
            "eration, natural language processing, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE language models (LLMs) have achieved remark-\n",
            "able success, though they still face significant limitations,\n",
            "especially in domain-specific or knowledge-intensive tasks [1],\n",
            "notably producing “hallucinations” [2] when handling queries\n",
            "beyond their training data or requiring current information. To\n",
            "overcome challenges, Retrieval-Augmented Generation (RAG)\n",
            "enhances LLMs by retrieving relevant document chunks from\n",
            "external knowledge base through semantic similarity calcu-\n",
            "lation. By referencing external knowledge, RAG effectively\n",
            "reduces the problem of generating factually incorrect content.\n",
            "Its integration into LLMs has resulted in widespread adoption,\n",
            "establishing RAG as a key technology in advancing chatbots\n",
            "and enhancing the suitability of LLMs for real-world applica-\n",
            "tions.\n",
            "RAG technology has rapidly developed in recent years, and\n",
            "the technology tree summarizing related research is shown\n",
            "Corresponding Author.Email:haofen.wang@tongji.edu.cn\n",
            "1Resources\n",
            "are\n",
            "available\n",
            "at\n",
            "https://github.com/Tongji-KGLLM/\n",
            "RAG-Survey\n",
            "in Figure 1. The development trajectory of RAG in the era\n",
            "of large models exhibits several distinct stage characteristics.\n",
            "Initially, RAG’s inception coincided with the rise of the\n",
            "Transformer architecture, focusing on enhancing language\n",
            "models by incorporating additional knowledge through Pre-\n",
            "Training Models (PTM). This early stage was characterized\n",
            "by foundational work aimed at refining pre-training techniques\n",
            "[3]–[5].The subsequent arrival of ChatGPT [6] marked a\n",
            "pivotal moment, with LLM demonstrating powerful in context\n",
            "learning (ICL) capabilities. RAG research shifted towards\n",
            "providing better information for LLMs to answer more com-\n",
            "plex and knowledge-intensive tasks during the inference stage,\n",
            "leading to rapid development in RAG studies. As research\n",
            "progressed, the enhancement of RAG was no longer limited\n",
            "to the inference stage but began to incorporate more with LLM\n",
            "fine-tuning techniques.\n",
            "The burgeoning field of RAG has experienced swift growth,\n",
            "yet it has not been accompanied by a systematic synthesis that\n",
            "could clarify its broader trajectory. Thi\n",
            "</Content>\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_web\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document href=\"https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\"/>\n",
            "Naive RAG established the groundwork for retrieval-augmented systems by combining document retrieval with language model generation. For example, in a question-answering task, RECALL ensures that a RAG system accurately incorporates all relevant points from retrieved documents into the generated answer. Vector databases play a crucial role in the operation of RAG systems, providing the infrastructure required for storing and retrieving high-dimensional embeddings of contextual information needed for LLMs. These embeddings capture the semantic and contextual meaning of unstructured data, enabling precise similarity searches that underpin the effectiveness of retrieval-augmented generation. By integrating retrieval into generation, RAG systems deliver more accurate and context-aware outputs, making them effective for applications requiring current or specialized knowledge.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.devstark.com/blog/naive-rag-advanced-rag-and-modular-rag-architectures/\"/>\n",
            "It remains rooted in the core principles of Advanced and Naive RAG and offers unique features such as adding a search module for similarity queries and fine-tuning the retriever. Instead of simply using retrieved information as-is, Advanced RAG incorporates extra processing steps to enhance the relevance and improve the overall quality of the responses. In this step of Advanced RAG, we can improve our processes by optimizing chunk embedding and retrieval. Fine-tuning embedding models with domain-specific data and optimizing similarity metrics allows RAG to retrieve more accurate information. Advanced RAG introduces re-ranking as an additional step after retrieval to refine the information so that the most relevant and valuable data is given priority.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
            "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. Modular RAG is an advanced form of Retrieval-Augmented Generation that leverages a modular design to separate and optimize various components of the system. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. Seamless Integration: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36manswer_question\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: expert\n",
            "\n",
            "Certainly, Dr. Carter. A specific example where Modular RAG significantly outperforms Naive RAG can be seen in applications requiring high levels of coherence and relevance in generated responses, such as complex question-answering systems.\n",
            "\n",
            "**Example: Question-Answering Systems**:\n",
            "- In a typical question-answering task, the Naive RAG system retrieves documents based on semantic similarity and uses them directly in generating answers. However, because Naive RAG's retrieval process is static and lacks flexibility, it often results in integrating less relevant or coherent data into the generated response [3].\n",
            "- On the other hand, Modular RAG, with its ability to optimize and swap out different components, can employ specialized retrieval modules that are fine-tuned for specific types of queries or domains. This leads to more precise retrieval of relevant information, which, when integrated with the generative process, results in more accurate and context-aware answers [3].\n",
            "\n",
            "**Benefits Observed**:\n",
            "- **Efficiency**: Modular RAG can process queries faster by utilizing optimized retrieval modules that minimize unnecessary computational overhead [3].\n",
            "- **Accuracy**: The modular approach ensures that only the most relevant data is used in generating responses, significantly reducing errors and improving the quality of information provided [3].\n",
            "- **Scalability and Adaptability**: When dealing with different domains, Modular RAG can easily adapt by integrating domain-specific modules, which is not as feasible with the monolithic structure of Naive RAG [3].\n",
            "\n",
            "This adaptability and precision make Modular RAG particularly beneficial in environments where the accuracy of information is paramount, such as legal, medical, or scientific fields.\n",
            "\n",
            "Sources:\n",
            "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
            "[3] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\n",
            "[3] https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "That's a compelling example, Dr. Carter. How do you see the future development of Modular RAG impacting AI research and its applications in the coming years?\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
            "<Title>\n",
            "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
            "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
            "increasing demands of application scenarios have driven the evolution of RAG,\n",
            "leading to the integration of advanced retrievers, LLMs and other complementary\n",
            "technologies, which in turn has amplified the intricacy of RAG systems.\n",
            "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process of\n",
            "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
            "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
            "decomposing complex RAG systems into independent modules and specialized\n",
            "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a more advanced\n",
            "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
            "extensive research, this paper further identifies prevalent RAG\n",
            "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
            "analysis of their respective implementation nuances. Modular RAG presents\n",
            "innovative opportunities for the conceptualization and deployment of RAG\n",
            "systems. Finally, the paper explores the potential emergence of new operators\n",
            "and paradigms, establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment of RAG\n",
            "technologies.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "1\n",
            "Modular RAG: Transforming RAG Systems into\n",
            "LEGO-like Reconfigurable Frameworks\n",
            "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
            "Abstract—Retrieval-augmented\n",
            "Generation\n",
            "(RAG)\n",
            "has\n",
            "markedly enhanced the capabilities of Large Language Models\n",
            "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
            "demands of application scenarios have driven the evolution\n",
            "of RAG, leading to the integration of advanced retrievers,\n",
            "LLMs and other complementary technologies, which in turn\n",
            "has amplified the intricacy of RAG systems. However, the rapid\n",
            "advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process\n",
            "of “retrieve-then-generate”. In this context, this paper examines\n",
            "the limitations of the existing RAG paradigm and introduces\n",
            "the modular RAG framework. By decomposing complex RAG\n",
            "systems into independent modules and specialized operators, it\n",
            "facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a\n",
            "more advanced design that integrates routing, scheduling, and\n",
            "fusion mechanisms. Drawing on extensive research, this paper\n",
            "further identifies prevalent RAG patterns—linear, conditional,\n",
            "branching, and looping—and offers a comprehensive analysis\n",
            "of their respective implementation nuances. Modular RAG\n",
            "presents\n",
            "innovative\n",
            "opportunities\n",
            "for\n",
            "the\n",
            "conceptualization\n",
            "and deployment of RAG systems. Finally, the paper explores\n",
            "the potential emergence of new operators and paradigms,\n",
            "establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment\n",
            "of RAG technologies.\n",
            "Index Terms—Retrieval-augmented generation, large language\n",
            "model, modular system, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE Language Models (LLMs) have demonstrated\n",
            "remarkable capabilities, yet they still face numerous\n",
            "challenges, such as hallucination and the lag in information up-\n",
            "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
            "ing external knowledge bases, provides LLMs with important\n",
            "contextual information, significantly enhancing their perfor-\n",
            "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
            "an enhancement method, has been widely applied in various\n",
            "practical application scenarios, including knowledge question\n",
            "answering, recommendation systems, customer service, and\n",
            "personal assistants. [3]–[6]\n",
            "During the nascent stages of RAG , its core framework is\n",
            "constituted by indexing, retrieval, and generation, a paradigm\n",
            "referred to as Naive RAG [7]. However, as the complexity\n",
            "of tasks and the demands of applications have escalated, the\n",
            "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
            "Systems, Tongji University, Shanghai, 201210, China.\n",
            "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
            "Computer Science, Fudan University, Shanghai, 200438, China.\n",
            "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
            "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
            "Wang. E-mail: carter.whfcarter@gmail.com)\n",
            "limitations of Naive RAG have become increasingly apparent.\n",
            "As depicted in Figure 1, it predominantly hinges on the\n",
            "straightforward similarity of chunks, result in poor perfor-\n",
            "mance when confronted with complex queries and chunks with\n",
            "substantial variability. The primary challenges of Naive RAG\n",
            "include: 1) Shallow Understanding of Queries. The semantic\n",
            "similarity between a query and document chunk is not always\n",
            "highly consistent. Relying solely on similarity calculations\n",
            "for retrieval lacks an in-depth exploration of the relationship\n",
            "between the query and the document [8]. 2) Retrieval Re-\n",
            "dundancy and Noise. Feeding all retrieved chunks directly\n",
            "into LLMs is not always beneficial. Research indicates that\n",
            "an excess of redundant and noisy information may interfere\n",
            "with the LLM’s identification of key information, thereby\n",
            "increasing the risk of generating erroneous and hallucinated\n",
            "responses. [9]\n",
            "To overcome the aforementioned limitations, \n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2411.03538v1\" date=\"2024-11-05\" authors=\"Quinn Leng, Jacob Portes, Sam Havens, Matei Zaharia, Michael Carbin\"/>\n",
            "<Title>\n",
            "Long Context RAG Performance of Large Language Models\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval Augmented Generation (RAG) has emerged as a crucial technique for\n",
            "enhancing the accuracy of Large Language Models (LLMs) by incorporating\n",
            "external information. With the advent of LLMs that support increasingly longer\n",
            "context lengths, there is a growing interest in understanding how these models\n",
            "perform in RAG scenarios. Can these new long context models improve RAG\n",
            "performance? This paper presents a comprehensive study of the impact of\n",
            "increased context length on RAG performance across 20 popular open source and\n",
            "commercial LLMs. We ran RAG workflows while varying the total context length\n",
            "from 2,000 to 128,000 tokens (and 2 million tokens when possible) on three\n",
            "domain-specific datasets, and report key insights on the benefits and\n",
            "limitations of long context in RAG applications. Our findings reveal that while\n",
            "retrieving more documents can improve performance, only a handful of the most\n",
            "recent state of the art LLMs can maintain consistent accuracy at long context\n",
            "above 64k tokens. We also identify distinct failure modes in long context\n",
            "scenarios, suggesting areas for future research.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "Long Context RAG Performance of Large Language\n",
            "Models\n",
            "Quinn Leng∗\n",
            "Databricks Mosaic Research\n",
            "quinn.leng@databricks.com\n",
            "Jacob Portes∗\n",
            "Databricks Mosaic Research\n",
            "jacob.portes@databricks.com\n",
            "Sam Havens\n",
            "Databricks Mosaic Research\n",
            "sam.havens@databricks.com\n",
            "Matei Zaharia\n",
            "Databricks Mosaic Research\n",
            "matei@databricks.com\n",
            "Michael Carbin\n",
            "Databricks Mosaic Research\n",
            "michael.carbin@databricks.com\n",
            "Abstract\n",
            "Retrieval Augmented Generation (RAG) has emerged as a crucial technique for\n",
            "enhancing the accuracy of Large Language Models (LLMs) by incorporating\n",
            "external information. With the advent of LLMs that support increasingly longer\n",
            "context lengths, there is a growing interest in understanding how these models\n",
            "perform in RAG scenarios. Can these new long context models improve RAG\n",
            "performance? This paper presents a comprehensive study of the impact of increased\n",
            "context length on RAG performance across 20 popular open source and commercial\n",
            "LLMs. We ran RAG workflows while varying the total context length from 2,000\n",
            "to 128,000 tokens (and 2 million tokens when possible) on three domain-specific\n",
            "datasets, and report key insights on the benefits and limitations of long context\n",
            "in RAG applications. Our findings reveal that while retrieving more documents\n",
            "can improve performance, only a handful of the most recent state of the art LLMs\n",
            "can maintain consistent accuracy at long context above 64k tokens. We also\n",
            "identify distinct failure modes in long context scenarios, suggesting areas for future\n",
            "research.\n",
            "1\n",
            "Introduction\n",
            "The development of Large Language Models (LLMs) with increasingly longer context lengths has\n",
            "opened new possibilities for Retrieval Augmented Generation (RAG) applications. Recent models\n",
            "such as Anthropic Claude (200k tokens) [1], GPT-4-turbo (128k tokens) [2], OpenAI o1 (128k tokens)\n",
            "[3], Llama 3 [4] and Google Gemini 1.5 Pro (2 million tokens) [5] have led to speculation about\n",
            "whether long context models might eventually subsume traditional RAG workflows entirely. In this\n",
            "study, we empirically investigate the impact of increased context length on RAG performance and\n",
            "explore the limitations and challenges that arise in long context scenarios.\n",
            "RAG can enhance the accuracy of LLMs by retrieving information from external sources, enabling\n",
            "users to incorporate task-specific or private data into their LLM workflows. Published results using\n",
            "RAG-like methods have demonstrated benefits across many applications [6] including machine\n",
            "∗Equal contribution\n",
            "Workshop on Adaptive Foundation Models, 38th Conference on Neural Information Processing Systems\n",
            "(NeurIPS 2024).\n",
            "arXiv:2411.03538v1  [cs.LG]  5 Nov 2024\n",
            "Figure 1:\n",
            "Long context RAG performance of o1,\n",
            "GPT-4,\n",
            "Claude 3/3.5,\n",
            "Gemini 1.5\n",
            "(gemini-1.5-pro-001 and gemini-1.5-flash-001), Llama 3/3.1, Qwen 2, Mistral and DBRX\n",
            "models on 3 curated RAG datasets (Databricks DocsQA, FinanceBench, and Natural Questions). All\n",
            "values can be found in Table S3. Model versions are listed in Table S1.\n",
            "translation [7], semantic parsing [8], question answering [9, 10, 11, 12], and open-ended text genera-\n",
            "tion [13]. With longer context lengths, LLM developers can feed more documents into their RAG\n",
            "applications. While there has been recent speculation that long context LLMs will replace RAG\n",
            "entirely [14], in this paper we study whether long context LLMs can indeed be used effectively for\n",
            "RAG systems. How well do the best open source and commercial models do on long-context RAG\n",
            "tasks?\n",
            "In this study, we apply a standard RAG approach and evaluate the performance of 20 popular open\n",
            "source and commercial LLMs with varying context lengths from 2,000 to 128,000 tokens (and 2\n",
            "million tokens when possible). We then analyze distinct failure modes for different models across\n",
            "long context RAG scenarios. We show that:\n",
            "• Using longer context does not uniformly increase RAG performance. The majority of\n",
            "models we evaluated first increase and then decrease RAG performance as context length\n",
            "increases. Only a handful of the most recent state o\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2407.19994v3\" date=\"2024-09-13\" authors=\"Cheonsu Jeong\"/>\n",
            "<Title>\n",
            "A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "This study aims to improve knowledge-based question-answering (QA) systems by\n",
            "overcoming the limitations of existing Retrieval-Augmented Generation (RAG)\n",
            "models and implementing an advanced RAG system based on Graph technology to\n",
            "develop high-quality generative AI services. While existing RAG models\n",
            "demonstrate high accuracy and fluency by utilizing retrieved information, they\n",
            "may suffer from accuracy degradation as they generate responses using\n",
            "pre-loaded knowledge without reprocessing. Additionally, they cannot\n",
            "incorporate real-time data after the RAG configuration stage, leading to issues\n",
            "with contextual understanding and biased information. To address these\n",
            "limitations, this study implemented an enhanced RAG system utilizing Graph\n",
            "technology. This system is designed to efficiently search and utilize\n",
            "information. Specifically, it employs LangGraph to evaluate the reliability of\n",
            "retrieved information and synthesizes diverse data to generate more accurate\n",
            "and enhanced responses. Furthermore, the study provides a detailed explanation\n",
            "of the system's operation, key implementation steps, and examples through\n",
            "implementation code and validation results, thereby enhancing the understanding\n",
            "of advanced RAG technology. This approach offers practical guidelines for\n",
            "implementing advanced RAG systems in corporate services, making it a valuable\n",
            "resource for practical application.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            " \n",
            "* Corresponding Author: Cheonsu Jeong; paripal@korea.ac.kr \n",
            " \n",
            " \n",
            "1  \n",
            " \n",
            "A Study on the Implementation Method \n",
            "of an Agent-Based Advanced RAG  \n",
            "System Using Graph \n",
            "Cheonsu Jeong1 \n",
            " \n",
            " \n",
            " \n",
            "1 Dr. Jeong is Principal Consultant & the Technical Leader for AI Automation at SAMSUNG SDS; \n",
            " \n",
            "Abstract  \n",
            "This study aims to improve knowledge-based question-answering (QA) systems by overcoming the limitations of \n",
            "existing Retrieval-Augmented Generation (RAG) models and implementing an advanced RAG system based on \n",
            "Graph technology to develop high-quality generative AI services. While existing RAG models demonstrate high ac-\n",
            "curacy and fluency by utilizing retrieved information, they may suffer from accuracy degradation as they generate \n",
            "responses using pre-loaded knowledge without reprocessing. Additionally, they cannot incorporate real-time data \n",
            "after the RAG configuration stage, leading to issues with contextual understanding and biased information. \n",
            "To address these limitations, this study implemented an enhanced RAG system utilizing Graph technology. This system \n",
            "is designed to efficiently search and utilize information. Specifically, it employs LangGraph to evaluate the reliability \n",
            "of retrieved information and synthesizes diverse data to generate more accurate and enhanced responses. Furthermore, \n",
            "the study provides a detailed explanation of the system's operation, key implementation steps, and examples through \n",
            "implementation code and validation results, thereby enhancing the understanding of advanced RAG technology. This \n",
            "approach offers practical guidelines for implementing advanced RAG systems in corporate services, making it a valu-\n",
            "able resource for practical application. \n",
            " \n",
            "Keywords \n",
            "Advance RAG; Agent RAG; LLM; Generative AI; LangGraph \n",
            " \n",
            " \n",
            "I. Introduction \n",
            "Recent advancements in AI technology have brought sig-\n",
            "nificant attention to Generative AI. Generative AI, a form \n",
            "of artificial intelligence that can create new content such \n",
            "as text, images, audio, and video based on vast amounts \n",
            "of trained data models (Jeong, 2023d), is being applied in \n",
            "various fields, including daily conversations, finance, \n",
            "healthcare, education, and entertainment (Ahn & Park, \n",
            "2023). As generative AI services become more accessible \n",
            "to the general public, the role of generative AI-based chat-\n",
            "bots is becoming increasingly important (Adam et al., \n",
            "2021; Przegalinska et al., 2019; Park, 2024). A chatbot is \n",
            "an intelligent agent that allows users to have conversa-\n",
            "tions typically through text or voice (Sánchez-Díaz et al., \n",
            "2018; Jeong & Jeong, 2020). Recently, generative AI \n",
            "chatbots have advanced to the level of analyzing human \n",
            "emotions and intentions to provide responses (Jeong, \n",
            "2023a). With the advent of large language models \n",
            "(LLMs), these chatbots can now be utilized for automatic \n",
            " \n",
            "Cheonsu Jeong \n",
            " \n",
            "2  \n",
            " \n",
            "dialogue generation and translation (Jeong, 2023b). How-\n",
            "ever, they may generate responses that conflict with the \n",
            "latest information and have a low understanding of new \n",
            "problems or domains as they rely on previously trained \n",
            "data (Jeong, 2023c). While 2023 was marked by the re-\n",
            "lease of foundational large language models (LLMs) like \n",
            "ChatGPT and Llama-2, experts predict that 2024 will be \n",
            "the year of Retrieval Augmented Generation (RAG) and \n",
            "AI Agents (Skelter Labs, 2024). \n",
            "However, there are several considerations for companies \n",
            "looking to adopt generative AI services. Companies must \n",
            "address concerns such as whether the AI can provide ac-\n",
            "curate responses based on internal data, the potential risk \n",
            "of internal data leakage, and how to integrate generative \n",
            "AI with corporate systems. Solutions include using do-\n",
            "main-specific fine-tuned LLMs and enhancing reliability \n",
            "with RAG that utilizes internal information (Jung, 2024). \n",
            "When domain-specific information is fine-tuned on GPT-\n",
            "4 LLM, accuracy improves from 75% to 81%, and adding \n",
            "RAG can further increase accuracy to 86% (Angels et al., \n",
            "2024). RAG models are known for effectively combinin\n",
            "</Content>\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_web\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document href=\"https://www.ibm.com/think/topics/rag-techniques\"/>\n",
            "RAG adds power to generative AI models by interspersing real-time data retrieval, ensuring that the retrieval process produces a more accurate and timely output. RAG adds power to generative AI models by interspersing real-time data retrieval, ensuring that the retrieval process produces a more accurate and timely output. Active development in retrieval systems that leverage advanced prompt engineering techniques and fine-tuning methods to enhance RAG models for high-precision content generation are going on to ensure better performance and scalability. Future advancements in self-RAG approaches, multimodal AI models and improved metrics will continue to refine the retrieval process, ensuring better handling of additional context in natural language interactions.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.chitika.com/how-rag-is-shaping-the-future-of-conversational-ai-systems/\"/>\n",
            "RAG bridges retrieval-based and generative models, creating dynamic systems that adapt to real-time data. Unlike static models, RAG retrieves real-time data, ensuring contextual relevance. Fresh Insight: Dynamic retrieval systems in RAG enable AGI to adaptively integrate real-time knowledge, bridging static training limitations. By integrating retrieval and generation, RAG bridges the gap between static training data and real-time adaptability, making it a transformative solution for modern conversational AI challenges. RAG improves the accuracy and relevance of responses in conversational AI systems by dynamically retrieving real-time, context-specific information from external knowledge bases. Emerging trends and future advancements in RAG for conversational AI include the integration of multimodal capabilities, enabling systems to process and generate responses using diverse data formats such as text, images, and audio.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://medium.com/aingineer/a-comprehensive-guide-to-implementing-modular-rag-for-scalable-ai-systems-3fb47c46dc8e\"/>\n",
            "A Comprehensive Guide to Implementing Modular RAG for Scalable AI Systems | by Gaurav Nigam | aingineer | Dec, 2024 | Medium A Comprehensive Guide to Implementing Modular RAG for Scalable AI Systems In the rapidly evolving landscape of AI, Modular RAG (Retrieval-Augmented Generation) has emerged as a transformative approach to building robust, scalable, and adaptable AI systems. By decoupling retrieval, reasoning, and generation into independent modules, Modular RAG empowers engineering leaders, architects, and senior engineers to design systems that are not only efficient but also flexible enough to meet the dynamic demands of modern enterprises. This guide aims to provide an in-depth exploration of Modular RAG, from its foundational principles to practical implementation strategies, tailored for professionals with a keen interest in scaling enterprise AI systems.\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36manswer_question\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: expert\n",
            "\n",
            "The future development of Modular RAG is poised to significantly impact AI research and its applications in several key ways:\n",
            "\n",
            "1. **Enhanced Flexibility and Customization**:\n",
            "   - Modular RAG's design allows for greater flexibility in customizing AI systems to meet specific needs. As AI applications become more diverse, the ability to tailor individual components without overhauling entire systems will become increasingly important [3].\n",
            "\n",
            "2. **Improved Scalability**:\n",
            "   - As the demand for AI systems grows, particularly in enterprise and industrial applications, the scalability offered by Modular RAG will be crucial. Its modular structure supports scaling by enabling the integration of more powerful or specialized modules as required, which can handle larger datasets and more complex queries efficiently [3].\n",
            "\n",
            "3. **Broader Adoption Across Domains**:\n",
            "   - The ability to easily adapt Modular RAG systems to different domains, such as healthcare, finance, and legal industries, will likely lead to broader adoption. This adaptability ensures that AI can provide accurate and contextually relevant information across various fields, enhancing its utility and reliability [3].\n",
            "\n",
            "4. **Advancements in Real-Time Data Integration**:\n",
            "   - With ongoing developments in real-time data retrieval and integration, Modular RAG will enhance the ability of AI systems to provide up-to-date and contextually relevant outputs. This will be particularly beneficial in fast-evolving fields where timely information is critical [3].\n",
            "\n",
            "5. **Innovation in AI Research**:\n",
            "   - The modular approach encourages experimentation with different retrieval and generation techniques, fostering innovation. Researchers can explore new algorithms and methodologies within individual modules without disrupting the overall system, leading to continuous improvements and breakthroughs in AI capabilities [3].\n",
            "\n",
            "Overall, Modular RAG represents a significant step forward in making AI systems more efficient, adaptable, and scalable. Its continued development is likely to play a pivotal role in advancing AI research and expanding the range of applications in which AI can be effectively utilized.\n",
            "\n",
            "Sources:\n",
            "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
            "[3] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\n",
            "[3] https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Thank you so much for your help, Dr. Carter! Your insights have been incredibly valuable.\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_web\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document href=\"https://www.dataversity.net/rag-the-future-of-reliable-and-accurate-generative-ai/\"/>\n",
            "By facilitating rapid access to pertinent data, RAG can dramatically shorten research durations and support research and development initiatives with accurate and timely information. Businesses can use this capability to design domain-specific AI models, promoting creativity and speeding up the creation of new technologies.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.harrisonclarke.com/blog/challenges-and-future-directions-in-rag-research-embracing-data-ai\"/>\n",
            "Example: Implementing a hybrid retrieval system that uses sparse representations for initial filtering and dense representations for fine-grained ranking can enhance the scalability and accuracy of RAG systems in large-scale applications. Transfer Learning: Using models pre-trained on large, diverse datasets and fine-tuning them on domain-specific data can help RAG systems adapt to new domains more effectively. Task-Specific Metrics: Developing metrics tailored to specific applications of RAG systems (e.g., customer support, research synthesis) can provide more relevant assessments of performance. As technology leaders, the ability to harness the power of Data & AI through advancements in RAG systems can drive significant innovation and competitive advantage. By investing in the latest research directions—enhancing scalability, improving domain adaptability, developing better evaluation metrics, and integrating ethical considerations—technology companies can unlock the full potential of RAG systems.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.chitika.com/how-rag-is-shaping-the-future-of-conversational-ai-systems/\"/>\n",
            "RAG bridges retrieval-based and generative models, creating dynamic systems that adapt to real-time data. Unlike static models, RAG retrieves real-time data, ensuring contextual relevance. Fresh Insight: Dynamic retrieval systems in RAG enable AGI to adaptively integrate real-time knowledge, bridging static training limitations. By integrating retrieval and generation, RAG bridges the gap between static training data and real-time adaptability, making it a transformative solution for modern conversational AI challenges. RAG improves the accuracy and relevance of responses in conversational AI systems by dynamically retrieving real-time, context-specific information from external knowledge bases. Emerging trends and future advancements in RAG for conversational AI include the integration of multimodal capabilities, enabling systems to process and generate responses using diverse data formats such as text, images, and audio.\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
            "<Title>\n",
            "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
            "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
            "increasing demands of application scenarios have driven the evolution of RAG,\n",
            "leading to the integration of advanced retrievers, LLMs and other complementary\n",
            "technologies, which in turn has amplified the intricacy of RAG systems.\n",
            "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process of\n",
            "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
            "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
            "decomposing complex RAG systems into independent modules and specialized\n",
            "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a more advanced\n",
            "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
            "extensive research, this paper further identifies prevalent RAG\n",
            "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
            "analysis of their respective implementation nuances. Modular RAG presents\n",
            "innovative opportunities for the conceptualization and deployment of RAG\n",
            "systems. Finally, the paper explores the potential emergence of new operators\n",
            "and paradigms, establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment of RAG\n",
            "technologies.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "1\n",
            "Modular RAG: Transforming RAG Systems into\n",
            "LEGO-like Reconfigurable Frameworks\n",
            "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
            "Abstract—Retrieval-augmented\n",
            "Generation\n",
            "(RAG)\n",
            "has\n",
            "markedly enhanced the capabilities of Large Language Models\n",
            "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
            "demands of application scenarios have driven the evolution\n",
            "of RAG, leading to the integration of advanced retrievers,\n",
            "LLMs and other complementary technologies, which in turn\n",
            "has amplified the intricacy of RAG systems. However, the rapid\n",
            "advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process\n",
            "of “retrieve-then-generate”. In this context, this paper examines\n",
            "the limitations of the existing RAG paradigm and introduces\n",
            "the modular RAG framework. By decomposing complex RAG\n",
            "systems into independent modules and specialized operators, it\n",
            "facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a\n",
            "more advanced design that integrates routing, scheduling, and\n",
            "fusion mechanisms. Drawing on extensive research, this paper\n",
            "further identifies prevalent RAG patterns—linear, conditional,\n",
            "branching, and looping—and offers a comprehensive analysis\n",
            "of their respective implementation nuances. Modular RAG\n",
            "presents\n",
            "innovative\n",
            "opportunities\n",
            "for\n",
            "the\n",
            "conceptualization\n",
            "and deployment of RAG systems. Finally, the paper explores\n",
            "the potential emergence of new operators and paradigms,\n",
            "establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment\n",
            "of RAG technologies.\n",
            "Index Terms—Retrieval-augmented generation, large language\n",
            "model, modular system, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE Language Models (LLMs) have demonstrated\n",
            "remarkable capabilities, yet they still face numerous\n",
            "challenges, such as hallucination and the lag in information up-\n",
            "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
            "ing external knowledge bases, provides LLMs with important\n",
            "contextual information, significantly enhancing their perfor-\n",
            "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
            "an enhancement method, has been widely applied in various\n",
            "practical application scenarios, including knowledge question\n",
            "answering, recommendation systems, customer service, and\n",
            "personal assistants. [3]–[6]\n",
            "During the nascent stages of RAG , its core framework is\n",
            "constituted by indexing, retrieval, and generation, a paradigm\n",
            "referred to as Naive RAG [7]. However, as the complexity\n",
            "of tasks and the demands of applications have escalated, the\n",
            "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
            "Systems, Tongji University, Shanghai, 201210, China.\n",
            "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
            "Computer Science, Fudan University, Shanghai, 200438, China.\n",
            "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
            "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
            "Wang. E-mail: carter.whfcarter@gmail.com)\n",
            "limitations of Naive RAG have become increasingly apparent.\n",
            "As depicted in Figure 1, it predominantly hinges on the\n",
            "straightforward similarity of chunks, result in poor perfor-\n",
            "mance when confronted with complex queries and chunks with\n",
            "substantial variability. The primary challenges of Naive RAG\n",
            "include: 1) Shallow Understanding of Queries. The semantic\n",
            "similarity between a query and document chunk is not always\n",
            "highly consistent. Relying solely on similarity calculations\n",
            "for retrieval lacks an in-depth exploration of the relationship\n",
            "between the query and the document [8]. 2) Retrieval Re-\n",
            "dundancy and Noise. Feeding all retrieved chunks directly\n",
            "into LLMs is not always beneficial. Research indicates that\n",
            "an excess of redundant and noisy information may interfere\n",
            "with the LLM’s identification of key information, thereby\n",
            "increasing the risk of generating erroneous and hallucinated\n",
            "responses. [9]\n",
            "To overcome the aforementioned limitations, \n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2411.03538v1\" date=\"2024-11-05\" authors=\"Quinn Leng, Jacob Portes, Sam Havens, Matei Zaharia, Michael Carbin\"/>\n",
            "<Title>\n",
            "Long Context RAG Performance of Large Language Models\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval Augmented Generation (RAG) has emerged as a crucial technique for\n",
            "enhancing the accuracy of Large Language Models (LLMs) by incorporating\n",
            "external information. With the advent of LLMs that support increasingly longer\n",
            "context lengths, there is a growing interest in understanding how these models\n",
            "perform in RAG scenarios. Can these new long context models improve RAG\n",
            "performance? This paper presents a comprehensive study of the impact of\n",
            "increased context length on RAG performance across 20 popular open source and\n",
            "commercial LLMs. We ran RAG workflows while varying the total context length\n",
            "from 2,000 to 128,000 tokens (and 2 million tokens when possible) on three\n",
            "domain-specific datasets, and report key insights on the benefits and\n",
            "limitations of long context in RAG applications. Our findings reveal that while\n",
            "retrieving more documents can improve performance, only a handful of the most\n",
            "recent state of the art LLMs can maintain consistent accuracy at long context\n",
            "above 64k tokens. We also identify distinct failure modes in long context\n",
            "scenarios, suggesting areas for future research.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "Long Context RAG Performance of Large Language\n",
            "Models\n",
            "Quinn Leng∗\n",
            "Databricks Mosaic Research\n",
            "quinn.leng@databricks.com\n",
            "Jacob Portes∗\n",
            "Databricks Mosaic Research\n",
            "jacob.portes@databricks.com\n",
            "Sam Havens\n",
            "Databricks Mosaic Research\n",
            "sam.havens@databricks.com\n",
            "Matei Zaharia\n",
            "Databricks Mosaic Research\n",
            "matei@databricks.com\n",
            "Michael Carbin\n",
            "Databricks Mosaic Research\n",
            "michael.carbin@databricks.com\n",
            "Abstract\n",
            "Retrieval Augmented Generation (RAG) has emerged as a crucial technique for\n",
            "enhancing the accuracy of Large Language Models (LLMs) by incorporating\n",
            "external information. With the advent of LLMs that support increasingly longer\n",
            "context lengths, there is a growing interest in understanding how these models\n",
            "perform in RAG scenarios. Can these new long context models improve RAG\n",
            "performance? This paper presents a comprehensive study of the impact of increased\n",
            "context length on RAG performance across 20 popular open source and commercial\n",
            "LLMs. We ran RAG workflows while varying the total context length from 2,000\n",
            "to 128,000 tokens (and 2 million tokens when possible) on three domain-specific\n",
            "datasets, and report key insights on the benefits and limitations of long context\n",
            "in RAG applications. Our findings reveal that while retrieving more documents\n",
            "can improve performance, only a handful of the most recent state of the art LLMs\n",
            "can maintain consistent accuracy at long context above 64k tokens. We also\n",
            "identify distinct failure modes in long context scenarios, suggesting areas for future\n",
            "research.\n",
            "1\n",
            "Introduction\n",
            "The development of Large Language Models (LLMs) with increasingly longer context lengths has\n",
            "opened new possibilities for Retrieval Augmented Generation (RAG) applications. Recent models\n",
            "such as Anthropic Claude (200k tokens) [1], GPT-4-turbo (128k tokens) [2], OpenAI o1 (128k tokens)\n",
            "[3], Llama 3 [4] and Google Gemini 1.5 Pro (2 million tokens) [5] have led to speculation about\n",
            "whether long context models might eventually subsume traditional RAG workflows entirely. In this\n",
            "study, we empirically investigate the impact of increased context length on RAG performance and\n",
            "explore the limitations and challenges that arise in long context scenarios.\n",
            "RAG can enhance the accuracy of LLMs by retrieving information from external sources, enabling\n",
            "users to incorporate task-specific or private data into their LLM workflows. Published results using\n",
            "RAG-like methods have demonstrated benefits across many applications [6] including machine\n",
            "∗Equal contribution\n",
            "Workshop on Adaptive Foundation Models, 38th Conference on Neural Information Processing Systems\n",
            "(NeurIPS 2024).\n",
            "arXiv:2411.03538v1  [cs.LG]  5 Nov 2024\n",
            "Figure 1:\n",
            "Long context RAG performance of o1,\n",
            "GPT-4,\n",
            "Claude 3/3.5,\n",
            "Gemini 1.5\n",
            "(gemini-1.5-pro-001 and gemini-1.5-flash-001), Llama 3/3.1, Qwen 2, Mistral and DBRX\n",
            "models on 3 curated RAG datasets (Databricks DocsQA, FinanceBench, and Natural Questions). All\n",
            "values can be found in Table S3. Model versions are listed in Table S1.\n",
            "translation [7], semantic parsing [8], question answering [9, 10, 11, 12], and open-ended text genera-\n",
            "tion [13]. With longer context lengths, LLM developers can feed more documents into their RAG\n",
            "applications. While there has been recent speculation that long context LLMs will replace RAG\n",
            "entirely [14], in this paper we study whether long context LLMs can indeed be used effectively for\n",
            "RAG systems. How well do the best open source and commercial models do on long-context RAG\n",
            "tasks?\n",
            "In this study, we apply a standard RAG approach and evaluate the performance of 20 popular open\n",
            "source and commercial LLMs with varying context lengths from 2,000 to 128,000 tokens (and 2\n",
            "million tokens when possible). We then analyze distinct failure modes for different models across\n",
            "long context RAG scenarios. We show that:\n",
            "• Using longer context does not uniformly increase RAG performance. The majority of\n",
            "models we evaluated first increase and then decrease RAG performance as context length\n",
            "increases. Only a handful of the most recent state o\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2502.06872v1\" date=\"2025-02-08\" authors=\"Bo Ni, Zheyuan Liu, Leyao Wang, Yongjia Lei, Yuying Zhao, Xueqi Cheng, Qingkai Zeng, Luna Dong, Yinglong Xia, Krishnaram Kenthapadi, Ryan Rossi, Franck Dernoncourt, Md Mehrab Tanjim, Nesreen Ahmed, Xiaorui Liu, Wenqi Fan, Erik Blasch, Yu Wang, Meng Jiang, Tyler Derr\"/>\n",
            "<Title>\n",
            "Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-Augmented Generation (RAG) is an advanced technique designed to\n",
            "address the challenges of Artificial Intelligence-Generated Content (AIGC). By\n",
            "integrating context retrieval into content generation, RAG provides reliable\n",
            "and up-to-date external knowledge, reduces hallucinations, and ensures relevant\n",
            "context across a wide range of tasks. However, despite RAG's success and\n",
            "potential, recent studies have shown that the RAG paradigm also introduces new\n",
            "risks, including robustness issues, privacy concerns, adversarial attacks, and\n",
            "accountability issues. Addressing these risks is critical for future\n",
            "applications of RAG systems, as they directly impact their trustworthiness.\n",
            "Although various methods have been developed to improve the trustworthiness of\n",
            "RAG methods, there is a lack of a unified perspective and framework for\n",
            "research in this topic. Thus, in this paper, we aim to address this gap by\n",
            "providing a comprehensive roadmap for developing trustworthy RAG systems. We\n",
            "place our discussion around five key perspectives: reliability, privacy,\n",
            "safety, fairness, explainability, and accountability. For each perspective, we\n",
            "present a general framework and taxonomy, offering a structured approach to\n",
            "understanding the current challenges, evaluating existing solutions, and\n",
            "identifying promising future research directions. To encourage broader adoption\n",
            "and innovation, we also highlight the downstream applications where trustworthy\n",
            "RAG systems have a significant impact.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "Towards Trustworthy Retrieval Augmented\n",
            "Generation for Large Language Models: A Survey\n",
            "Bo Ni1, Zheyuan Liu†2, Leyao Wang†1 Yongjia Lei†3, Yuying Zhao1, Xueqi Cheng1,\n",
            "Qingkai Zeng2, Luna Dong4, Yinglong Xia4, Krishnaram Kenthapadi5, Ryan Rossi6,\n",
            "Franck Dernoncourt6, Md Mehrab Tanjim6, Nesreen Ahmed7, Xiaorui Liu8, Wenqi Fan9,\n",
            "Erik Blasch10, Yu Wang*3, Meng Jiang*2, Tyler Derr*1\n",
            "1Vanderbilt University, 2University of Notre Dame, 3University of Oregon, 4Meta,\n",
            "5Oracle Health AI, 6Adobe Research, 7Cisco AI Research, 8North Carolina State University,\n",
            "9The Hong Kong Polytechnic University, 10Air Force Research Lab\n",
            "{bo.ni, leyao.wang, yuying.zhao, xueqi.cheng, tyler.derr}@vanderbilt.edu,\n",
            "{zliu29, qzeng, mjiang2}@nd.edu, {yongjia, yuwang}@uoregon.edu,\n",
            "{lunadong, yxia}@meta.com, krishnaram.kenthapadi@oracle.com,\n",
            "{ryrossi,dernonco,tanjim}@adobe.com, nesahmed@cisco.com,\n",
            "xliu96@ncsu.edu, wenqi.fan@polyu.edu.hk, erik.blasch.1@us.af.mil\n",
            "Abstract\n",
            "Retrieval-Augmented Generation (RAG) is an advanced technique designed to\n",
            "address the challenges of Artificial Intelligence-Generated Content (AIGC). By\n",
            "integrating context retrieval into content generation, RAG provides reliable and\n",
            "up-to-date external knowledge, reduces hallucinations, and ensures relevant context\n",
            "across a wide range of tasks. However, despite RAG’s success and potential, recent\n",
            "studies have shown that the RAG paradigm also introduces new risks, including\n",
            "robustness issues, privacy concerns, adversarial attacks, and accountability issues.\n",
            "Addressing these risks is critical for future applications of RAG systems, as they\n",
            "directly impact their trustworthiness. Although various methods have been devel-\n",
            "oped to improve the trustworthiness of RAG methods, there is a lack of a unified\n",
            "perspective and framework for research in this topic. Thus, in this paper, we aim to\n",
            "address this gap by providing a comprehensive roadmap for developing trustworthy\n",
            "RAG systems. We place our discussion around five key perspectives: reliability,\n",
            "privacy, safety, fairness, explainability, and accountability. For each perspective,\n",
            "we present a general framework and taxonomy, offering a structured approach to\n",
            "understanding the current challenges, evaluating existing solutions, and identifying\n",
            "promising future research directions. To encourage broader adoption and inno-\n",
            "vation, we also highlight the downstream applications where trustworthy RAG\n",
            "systems have a significant impact. For more information about the survey, please\n",
            "check our GitHub repository*.\n",
            "†Significant Contribution.\n",
            "*Corresponding Authors.\n",
            "*https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation\n",
            "Preprint. Under review.\n",
            "arXiv:2502.06872v1  [cs.CL]  8 Feb 2025\n",
            "Contents\n",
            "1\n",
            "Introduction\n",
            "3\n",
            "2\n",
            "Preliminaries\n",
            "4\n",
            "2.1 Retrieval Augmented Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "4\n",
            "2.2 Tasks and Evaluations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "5\n",
            "2.3 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "6\n",
            "2.4 Paper Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "8\n",
            "2.5 Notes on the Organization of the Survey\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "8\n",
            "3\n",
            "Reliability of Retrieval Augmented Generation\n",
            "8\n",
            "3.1 Taxonomy of RAG Reliability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "8\n",
            "3.2 Uncertainty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "8\n",
            "3.3 Uncertainty Evaluation\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "10\n",
            "3.4 Robust Generalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "10\n",
            "3.5 Robustness Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "11\n",
            "3.6 Future Directions of RAG Reliability . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "11\n",
            "4\n",
            "Privacy of Retrieval Augmented Generation\n",
            "12\n",
            "4.1 Taxonomy of RAG Privacy\n",
            ". . . . . . . . . . . . . . . . . . . . \n",
            "</Content>\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36manswer_question\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: expert\n",
            "\n",
            "You're welcome! I'm glad I could provide the information you needed. If you have any more questions in the future or need further assistance, feel free to reach out. Have a great day!\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msave_interview\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "\u001b[1;32minterview\u001b[0m:\n",
            "Human: So you said you were writing an article on What are the differences between Modular RAG and Naive RAG, and what are the benefits of using it at production level?\n",
            "AI: Hello, I'm Alex, an analyst delving into the technical intricacies of AI models. Dr. Carter, could you please explain the fundamental differences between Modular RAG and Naive RAG? How do these differences impact the efficiency and accuracy of AI systems?\n",
            "AI: Certainly, Dr. Carter. The key differences between Modular RAG and Naive RAG lie in their structural and operational approaches:\n",
            "\n",
            "1. **Structural Design**:\n",
            "   - **Naive RAG** operates as a monolithic entity. It follows a straightforward \"Retrieve-Read\" framework where relevant documents are retrieved from an external knowledge base and used directly to inform the generative process [3].\n",
            "   - **Modular RAG**, on the other hand, employs a modular design that separates the retrieval and generation processes into distinct, interchangeable modules. This modularity allows for seamless integration with various retrieval modules, enhancing the coherence and relevance of generated responses [3].\n",
            "\n",
            "2. **Flexibility and Optimization**:\n",
            "   - **Naive RAG** has a relatively static retrieval process, often leading to inefficiencies and suboptimal integration with the generative model [3].\n",
            "   - **Modular RAG** leverages its modular design to optimize various components of the system individually, allowing for more flexible and efficient operations [3].\n",
            "\n",
            "3. **Integration with Generative Models**:\n",
            "   - **Naive RAG's** integration between retrieval and generation is less dynamic, which can affect the quality of the output, particularly in complex or nuanced tasks [3].\n",
            "   - **Modular RAG**, by design, allows for better integration and coordination between its modules, leading to improved coherence and relevance in the generated responses [3].\n",
            "\n",
            "**Benefits at Production Level**:\n",
            "- **Efficiency**: The modular approach allows for targeted improvements and optimizations of individual components, resulting in a more efficient system overall [3].\n",
            "- **Scalability**: Modular RAG's design makes it easier to scale and adapt to different use cases or domains by swapping or upgrading specific modules without overhauling the entire system [3].\n",
            "- **Accuracy**: By enhancing the integration and coordination between retrieval and generation, Modular RAG can produce more accurate and context-aware outputs, which is crucial for applications requiring current or specialized knowledge [3].\n",
            "\n",
            "These differences and benefits make Modular RAG a more advanced and adaptable solution compared to Naive RAG, especially in production environments where efficiency, scalability, and accuracy are critical.\n",
            "\n",
            "Sources:\n",
            "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
            "[3] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\n",
            "[3] https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\n",
            "AI: Thank you for that detailed explanation, Dr. Carter. Could you provide a specific example of a situation where Modular RAG has significantly outperformed Naive RAG, particularly in terms of efficiency or accuracy?\n",
            "AI: Certainly, Dr. Carter. A specific example where Modular RAG significantly outperforms Naive RAG can be seen in applications requiring high levels of coherence and relevance in generated responses, such as complex question-answering systems.\n",
            "\n",
            "**Example: Question-Answering Systems**:\n",
            "- In a typical question-answering task, the Naive RAG system retrieves documents based on semantic similarity and uses them directly in generating answers. However, because Naive RAG's retrieval process is static and lacks flexibility, it often results in integrating less relevant or coherent data into the generated response [3].\n",
            "- On the other hand, Modular RAG, with its ability to optimize and swap out different components, can employ specialized retrieval modules that are fine-tuned for specific types of queries or domains. This leads to more precise retrieval of relevant information, which, when integrated with the generative process, results in more accurate and context-aware answers [3].\n",
            "\n",
            "**Benefits Observed**:\n",
            "- **Efficiency**: Modular RAG can process queries faster by utilizing optimized retrieval modules that minimize unnecessary computational overhead [3].\n",
            "- **Accuracy**: The modular approach ensures that only the most relevant data is used in generating responses, significantly reducing errors and improving the quality of information provided [3].\n",
            "- **Scalability and Adaptability**: When dealing with different domains, Modular RAG can easily adapt by integrating domain-specific modules, which is not as feasible with the monolithic structure of Naive RAG [3].\n",
            "\n",
            "This adaptability and precision make Modular RAG particularly beneficial in environments where the accuracy of information is paramount, such as legal, medical, or scientific fields.\n",
            "\n",
            "Sources:\n",
            "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
            "[3] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\n",
            "[3] https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\n",
            "AI: That's a compelling example, Dr. Carter. How do you see the future development of Modular RAG impacting AI research and its applications in the coming years?\n",
            "AI: The future development of Modular RAG is poised to significantly impact AI research and its applications in several key ways:\n",
            "\n",
            "1. **Enhanced Flexibility and Customization**:\n",
            "   - Modular RAG's design allows for greater flexibility in customizing AI systems to meet specific needs. As AI applications become more diverse, the ability to tailor individual components without overhauling entire systems will become increasingly important [3].\n",
            "\n",
            "2. **Improved Scalability**:\n",
            "   - As the demand for AI systems grows, particularly in enterprise and industrial applications, the scalability offered by Modular RAG will be crucial. Its modular structure supports scaling by enabling the integration of more powerful or specialized modules as required, which can handle larger datasets and more complex queries efficiently [3].\n",
            "\n",
            "3. **Broader Adoption Across Domains**:\n",
            "   - The ability to easily adapt Modular RAG systems to different domains, such as healthcare, finance, and legal industries, will likely lead to broader adoption. This adaptability ensures that AI can provide accurate and contextually relevant information across various fields, enhancing its utility and reliability [3].\n",
            "\n",
            "4. **Advancements in Real-Time Data Integration**:\n",
            "   - With ongoing developments in real-time data retrieval and integration, Modular RAG will enhance the ability of AI systems to provide up-to-date and contextually relevant outputs. This will be particularly beneficial in fast-evolving fields where timely information is critical [3].\n",
            "\n",
            "5. **Innovation in AI Research**:\n",
            "   - The modular approach encourages experimentation with different retrieval and generation techniques, fostering innovation. Researchers can explore new algorithms and methodologies within individual modules without disrupting the overall system, leading to continuous improvements and breakthroughs in AI capabilities [3].\n",
            "\n",
            "Overall, Modular RAG represents a significant step forward in making AI systems more efficient, adaptable, and scalable. Its continued development is likely to play a pivotal role in advancing AI research and expanding the range of applications in which AI can be effectively utilized.\n",
            "\n",
            "Sources:\n",
            "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
            "[3] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\n",
            "[3] https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\n",
            "AI: Thank you so much for your help, Dr. Carter! Your insights have been incredibly valuable.\n",
            "AI: You're welcome! I'm glad I could provide the information you needed. If you have any more questions in the future or need further assistance, feel free to reach out. Have a great day!\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mwrite_section\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "## Advancements in Modular and Naive Retrieval-Augmented Generation: Enhancing AI Efficiency and Accuracy\n",
            "\n",
            "### Summary\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) has become a transformative approach in enhancing the capabilities of Large Language Models (LLMs) by integrating external knowledge bases. This integration allows LLMs to overcome inherent limitations such as hallucinations and outdated knowledge. Traditionally, the Naive RAG model has been the foundation, characterized by a straightforward retrieval and generation process. However, the rapid evolution of AI applications has led to the development of Modular RAG, which offers a more sophisticated and flexible framework. The Modular RAG separates the retrieval and generation processes into distinct modules, allowing for optimized and adaptable AI systems. This report synthesizes insights from several sources to provide a comprehensive understanding of the technical differences and advancements between Modular RAG and Naive RAG, focusing on their impact on efficiency and accuracy in AI systems.\n",
            "\n",
            "Key insights from the analysis include:\n",
            "\n",
            "1. **Document 1**: A theory-based approach, Tok-RAG, introduces a novel method for token-level harmonization in RAG, emphasizing the balance between benefit and detriment in next-token prediction by modeling RAG as a fusion of LLM knowledge and retrieved text distributions [1].\n",
            "   \n",
            "2. **Document 2**: CFT-RAG employs entity tree structures and Cuckoo Filters to enhance the efficiency of Tree-RAG, demonstrating significant speed improvements over naive methods while maintaining generative quality [2].\n",
            "\n",
            "3. **Document 3**: MMed-RAG addresses factual hallucinations in medical AI by introducing a domain-aware retrieval mechanism and adaptive context selection, significantly improving factual accuracy in medical vision-language models [3].\n",
            "\n",
            "4. **Document 4**: Highlights the foundational aspects of Naive RAG and its evolution into more advanced frameworks like Modular RAG, underscoring the need for flexible and scalable retrieval methods [4].\n",
            "\n",
            "5. **Document 5**: Emphasizes the modular nature of RAG systems, advocating for reconfigurable frameworks that allow dynamic integration and improved handling of complex queries [5].\n",
            "\n",
            "### Comprehensive Analysis\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) systems have evolved significantly from their initial Naive RAG form, which integrated document retrieval with language model generation in a monolithic structure. The modular approach in RAG systems presents a significant advancement by breaking down the retrieval and generation processes into interchangeable modules. This section examines the technical distinctions and advancements between Naive and Modular RAG, focusing on their implications for AI efficiency and accuracy.\n",
            "\n",
            "#### Naive RAG: Foundation and Limitations\n",
            "\n",
            "- **Basic Framework**: Naive RAG operates on a \"Retrieve-Read\" framework, where relevant documents are retrieved based on semantic similarity and used directly in the generative process. This process often involves the same encoding model, leading to inefficiencies when handling complex information [4].\n",
            "\n",
            "- **Challenges**:\n",
            "  - **Retrieval Redundancy**: Naive RAG can suffer from redundant and noisy retrievals that interfere with LLMs' ability to identify key information, increasing the risk of generating erroneous outputs [4].\n",
            "  - **Limited Adaptability**: The static nature of Naive RAG's retrieval process limits its adaptability to dynamic and real-time data, which is crucial for applications requiring current or specialized knowledge [5].\n",
            "\n",
            "#### Modular RAG: Advancements and Innovations\n",
            "\n",
            "- **Modular Framework**: Modular RAG introduces a reconfigurable architecture that separates retrieval, reasoning, and generation into distinct modules. This separation allows for optimized processing and integration of various retrieval modules, enhancing coherence and relevance in generated responses [5].\n",
            "\n",
            "- **Technical Improvements**:\n",
            "  - **Dynamic Integration**: By decoupling the retrieval and generation processes, Modular RAG facilitates seamless integration of different data types and retrieval strategies, enabling more precise and context-aware outputs [5].\n",
            "  - **Enhanced Retrieval Efficiency**: Advanced approaches like CFT-RAG use hierarchical tree structures and efficient data structures like Cuckoo Filters to accelerate the retrieval process, significantly outperforming naive methods in speed and quality [2].\n",
            "\n",
            "- **Innovative Applications**:\n",
            "  - **Medical AI**: MMed-RAG exemplifies the application of Modular RAG in enhancing factual accuracy within medical AI systems. By utilizing domain-aware retrieval and adaptive context selection, it addresses the issue of factual hallucinations prevalent in medical vision-language models [3].\n",
            "  - **Graph-Based RAG**: The introduction of graph-based methods like KET-RAG demonstrates the potential of Modular RAG in complex domains requiring multi-hop reasoning by constructing triplet-based knowledge graphs, improving retrieval accuracy and reducing indexing costs [1].\n",
            "\n",
            "#### Conclusion\n",
            "\n",
            "The transition from Naive to Modular RAG marks a significant step forward in AI research, enabling more efficient and accurate systems capable of handling complex and dynamic information. Modular RAG's flexible architecture and enhanced retrieval mechanisms provide a robust framework for developing scalable AI systems that meet the demands of modern applications. By addressing the limitations of Naive RAG, Modular RAG sets a new standard for RAG systems, paving the way for future innovations in AI technology.\n",
            "\n",
            "### Sources\n",
            "\n",
            "[1] http://arxiv.org/abs/2406.00944v2  \n",
            "[2] http://arxiv.org/abs/2501.15098v1  \n",
            "[3] http://arxiv.org/abs/2410.13085v1  \n",
            "[4] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/  \n",
            "[5] http://arxiv.org/abs/2407.21059v1  \n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "# Set research topic\n",
        "topic = \"What are the differences between Modular RAG and Naive RAG, and what are the benefits of using it at production level\"\n",
        "\n",
        "# Create initial interview message\n",
        "messages = [HumanMessage(f\"So you said you were writing an article on {topic}?\")]\n",
        "\n",
        "# Configure thread ID\n",
        "config = RunnableConfig(\n",
        "    recursion_limit=100,\n",
        "    configurable={\"thread_id\": random_uuid()},\n",
        ")\n",
        "\n",
        "# Execute graph\n",
        "invoke_graph(\n",
        "    interview_graph,\n",
        "    {\"analyst\": analysts[0], \"messages\": messages, \"max_num_turns\": 5},\n",
        "    config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a4090d7",
      "metadata": {},
      "source": [
        "Display completed interview section in markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2eef4a1f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Advancements in Modular and Naive Retrieval-Augmented Generation: Enhancing AI Efficiency and Accuracy\n",
              "\n",
              "### Summary\n",
              "\n",
              "Retrieval-Augmented Generation (RAG) has become a transformative approach in enhancing the capabilities of Large Language Models (LLMs) by integrating external knowledge bases. This integration allows LLMs to overcome inherent limitations such as hallucinations and outdated knowledge. Traditionally, the Naive RAG model has been the foundation, characterized by a straightforward retrieval and generation process. However, the rapid evolution of AI applications has led to the development of Modular RAG, which offers a more sophisticated and flexible framework. The Modular RAG separates the retrieval and generation processes into distinct modules, allowing for optimized and adaptable AI systems. This report synthesizes insights from several sources to provide a comprehensive understanding of the technical differences and advancements between Modular RAG and Naive RAG, focusing on their impact on efficiency and accuracy in AI systems.\n",
              "\n",
              "Key insights from the analysis include:\n",
              "\n",
              "1. **Document 1**: A theory-based approach, Tok-RAG, introduces a novel method for token-level harmonization in RAG, emphasizing the balance between benefit and detriment in next-token prediction by modeling RAG as a fusion of LLM knowledge and retrieved text distributions [1].\n",
              "   \n",
              "2. **Document 2**: CFT-RAG employs entity tree structures and Cuckoo Filters to enhance the efficiency of Tree-RAG, demonstrating significant speed improvements over naive methods while maintaining generative quality [2].\n",
              "\n",
              "3. **Document 3**: MMed-RAG addresses factual hallucinations in medical AI by introducing a domain-aware retrieval mechanism and adaptive context selection, significantly improving factual accuracy in medical vision-language models [3].\n",
              "\n",
              "4. **Document 4**: Highlights the foundational aspects of Naive RAG and its evolution into more advanced frameworks like Modular RAG, underscoring the need for flexible and scalable retrieval methods [4].\n",
              "\n",
              "5. **Document 5**: Emphasizes the modular nature of RAG systems, advocating for reconfigurable frameworks that allow dynamic integration and improved handling of complex queries [5].\n",
              "\n",
              "### Comprehensive Analysis\n",
              "\n",
              "Retrieval-Augmented Generation (RAG) systems have evolved significantly from their initial Naive RAG form, which integrated document retrieval with language model generation in a monolithic structure. The modular approach in RAG systems presents a significant advancement by breaking down the retrieval and generation processes into interchangeable modules. This section examines the technical distinctions and advancements between Naive and Modular RAG, focusing on their implications for AI efficiency and accuracy.\n",
              "\n",
              "#### Naive RAG: Foundation and Limitations\n",
              "\n",
              "- **Basic Framework**: Naive RAG operates on a \"Retrieve-Read\" framework, where relevant documents are retrieved based on semantic similarity and used directly in the generative process. This process often involves the same encoding model, leading to inefficiencies when handling complex information [4].\n",
              "\n",
              "- **Challenges**:\n",
              "  - **Retrieval Redundancy**: Naive RAG can suffer from redundant and noisy retrievals that interfere with LLMs' ability to identify key information, increasing the risk of generating erroneous outputs [4].\n",
              "  - **Limited Adaptability**: The static nature of Naive RAG's retrieval process limits its adaptability to dynamic and real-time data, which is crucial for applications requiring current or specialized knowledge [5].\n",
              "\n",
              "#### Modular RAG: Advancements and Innovations\n",
              "\n",
              "- **Modular Framework**: Modular RAG introduces a reconfigurable architecture that separates retrieval, reasoning, and generation into distinct modules. This separation allows for optimized processing and integration of various retrieval modules, enhancing coherence and relevance in generated responses [5].\n",
              "\n",
              "- **Technical Improvements**:\n",
              "  - **Dynamic Integration**: By decoupling the retrieval and generation processes, Modular RAG facilitates seamless integration of different data types and retrieval strategies, enabling more precise and context-aware outputs [5].\n",
              "  - **Enhanced Retrieval Efficiency**: Advanced approaches like CFT-RAG use hierarchical tree structures and efficient data structures like Cuckoo Filters to accelerate the retrieval process, significantly outperforming naive methods in speed and quality [2].\n",
              "\n",
              "- **Innovative Applications**:\n",
              "  - **Medical AI**: MMed-RAG exemplifies the application of Modular RAG in enhancing factual accuracy within medical AI systems. By utilizing domain-aware retrieval and adaptive context selection, it addresses the issue of factual hallucinations prevalent in medical vision-language models [3].\n",
              "  - **Graph-Based RAG**: The introduction of graph-based methods like KET-RAG demonstrates the potential of Modular RAG in complex domains requiring multi-hop reasoning by constructing triplet-based knowledge graphs, improving retrieval accuracy and reducing indexing costs [1].\n",
              "\n",
              "#### Conclusion\n",
              "\n",
              "The transition from Naive to Modular RAG marks a significant step forward in AI research, enabling more efficient and accurate systems capable of handling complex and dynamic information. Modular RAG's flexible architecture and enhanced retrieval mechanisms provide a robust framework for developing scalable AI systems that meet the demands of modern applications. By addressing the limitations of Naive RAG, Modular RAG sets a new standard for RAG systems, paving the way for future innovations in AI technology.\n",
              "\n",
              "### Sources\n",
              "\n",
              "[1] http://arxiv.org/abs/2406.00944v2  \n",
              "[2] http://arxiv.org/abs/2501.15098v1  \n",
              "[3] http://arxiv.org/abs/2410.13085v1  \n",
              "[4] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/  \n",
              "[5] http://arxiv.org/abs/2407.21059v1  "
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Markdown(interview_graph.get_state(config).values[\"sections\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "eec5b106",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Advancements in Modular and Naive Retrieval-Augmented Generation: Enhancing AI Efficiency and Accuracy\n",
            "\n",
            "### Summary\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) has become a transformative approach in enhancing the capabilities of Large Language Models (LLMs) by integrating external knowledge bases. This integration allows LLMs to overcome inherent limitations such as hallucinations and outdated knowledge. Traditionally, the Naive RAG model has been the foundation, characterized by a straightforward retrieval and generation process. However, the rapid evolution of AI applications has led to the development of Modular RAG, which offers a more sophisticated and flexible framework. The Modular RAG separates the retrieval and generation processes into distinct modules, allowing for optimized and adaptable AI systems. This report synthesizes insights from several sources to provide a comprehensive understanding of the technical differences and advancements between Modular RAG and Naive RAG, focusing on their impact on efficiency and accuracy in AI systems.\n",
            "\n",
            "Key insights from the analysis include:\n",
            "\n",
            "1. **Document 1**: A theory-based approach, Tok-RAG, introduces a novel method for token-level harmonization in RAG, emphasizing the balance between benefit and detriment in next-token prediction by modeling RAG as a fusion of LLM knowledge and retrieved text distributions [1].\n",
            "   \n",
            "2. **Document 2**: CFT-RAG employs entity tree structures and Cuckoo Filters to enhance the efficiency of Tree-RAG, demonstrating significant speed improvements over naive methods while maintaining generative quality [2].\n",
            "\n",
            "3. **Document 3**: MMed-RAG addresses factual hallucinations in medical AI by introducing a domain-aware retrieval mechanism and adaptive context selection, significantly improving factual accuracy in medical vision-language models [3].\n",
            "\n",
            "4. **Document 4**: Highlights the foundational aspects of Naive RAG and its evolution into more advanced frameworks like Modular RAG, underscoring the need for flexible and scalable retrieval methods [4].\n",
            "\n",
            "5. **Document 5**: Emphasizes the modular nature of RAG systems, advocating for reconfigurable frameworks that allow dynamic integration and improved handling of complex queries [5].\n",
            "\n",
            "### Comprehensive Analysis\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) systems have evolved significantly from their initial Naive RAG form, which integrated document retrieval with language model generation in a monolithic structure. The modular approach in RAG systems presents a significant advancement by breaking down the retrieval and generation processes into interchangeable modules. This section examines the technical distinctions and advancements between Naive and Modular RAG, focusing on their implications for AI efficiency and accuracy.\n",
            "\n",
            "#### Naive RAG: Foundation and Limitations\n",
            "\n",
            "- **Basic Framework**: Naive RAG operates on a \"Retrieve-Read\" framework, where relevant documents are retrieved based on semantic similarity and used directly in the generative process. This process often involves the same encoding model, leading to inefficiencies when handling complex information [4].\n",
            "\n",
            "- **Challenges**:\n",
            "  - **Retrieval Redundancy**: Naive RAG can suffer from redundant and noisy retrievals that interfere with LLMs' ability to identify key information, increasing the risk of generating erroneous outputs [4].\n",
            "  - **Limited Adaptability**: The static nature of Naive RAG's retrieval process limits its adaptability to dynamic and real-time data, which is crucial for applications requiring current or specialized knowledge [5].\n",
            "\n",
            "#### Modular RAG: Advancements and Innovations\n",
            "\n",
            "- **Modular Framework**: Modular RAG introduces a reconfigurable architecture that separates retrieval, reasoning, and generation into distinct modules. This separation allows for optimized processing and integration of various retrieval modules, enhancing coherence and relevance in generated responses [5].\n",
            "\n",
            "- **Technical Improvements**:\n",
            "  - **Dynamic Integration**: By decoupling the retrieval and generation processes, Modular RAG facilitates seamless integration of different data types and retrieval strategies, enabling more precise and context-aware outputs [5].\n",
            "  - **Enhanced Retrieval Efficiency**: Advanced approaches like CFT-RAG use hierarchical tree structures and efficient data structures like Cuckoo Filters to accelerate the retrieval process, significantly outperforming naive methods in speed and quality [2].\n",
            "\n",
            "- **Innovative Applications**:\n",
            "  - **Medical AI**: MMed-RAG exemplifies the application of Modular RAG in enhancing factual accuracy within medical AI systems. By utilizing domain-aware retrieval and adaptive context selection, it addresses the issue of factual hallucinations prevalent in medical vision-language models [3].\n",
            "  - **Graph-Based RAG**: The introduction of graph-based methods like KET-RAG demonstrates the potential of Modular RAG in complex domains requiring multi-hop reasoning by constructing triplet-based knowledge graphs, improving retrieval accuracy and reducing indexing costs [1].\n",
            "\n",
            "#### Conclusion\n",
            "\n",
            "The transition from Naive to Modular RAG marks a significant step forward in AI research, enabling more efficient and accurate systems capable of handling complex and dynamic information. Modular RAG's flexible architecture and enhanced retrieval mechanisms provide a robust framework for developing scalable AI systems that meet the demands of modern applications. By addressing the limitations of Naive RAG, Modular RAG sets a new standard for RAG systems, paving the way for future innovations in AI technology.\n",
            "\n",
            "### Sources\n",
            "\n",
            "[1] http://arxiv.org/abs/2406.00944v2  \n",
            "[2] http://arxiv.org/abs/2501.15098v1  \n",
            "[3] http://arxiv.org/abs/2410.13085v1  \n",
            "[4] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/  \n",
            "[5] http://arxiv.org/abs/2407.21059v1  \n"
          ]
        }
      ],
      "source": [
        "print(interview_graph.get_state(config).values[\"sections\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f982d5",
      "metadata": {},
      "source": [
        "### Parallel Interviewing by `map-reduce`\n",
        "Here's how to implement parallel interviews using map-reduce in LangGraph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ede721fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import List, Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class ResearchGraphState(TypedDict):\n",
        "    \"\"\"State definition for research graph\"\"\"\n",
        "\n",
        "    # Research topic\n",
        "    topic: str\n",
        "    # Maximum number of analysts\n",
        "    max_analysts: int\n",
        "    # Human analyst feedback\n",
        "    human_analyst_feedback: str\n",
        "    # List of questioning analysts\n",
        "    analysts: List[Analyst]\n",
        "    # List of sections containing Send() API keys\n",
        "    sections: Annotated[list, operator.add]\n",
        "    # Report components\n",
        "    introduction: str\n",
        "    content: str\n",
        "    conclusion: str\n",
        "    final_report: str"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3827de29",
      "metadata": {},
      "source": [
        "Let me explain how the `Send()` function is used in LangGraph for parallel interview execution:\n",
        "\n",
        "**Reference**\n",
        "- [LangGraph `Send()`](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d4389d5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.constants import Send\n",
        "\n",
        "\n",
        "def initiate_all_interviews(state: ResearchGraphState):\n",
        "    \"\"\"Initiates parallel interviews for all analysts\"\"\"\n",
        "\n",
        "    # Check for human feedback\n",
        "    human_analyst_feedback = state.get(\"human_analyst_feedback\")\n",
        "\n",
        "    # Return to analyst creation if human feedback exists\n",
        "    if human_analyst_feedback:\n",
        "        return \"create_analysts\"\n",
        "\n",
        "    # Otherwise, initiate parallel interviews using Send()\n",
        "    else:\n",
        "        topic = state[\"topic\"]\n",
        "        return [\n",
        "            Send(\n",
        "                \"conduct_interview\",\n",
        "                {\n",
        "                    \"analyst\": analyst,\n",
        "                    \"messages\": [\n",
        "                        HumanMessage(\n",
        "                            content=f\"So you said you were writing an article on {topic}?\"\n",
        "                        )\n",
        "                    ],\n",
        "                },\n",
        "            )\n",
        "            for analyst in state[\"analysts\"]\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb746ea",
      "metadata": {},
      "source": [
        "## Report Writing\n",
        "\n",
        "Next, we will define the guidelines for writing a report based on the interview content and define a function for report writing.\n",
        "\n",
        "### Define Nodes\n",
        "- Main Report Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8c0d3b46",
      "metadata": {},
      "outputs": [],
      "source": [
        "report_writer_instructions = \"\"\"You are a technical writer creating a report on this overall topic:\n",
        "\n",
        "{topic}\n",
        "\n",
        "You have a team of analysts. Each analyst has done two things:\n",
        "\n",
        "1. They conducted an interview with an expert on a specific sub-topic.\n",
        "2. They write up their finding into a memo.\n",
        "\n",
        "Your task:\n",
        "\n",
        "1. You will be given a collection of memos from your analysts.  \n",
        "2. Carefully review and analyze the insights from each memo.  \n",
        "3. Consolidate these insights into a detailed and comprehensive summary that integrates the central ideas from all the memos.  \n",
        "4. Organize the key points from each memo into the appropriate sections provided below, ensuring that each section is logical and well-structured.  \n",
        "5. Include all required sections in your report, using `### Section Name` as the header for each.  \n",
        "6. Aim for approximately 250 words per section, providing in-depth explanations, context, and supporting details.  \n",
        "\n",
        "**Sections to consider (including optional ones for greater depth):**\n",
        "\n",
        "- **Background**: Theoretical foundations, key concepts, and preliminary information necessary to understand the methodology and results.\n",
        "- **Related Work**: Overview of prior studies and how they compare or relate to the current research.\n",
        "- **Problem Definition**: A formal and precise definition of the research question or problem the paper aims to address.\n",
        "- **Methodology (or Methods)**: Detailed description of the methods, algorithms, models, data collection processes, or experimental setups used in the study.\n",
        "- **Implementation Details**: Practical details of how the methods or models were implemented, including software frameworks, computational resources, or parameter settings.\n",
        "- **Experiments**: Explanation of experimental protocols, datasets, evaluation metrics, procedures, and configurations employed to validate the methods.\n",
        "- **Results**: Presentation of experimental outcomes, often with statistical tables, graphs, figures, or qualitative analyses.\n",
        "\n",
        "To format your report:\n",
        "\n",
        "1. Use markdown formatting.\n",
        "2. Include no pre-amble for the report.\n",
        "3. Use no sub-heading.\n",
        "4. Start your report with a single title header: ## Insights\n",
        "5. Do not mention any analyst names in your report.\n",
        "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
        "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
        "8. List your sources in order and do not repeat.\n",
        "\n",
        "[1] Source 1\n",
        "[2] Source 2\n",
        "\n",
        "Here are the memos from your analysts to build your report from:\n",
        "\n",
        "{context}\"\"\"\n",
        "\n",
        "\n",
        "def write_report(state: ResearchGraphState):\n",
        "    \"\"\"Generates main report content from interview sections\"\"\"\n",
        "    sections = state[\"sections\"]\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    # Combine all sections\n",
        "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
        "\n",
        "    # Generate report from sections\n",
        "    system_message = report_writer_instructions.format(\n",
        "        topic=topic, context=formatted_str_sections\n",
        "    )\n",
        "    report = llm.invoke(\n",
        "        [\n",
        "            SystemMessage(content=system_message),\n",
        "            HumanMessage(content=\"Write a report based upon these memos.\"),\n",
        "        ]\n",
        "    )\n",
        "    return {\"content\": report.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "978dbdf4",
      "metadata": {},
      "source": [
        "- Introduction Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "be9672e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
        "\n",
        "You will be given all of the sections of the report.\n",
        "\n",
        "You job is to write a crisp and compelling introduction or conclusion section.\n",
        "\n",
        "The user will instruct you whether to write the introduction or conclusion.\n",
        "\n",
        "Include no pre-amble for either section.\n",
        "\n",
        "Target around 200 words, crisply previewing (for introduction),  or recapping (for conclusion) all of the sections of the report.\n",
        "\n",
        "Use markdown formatting.\n",
        "\n",
        "For your introduction, create a compelling title and use the # header for the title.\n",
        "\n",
        "For your introduction, use ## Introduction as the section header.\n",
        "\n",
        "For your conclusion, use ## Conclusion as the section header.\n",
        "\n",
        "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
        "\n",
        "\n",
        "def write_introduction(state: ResearchGraphState):\n",
        "    \"\"\"Creates report introduction\"\"\"\n",
        "    sections = state[\"sections\"]\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
        "\n",
        "    instructions = intro_conclusion_instructions.format(\n",
        "        topic=topic, formatted_str_sections=formatted_str_sections\n",
        "    )\n",
        "    intro = llm.invoke(\n",
        "        [instructions, HumanMessage(content=\"Write the report introduction\")]\n",
        "    )\n",
        "    return {\"introduction\": intro.content}\n",
        "\n",
        "\n",
        "def write_conclusion(state: ResearchGraphState):\n",
        "    \"\"\"Creates report conclusion\"\"\"\n",
        "    sections = state[\"sections\"]\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
        "\n",
        "    instructions = intro_conclusion_instructions.format(\n",
        "        topic=topic, formatted_str_sections=formatted_str_sections\n",
        "    )\n",
        "    conclusion = llm.invoke(\n",
        "        [instructions, HumanMessage(content=\"Write the report conclusion\")]\n",
        "    )\n",
        "    return {\"conclusion\": conclusion.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbf3d5e8",
      "metadata": {},
      "source": [
        "- Final Report Assembly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "29bbf7e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def finalize_report(state: ResearchGraphState):\n",
        "    \"\"\"Assembles final report with all components\"\"\"\n",
        "    content = state[\"content\"]\n",
        "\n",
        "    # Clean up content formatting\n",
        "    if content.startswith(\"## Insights\"):\n",
        "        content = content.strip(\"## Insights\")\n",
        "\n",
        "    # Handle sources section\n",
        "    if \"## Sources\" in content:\n",
        "        try:\n",
        "            content, sources = content.split(\"\\n## Sources\\n\")\n",
        "        except:\n",
        "            sources = None\n",
        "    else:\n",
        "        sources = None\n",
        "\n",
        "    # Assemble final report\n",
        "    final_report = (\n",
        "        state[\"introduction\"]\n",
        "        + \"\\n\\n---\\n\\n## Main Idea\\n\\n\"\n",
        "        + content\n",
        "        + \"\\n\\n---\\n\\n\"\n",
        "        + state[\"conclusion\"]\n",
        "    )\n",
        "\n",
        "    # Add sources if available\n",
        "    if sources is not None:\n",
        "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
        "\n",
        "    return {\"final_report\": final_report}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d83bbe53",
      "metadata": {},
      "source": [
        "Each function handles a specific aspect of report generation:\n",
        "- Content synthesis from interview sections\n",
        "- Introduction creation\n",
        "- Conclusion development\n",
        "- Final assembly with proper formatting and structure"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ef82f56",
      "metadata": {},
      "source": [
        "### Building the Report Writing Graph\n",
        "Here's the implementation of the research graph that orchestrates the entire workflow: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c59ca60f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAKgCAIAAAD/C1vLAAAAAXNSR0IArs4c6QAAIABJREFUeJzs3XdcVfX/B/D35XIvl8ve47KHAspeIu49cs/MNHNk01FaaWZlmVY21DLTcuTOWYoLN6CiIAgKgmxk73XhXrj398cpvv4UFRTu4cDr+UePy7nnfO7rQvLic9blKZVKAgAA4Ag1tgMAAAC0AHoLAAC4BL0FAABcgt4CAAAuQW8BAACXoLcAAIBL+J999hnbGQA4QK5QhBZkJlaVFtbVXirO0RUIDQQa4cW57fyxoYZIT10YU15Y01BvIBSx/V0EaAWYbwE8kVKpPJh9f0l8eHW9vKBOmlBZWiqrq6iXV9fLy2SyYllt+39cUldbKq+7XV78R/rdm6X5CqUyrryY7e8rwAvh4bpjgMfJFQ1lchmfePsfJAcamtmKddlO1AqUSiWPxzuQnXy3suR7994CNfzZCpyE3gJ41L2q0o0pt5d28RXz1dnO0iZKZbW6AmGFXGakITIQYOchcAz+4AL4fxqUypSq8s9cAztqaRGRgVDE56lpqQvW3IsqqJOyHQegZTDfAvif39LuTJQ4dqp/EnEVRX2NJDwej+0gAM2F+RbAv7ak3zEWijpVaRGRu67xhaIHOdJqtoMANBfmWwBERAqlslwuU1An/eew/n7sa7au9lod4fQT6PDQWwCUXVMZU1EcZGjOdhDWKJTKmoZ6W7EO20EAng37CQHox5RYD11DtlOwSY3HI6ISWS3bQQCeDb0FnV1RnXS+g7uWupDtICzTVhesSrxRLq9jOwjAM2A/IXR2tQ311Q31bKdoF2LKCvlqav2MJWwHAXgazLegU4sqLVh976YqX7GhoSHi8rkX+Xuxuroq6npYq4b6l5e+SZBB5z3IB1yB3oJOLaw4113XSJWvuOz9eRt+WPXc10splcrxwwMunAtp7Vz/Ci/JLZNhVyG0ax32jgAAzTHb1rVOqVDlK96Ji+7Ze8BzbNjQ0MDn87Mz08tKS7p7+LZBNCKijJrK6nr5KAv7Nhof4MVhvgWdmlqb3Vu2sCDvk6Xzh/R2HdLb9ZMl86qrK6sqywPdzQsLco8d2h3obv7BuzOZNaurq376duVLA717ekmG93Nf/sHc8rJSIjq4d1ugu/nVsAuzXxkR7G0Vfvns5QunJr4UREQrP3470N18z85fWz12d11DPu6dAe0b5lvQeWXVVH557+bqbkFtMfiHC18vLMh9a8HyqqqK6MgILS0dqbTmzQXLNv20euVXGyytbIxNzImopqb6rdkTCvJy5sx/38LS+sjBP0NP//PRp98SUVpaEp/P/+3nb95450N5vczHt0dNTc3AIaOuRVz6/uc/icjO3rnVYzto6Xnrm7b6sACtCL0FnZdUUa+jLmiLkSsryu7ERb/6+jtjJ04noumvvUVEmprihvp6gUAwePhYgeDf1928YW1qcuLOv87aO3QhoksXT0msbHV09YkoLSVJQ6S55oetZub/nuCnpa1bVl7q4ubu5RPYFrGJqLJeFlWaP8TMto3GB3hx2E8InVcXbYOVrm1SADq6+uaWVkcP7jp94vDDyxPv3nbs4tZYWuVlpYcP7BgxehJTWswKLm4ezOO0lKR+A4c3lhbj3t04F1ePtsjMqJbXhxXntt34AC8OvQWdl0zRUNJmn+Kx8be/XNw8Pv3orTdmjiktKWIWJt6NbawlIoq8dkUmqxsyfBzzpVwuT01K6OrqwVRaSXGhW3fvh8fMykyvqix36ebZRpmJSKTO72ti1XbjA7w49BZ0XjKFYtW9G200uLWt/cYtBz78ZG1M9PUDu7cSUUlxYUF+rouLe+M62VlpRGQpsWG+vB19XSaXdXV1J6LUlHtE5ODY9eExE+/eJqKuLt3bKDMR6Qs0cN0xtHPoLei8tNUFBgKNtrizkey/S6BGjJnM4/FkcjkRpSQnEJGx2f8u7GV2GAqE/95iav+e34nIzMKSiNJTkojI3rHLw8OmJt8lImPTNrw0OKas6EZpftuND/DicF4GdGrfuPdqi5vJLpj/ssTK1ssn8EJoiLq6+qBho4lIW1uXiPbs+LWqokKNzx86YpyHVwAR7di6YfyUGceP7Lt0/iQRSWuqiSg1JUnfwNDQyOThYbV0dIlow/dfdHf3sbSy9fFr/TMho8vyh5jipAxo1zDfgk6tul5eLpe17pi1tVKJlW345dDvvl5eUVH606a9rm6eROTa3WvUuJfjY6PWfvlhUmI8EXl4+b37/qfnQ4/PmT7qTlz0og+/IKKkxDtElJaa1HiyRqOXxkz18PL75/Ce9es+Ly8rbt3YzKeZuOkaeeobt/rIAK0I99WFzm7erfNfd+vJdor2Ql+ggeuOoZ1Db0FndyY/k8fj+eibPGmFEf09amub2Jfo7ukTFxv9+HJ9fYPDJ6+3dswmhF0+++mHbzf5lJWNbXZmxuPL+w4YuvKrDU8acFvG3Zk2riYamq0aE6CVobcAqKahXvrkjzLJfZDV5D8TnhpPqWhiOZ/PN7NQxSl5UmlNaXFR08+p8aipbJpisYFh07sBrxbnptdUvuPYhheHAbQK9BYA3S4vzpZWBhp27o/wUCqNMNMCLsB5GQDkoWd0t7IkpqyQ7SCsyaipIBzVAo7AfAvgXxVyWVW9TIPf6S4OOZGXpi/QGG3hwHYQgGZBbwH8T2hBloFAw05Ll+0gqlMqr9NU40s0tdkOAtBc2E8I8D+DTK1P5WdU1svZDqIKMkXDrsxEB7EuSgu4BfMtgEfl10nrFQ3Z0ionbX22s7QVHtFHdyI+cPbuom3AdhaAlkFvATRBrlCsSYoy1dCcKHFSKpW8jnIpboVcFlacYyPW6WMs6SBvCTof/meffcZ2BoB2h8/j9TWWmGhommiILxU9OJGbJlMorMU6ubVVKdUVClLqqAtza6vvVZUTUTt/nF5TEVmSL1XUSzS1T+dnaKkLBpna4KYYwF04vgXwRLZiHXUeb6S53VhLRytNbQOhqKa+/k5FcV5dja5AWCirDSt60CqPz2bdX79ze+uO+e9jdWGFXMbn8ezFurrqwpm2rhMkTgI1/MMHDsN+QgD2JSUlrVy5cu/evWwHAeAA/NkFAABcgt4CAAAuQW8BsE9NTc3WFp/WCNAs6C0A9ikUioyMJj52BAAeh94CaBe0tXHTCoBmQW8BtAtVVVVsRwDgBvQWAPt4PJ6xcdMf5wgAj0BvAbBPqVQWFT3hk4sB4P9DbwGwj8fjOTjg468AmgW9BcA+pVKZmprKdgoAbkBvAQAAl6C3ANjH4/H09PTYTgHADegtAPYplcry8nK2UwBwA3oLgH08Hk9fv8N+tjJA60JvAbBPqVSWlZWxnQKAG9BbAADAJegtAPbxeDyJRMJ2CgBuQG8BsE+pVD548IDtFADcgN4CAAAuQW8BsI/H49nb27OdAoAb0FsA7FMqlWlpaWynAOAG9BYAAHAJeguAfbgfPEDzobcA2If7wQM0H3oLAAC4BL0FwD41NTVbW1u2UwBwA3oLgH0KhSIjI4PtFADcgN4CAAAuQW8BtAva2tpsRwDgBvQWQLtQVVXFdgQAbkBvAbCPx+NZW1uznQKAG9BbAOxTKpVZWVlspwDgBvQWAABwCXoLgH08Hs/IyIjtFADcgN4CYJ9SqSwuLmY7BQA3oLcA2If76gI0H3oLgH24ry5A86G3ANinpqaGzzsGaCb0FgD7FAoFPu8YoJnQWwDs4/F4ZmZmbKcA4AaeUqlkOwNAJzV16tTq6moiqq+vr6ioMDQ0JCKZTHb69Gm2owG0X5hvAbBm1KhR+fn5ubm5hYWFdXV1ubm5ubm5Ojo6bOcCaNfQWwCsmTRpko2NzcNLeDxe37592UsEwAHoLQDWCIXCsWPH8vn8xiU2NjYTJ05kNRRAe4feAmDT5MmTJRIJ85jH4/Xv39/CwoLtUADtGnoLgE1CoXDChAnMlMvGxmbSpElsJwJo79BbACybPHmypaUlM9nC2fAAz6TOdgCA51FQJ82oqZB3lKs4Ame+XHPhgsOIQREleWxnaR266gJHsa6muoDtINAB4fot4JjkqrIt6XcyairddY2KZbVsx4GmNZAyvaq8t7FkSRcftrNAR4PeAi7JrKlcfvfqq9ZddQUabGeBZ4suK0ytLv+2ezCPx2M7C3Qc6C3gjHJ53ayoc0vx9zunxJcXpUurvnTrwXYQ6DhwXgZwxo7MxFEWdmyngJbprmesVCpvlRWyHQQ6DvQWcEZMeZGhQMR2CmgxgZpaanUF2ymg40BvAXcoyVCIw1rcY6qhiTNooBXhPHjgjEKZVIGjsRwkVyjrefVsp4COA/MtAADgEvQWAABwCXoLAAC4BL0FAABcgt4CAAAuQW8BAACXoLcAAIBL0FsAAMAl6C0AAOAS9BYAAHAJegugY7p27tTmLz6qKi9jOwhAK0NvAbyQ/KyMhOhItlM04cCmdVdOHq2Xy59jW7lcdv38KVkdboYL7RF6C+D5XQsNeX/y0JuXQtkO0sqWvzp2w/KFclkd20EAmoDeAnh+0uoqtiO0CWl1NdsRAJ4In2MCHVlFWcmRrT9Hh52vKCk2NLfoPWLcS9PnZKcmfTJzvMTB2a6LS0zEZZlUuvTHra4+AeUlxfs3fX8r7FxtdY3EwfmlV+f2GDiMGWf/pu/DT/5dXlqkpavn2aPPtHeX6ugbhJ089vuaT4no9IGdpw/sNJVYf3/wLBHV19f/s/O3S8cPlRUVGJqY9x45btSMeerqz/i3lpWS9PvXK7LT7tfX11vZO42aMTdwwDAiSk+6+8nM8cOmzszNTEu+HSMUifz6Dpz61hKRWPyUrR5258bVr9+b5eLt/8kvfzJL4iLD1y6Y7eYXtGzDttBDe0/u21ZckG9katbnpQljZr6xeOLg0qJ8InpjSCARzf90ba/hY+5GXd/383fZaclibZ3u/kGvL/1cKNJsmx8awDNgvgUdVmVZ6Wdzppw9tFsmq7N3c6+pLI+NuNTYHw9Sk+Ouhfn2GeQR1MfF27+qvOzzeVMvHz8k1ta1d3N/kJq88ZOF54/tZ1auLi/T0Tfo4uFDCsWVkCO/fbWMiEwsJfau3YnI3Maux6Dh3sH9iUipVG5YvvDQlvV1tVLHbp411ZWHtqzfvOqjZ6YV6+jk52TZdnG1sndKv3dn4yeLUu/GNz57at+O/OzMwIHDNESi0EN7d69f05ytGG5+PUwl1om3buRnZTBLrp45QUS9h4+OvxGx/bvPy0uKvIL6iMTaxfk5ROQd3F+gISIiv76DewwabmIpqamqWLdkfmpCnKtPgKWtQ3riXZQWsAjzLeiwjm7bVPAgyz0weNGajUKRpqxWWl5S3Pismprasp93Wjk4M18e2fZLwYOsAeOmzFryGY/Hy0pJ+uS18Qc2/dD3pYl8Pn/Wh5/zeDwiqq2pWTJleEz4xZrqqq6efgPGTP49Id6zR59XFy1jxom6fC7qcqhtF7dPf92loSmuqa769PWJV88cH/nK63Zd3J6S1sjU4pcT4cyrnNy3ffdPa66fP+ng1p151sza9qvthzU0xRVlJQtG97sScuS1JSv5fP7Tt2LweLy+oyb+9esPF48fmvLmYrms7ualUKFI5Nd3yMV//iKigP7D5n2ymnl3RPTqomWR50+X1tXOXf6llo4eM+erk0pNLa2XrPutcTUAtqC3oMOKDjtPRBPmvsdMDoQiTRNLq8ZnJQ7OjaVFRNFXzjO/kfdu+IZZoqmlXVVeVpCdaWFrn5Zw59iOX9MT71SUlyoVDUqlsjgvR+zYpYkXvXKeiERi8aEtG5glGhqaRJR6N+7pvSWrlZ49uDvs9D9FOQ+UpCCiggdZjc/qGhhpaIqJSFff0NhSkpuRVlqYZ2wuefpWjfqMGHdoy/orIUcnzlsQe/VyTVVFz6GjNLW03AN78dXVw04dE4o0hr/8upnEuslsEjtHU0vrgpysbxfPHT3zja6efs349gO0FfQWdFilRYVEZPqE38UisdbjK0ec/ueR1YQijaTb0V+9PUOpVLoHBhuZWURfOV9WVFhXK21y2LLiAiK6F3PzXszNh5cLhKKnp/1p+YLYiMvGFhL/AUMrSotjwi/W1TY9rREINYioQV7f/K0MTEy9evaNvnL+9rUrV8+eIKJew8cQkZW909Lvt2z77vPQQ3vPHz0wfvY7Y2e92eQrfrxh29avP429eiX26hXfPoPe/uI7ocYz3hFAG0FvQYelpaNTXlxXVligq2/4zJXF2toVJXXf7A2xtHN45Km/Nv/YUF8/Y/HyIZNeJaK8rMyyokKlUtm4glKheGgcHSKatfTzgeOmND9q/oOs2IjLhibma3f/o6Epvhd7Myb84sMv8eJb9Rs9KfrK+dP7dybFResbm3T378ks7+YftHbPiSshR7Z/t+rgbz95BvW2d+n+3/v631AmllYfb/gj4daNzas+iroceu7wvuEvv9b8NwjQinBeBnRYrt4BzFEu5jokuVyWlvDoOQsPrezPHOWSy2VEVC+Xp9yNY56SVtcQkbGFFXOCePb9RCJSNNQTkaaWDhHlZqYRkUKhqK+vd/EKIKLT+3dUlJYwmyfFRj0zam1NFRHpGf27MzD59i0iamhQvPhWzNshIs+gPvrGpvE3ImS1tT2HjFJT+/fffl52Jp/P7zdqontATyLKz84kIk0tLSLKyUxrHCH/QRbzXRoyaToR5WalPfNNAbQRzLegwxo3++2YiIuRF04n3oo0s7LNz84QCEXrDp1teuXX346JuHT1zPG7UddMLa3zs9J5fP4Ph0KFGiIXL7+oy6FbVi938fRLTYyvKCslotyMtK6efg5u3dX4/LjI8I+mj5ZWVS7bsL33iDFnD+56kJ6yeOIgK3vnitKSgpysVdsP2Xft9pSoFjb2OgaGaYl3vnp7hrq6IP5GBBHlZ6Y/fcr1lK14PB6zIzQ24vKgCS8TEZ/PDxw47PT+nUTUe/gYZoS87MylU4Y5dvfS1Te4fe2KulDD0c2DiJw9fHIyUr9b/IaZtY21Y9c5H69a894sgUAosXdKjIkkIjefwBf74QA8P8y3oMOS2Dmu3LzXu1d/uUyefu+uSKwdPGwUM096nJWD84pfd3v17CuT1qYmxInE2sFDRzM7AAdPmj785dfU1NRir1226+K2+JtftHT17sVEEZGppfWcj1cZmVnkZqQqFUqBSENDU7x805/9x0wWijRTE+Jqa2t6DBqhpaP79KhCDdGitT87unncv3M7Pztz9kdf9Bw6qqa6Kjsl6bm36j18rKZYOyv1XuP63fyCiMjG2cXaqSuzpKFe3s0/KCPpbvyNCLsubh98t4k5dWXy/EVePfs2NMhzM1L1DA3rpFJXn8Dy0uJb4Re0dPVnLF7eY9CI5/qZALQC3jP3oQO0E6OuHv/AyVuDz2c7CCcplcp/dm458Ov30977cMTLs1T50tdL8nk8es/RU5UvCh0Y9hMCqEJS3K0jv2980rOvLfnsSeegt4rzx/b/9esPlWVlRmYW/UdPbLsXAlAB9BaAKlSUFMVdD3/Ss9LqyjZ99ZqqKoFA1H/s5Amz32XOJQHgLuwnBM7AfkKOwn5CaF04LwMAALgEvQUAAFyC3gIAAC5BbwEAAJegtwAAgEvQWwAAwCXoLQAA4BL0FgAAcAl6CwAAuAS9BQAAXIL7EwJnOGrpKQi3JeMePo+npy5kOwV0HJhvAWfwiHJrq9lOAS2WUVNpKdZiOwV0HOgt4Iw+RpY50iq2U0CLVTfI/fRM2U4BHQd6CzhjnMSxQFYbWZrPdhBogT1ZSRMsHfWEGmwHgY4Dn2MCHLPw9hWJSGwoFEk0tYl4bMeBptU0yHOk1ddK8960cw82tmA7DnQo6C3gnpN5GVdL8+RKRVp1OdtZnpOiQVFbWyvWEj9phYryCl09XdWGak2mGmI7se4kiaO1Jj6mEloZeguABceOHYuNjf3000+bfHbPnj0bN26cMmXKggULVB4NoL3D8S0AFty9e9fNze1Jz0ZERMhkstOnT4eEhKg2FwAHoLcAWJCQkODq6trkU+Xl5bm5uURUUFDwxx9/JCcnqzwdQLuG3gJggaamZrdu3Zp8Kj4+vqysjHmcnp7+pH2JAJ0WegtA1e7du1dZWfmkZ2/cuNHYW0SUkpKyYsUKVUUD4AD0FoCqpaWl9ejR40nPxsTE8Hj/O79foVBERET88ccfqkoH0N6htwBULTY21tzc/EnPlpSUND5WKpVCoVAgELz++uuqSgfQ3uG+ugCqVl1d/aSDW0RUVlZmamoaEhISHh5uZGTk4uKi2nQA7R3mWwCqdv78eQcHhyc9e/nyZeb097y8vMOHD6s2GgAHYL4FoFI5OTne3t6amprPXLNXr14NDQ0qCQXAJZhvAajU/fv31dWb9feimZnZ5MmT2z4RAMegtwBUKjU19Sk7CR+xY8eOh8+JBwD0FoCqlZaWPulOGY+LjY2NjY1t40QAHIPeAlCpmJiYp5wE/4jp06cbGhq2cSIAjsF5GQAqlZGRYWtr28yVfXx82jgOAPdgvgWgOuXl5VpaWjo6zf1Iquzs7F27drVxKACOQW8BqM6DBw9atN9PIBDs2bOnLRMBcA96C0B1cnNzHR0dm7++mZkZ7gcP8Aj0FoDq5OXl6erqtmiTp9yBF6BzQm8BqE5hYaGJiUmLNlm9enV6enqbJQLgHvQWgOrU1dU1/yR4Rm5ubk5OTpslAuAe9BaA6mRnZ2tpabVok3feecfJyanNEgFwD67fAlCdioqKlh7f6tq1a5vFAeAkzLcAVMfQ0LClvXX+/Pnw8PA2SwTAPegtANVJTk4WCAQt2uTevXsJCQltlgiAe7CfEEB15HJ5S3urR48e9fX1bZYIgHvQWwCq4+Li0tLe8vb2brM4AJyE/YQAqnP37t2WfoRxTExMTExMmyUC4B70FoDqqKmpKRSKFm1y5coV9BbAw7CfEEB1nJ2dW3qwyt3dvfn3jwfoDNBbAKqTm5tbW1vbok369evXZnEAOAn7CQFUx9jYuKW9FRkZmZWV1WaJALgHvQWgOmpqahUVFS3aZOfOndnZ2W2WCIB70FsAqqOvr19WVtaiTfz9/e3s7NosEQD34PgWgOrY2dnV1dW1aJOZM2e2WRwATsJ8C0B1+Hx+S3f67dq1q6WXfAF0bOgtANWxtLRs0fqVlZVbt27l8/ltlgiAe9BbAKqjp6fXopvkyuXy2bNnt2UiAO5BbwGojoWFhUgkav76hoaGr776alsmAuAe9BaA6lhYWERERDR//dTU1OvXr7dlIgDuQW8BqI6mpqavr29JSUkz1z916lR8fHwbhwLgGJ5SqWQ7A0An0rt3by0tLYVCUVVVZWRk9M8//zxl5fDwcIlEguu3AB6G67cAVMHX11epVPJ4PB6PJ5VKmYUDBgx4+lbBwcEqSQfAJdhPCKAK48ePV1dX5/F4jUt0dXX79u379K1OnDjR0vsZAnR46C0AVVi2bJmNjU3jl0ql0tDQ0MfH5ymbSKXSr7/+ukXnHwJ0BugtAFXg8XgffPCBoaFh45JevXo9fROZTLZ69eq2jwbAMegtABXp0aPH4MGDmZtf6OnpPbO39PT0+vTpo6p0AJyB3gJQnSVLltjb2yuVSgMDAz8/v6evHBERcf78eVVFA+AMnE8IHFAsq63vKBdszP9o6cqVK/0GDcivkz59zeNhl93c3J65GmcolUZCkboa/laGF4Xrt6Bd25Qad74w21qsnVNbzXYWVZPLZOrq6ryO8oteSPxCmdRZW3+ixLGPsYTtOMBh6C1op2QKxbxb54ONLOzEOjrqQrbjQOsoltWeK8jqaWQxUeLEdhbgKvQWtFOzokKHm9raaOmwHQRa3+GclAADM1QXPJ8OsgsCOpjDOSkeesYorY5qvKXjtZK8EhkuqYbngd6C9ii2vEhHXcB2CmhDdYqGlOpytlMAJ6G3oD1SKJVmGmK2U0AbshXr5NV2lFMlQbXQW9Ae5dRWKwhHXjuymoaGWkU92ymAk9BbAADAJegtAADgEvQWAABwCXoLAAC4BL0FAABcgt4CAAAuQW8BAACXoLcAAIBL0FsAAMAl6C0AAOAS9BZ0HEm3o49u2ySX1bEdhH0KhSL+RsTx3b8TkbS68lpoyLVzp1plZGl15fHdvx/Y9H2rjAbwHNBb0HF8u/iNg7/9VC/n2F3vSgrzfvr4vXmDA+YP6xF54XSrjCmtrlzz3uun9+0kopiIyxtXLI67HtYqI+c/yNq38duEmJutMhrAc1BnOwBAZ/fjh++mJsQ5uLoLRSJHN3e24wC0d+gtADblZaanJsQ5u3uv/G0v21kAuAG9BR3Nvl++vXkpVF4nc+ru8erC5Ra29kR0ct/23T+tGTPzjUnzFxGRtLp67iBfXUOjX06EE9HcQf5dvXzF2joxEZfV+WpO7t7+/QZf+PtgZnKitp7+sCkzhk2ZyQy+f9P34Sf/Li8t0tLV8+zRZ9q7S3X0DYjohw/fTo6PeWn6nHOH95YVF1raOUx984Nu/kFPj/r3jt8O/Po9ESXH3Zoe5DJryWcDx08lomvnTv2zY3NOeopIW9s7uP/Ut97XNTBkNkm7d+fApu+TbkfzeGpdPLwnzV9k37Ub81RNVcX+Td9HXjhTW1Nj69T1kddKvh39/uShJXm5pta2w6fM6Dd6ErP8WujJQ1vXF+bmCNQFTu6eU9/+wNbZlXmqoqzkyNafo8POV5QUG5pb9B4x7qXpcx4es05a8/kb0zKTEyfMfW/c62+1xk8P4NlwfAs6mvNH9huZWqgLBbevhX2zeK6srlkfBh8TfvHOzasB/Yfw1YXRV85vXvWxtLoqoP/QqvLSXT9+HR12gVmturxMR9+gi4cPKRRXQo789tWyxhEqSor3bfzWrqubR2Dv9MS7373/RkFO1tNf1MzaxqmbJxHpGBh69exrbG5JRKf279j4ycKczDQHN3dNTa3Lxw+tevMVaXU1ESXHx3zxxiuDjSf/AAAgAElEQVRx18Mt7RzNre1uXwtbNf+VjOQEIpLLZV+/9/q5w/vkdXU2jl1yMtIeea2cjFSRSGxqbfsgNXnr1yuObv+VWV4vlzXU13dx99IxMIi7Hr524RxZrZSIKstKP5sz5eyh3TJZnb2be01leWzEJXX1//eX7pbVyzOTE3sMGo7SAlXCfAs6mmU/73T19q+tqfn09Yk5GakJ0Tc8g3o3Z8MVv+4xt7K5fyf2szlTdPUNVm7eKxKLHVzdt3/3+a2wCz69+hPRrA8/5/F4RFRbU7NkyvCY8Is11VViLW1mhFlLP+s/ZjIR7Vm/NmTvtojTx8fOevMprxg4YJiOnsHqd2Y6urp/sG4zEZUXF+3/eZ1IrLXqj4MWtvZKpXLT50sjTv9z8Z+/hk99bfs3n8vrat/+Yl3Q4JFEdP7o/j/Wrjy8deOitT9fPHYwLSHeyrHLsg3bdQ0Mi/NzFowd8PBr9Rg88p0v1hFRXGT42gWzj/3xy4Axk3UNDIOHje41fAyzzg8fvhN1OfRudKRXz75Ht20qeJDlHhi8aM1GoUhTVistLyl+eMC/d/x2LfSkvWu3ectXt/ynBPD80FvQ0dh1cSMikVjsEdQ7JyO14MEzJj2NmOmOsZklEYm0tEViMRFZ2toTUWlRAbNOWsKdYzt+TU+8U1FeqlQ0KJXK4rwcsWMX5lkTSyvmgb1rdyJq/ks3ir0eJpfL9E1MLxw7wCyRVlcRUcrduKK8BxnJCXx19bSE+LSEeCKSyWqJKOXubSKKuXqRiEZMe53ZoygSaz0ysoZIk3ngHhDcxdM3KTYq6XaUX9/BpUX5f+/4LS4yvKQgn8cjImKmidFh54lowtz3hCJNIhKKNBvfHRHlpKfcj7tFRC+/vVT438gAqoHegg5LXSAkovp62QuNwvwuVyqZ68O+enuGUql0Dww2MrOIvnK+rKiwrlb6+EYCIfPS8pa+WnlRIREV5mSH7N328HKhhqisuIiIGurrH31KKCKisqIiIjKTWD02ZBP0DIyIqKa6urqyfOXrU0qL8h1c3bv5BKYkxGck3a2rkRJRaVEhEZlKrJscobqinHlwdPsmN9/Alr5NgBeB3oJOQU1NjYgUSuWLDHL+6L6G+voZi5cPmfQqEeVlZZYVFSpfbMxHiLV1iKjHoBHvrHr0wt4H6SlEpG9ssvGfK49vqG9klEFUWljYnFcpys8hIkMT0xsXz5YW5fv1HbxwzQYiOrptU0bSXeYdaenolBfXlRUW6OobPj6CulBj0dqNW75afvfmtYjT//QcOup53zFAi+G8DOgUdA2MiCg98Q7z5dXQ488xiLS6hoiMLayYMxKz7ycSkaKhNS9zdvHxJ6KoK+dT7sYxS9Lu3amT1hCRhY29npFxWVHhmYO7mafKS4rzMtOZx8xJgCf2bK0qLyOiutpHz0ZhBiGiqMvn0hLixdq6zt29amuqicj0vx2AyXHRRKRQNBCRq3cA02TM/Ufkchmzc5Jh79LNs0fvae8uJaLdG9ZKqytb8ZsA8HSYb0Gn0NXLV12oERcZ/uHLIxvnLi3l4uUXdTl0y+rlLp5+qYnxFWWlRJSbkdbV06+1ckrsHHsPH3vl5NHP506xcXatr5fnpN1/+d2lw6e+pqamNuXNxb99uWznulVn/vpTU0s7Jz2lu3/PRWt/JqJhL7929tDetIQ7C8cPsLC1z8969NDatdCQnIzUulppflYGEU15630NTXFXD18iOnNwV/6DzJKCvLTEO0SUm5lKRONmvx0TcTHywunEW5FmVrb52RkCoWjdobMPj9lzyEsX//7rbtT1v379acb7n7TWNwHg6TDfgk7B0MT8nS/WWdo65Odk8wWCGYuXP8cggydNH/7ya2pqarHXLtt1cVv8zS9aunr3YqJaN+qc5V9Nmr/QxNIq835icW6Oi0+ArZML81SfkePfW/2TvWv34tycrJRkcys7j8B/T5XU1Tdc9vN2N78eDQ2KkoJ8n979Hh5TQ1NzxMuzKktLS/Jybbu4vbPq+4HjpjDnj8xd/pWRmcXtq1eIx1vywxZLW4fUhHi5XCaxc1y5ea93r/5ymTz93l2RWDt42KjHJ5cz3l/BV1cPPbwn7d6d1v0+ADwJr3X3zgO0itnR50Zb2JtpiNkOAm3lTEGWq47BJIkT20GAe7CfEKANJcXdOvL7xic9+9qSz8yecMIeADwJegugDVWUFMVdD3/SszidAeA5oLcA2pBf38G7riaynQKgQ8F5GQAAwCXoLQAA4BL0FgAAcAl6CwAAuAS9BQAAXILeAgAALkFvAQAAl6C3AACAS3DdMXCerEaafeOWQIxP3WWZiZ2NyMSI7RTQ8aG3gPN4DQ0GWtqOLl3ZDtKpCdTVG/hqRWzHgM4AvQWcJ9QS2/l7N7Ado5PjEU+uVBAp2A4CHR96CzhPqaZWrkRtAXQWOC8DAAC4BL0FAABcgt4CAAAuQW8BAACXoLcAAIBL0FsAAMAl6C0AAOAS9BYAAHAJegsAALgEvQUAAFyC3gIAAC5BbwEAAJegtwAAgEvQW9BJnT24Z+5Avzs3rj5zTaVSqZJErfnSm1d9PKuPh0LR3E8VKSsq/H7pW3MG+qxb8ubzvSKAyqC3oJNSkqK+oV6hfNpv9vysjB8+fDv00F4V5vrXyb3bV8ya8NybZ6clmdvaq6k19x/4L58vTYyJeuW9j/qPmfzcLwqgGugt6KSGTJy+7WKMe0DwU9a5cTk06vI5Bzd3FeYiZpp1aOsGXUMjHo/3HJsrFIoHaSkSO4dmrv8gPeXuzauDJ07rP2ayT6/+zUz4HMEAWgUP//9BOzQ7+txoC3szDXEbjX/4942Ht24kot9Cb5YXFa5Z8HpXL7+C7MzMlHuGpubzlq/u4uFzbMfmv379gVnf0MR8/d8XlUrl2YO7zh3eV/AgS0tPf+ikV0fNmFteXPT2S71su7jV18tz01OW/7LT3MrukSXRYRdP7Nr6w+FzJhaSvOzMDyYNGT/nnbGz3lrx2gSxjo5CoUhLjDcys5g4b0HggGENDQ3zBvvVSaXMS8/5eFW/0ZMakzc0NMhqax9+L+pCgUAgfHhJflbG+5OHGplbSquq1IWCXsPGTH5zsbq6OhHdvh52bNumtHt3+HyBb5/+ry/9POLsia2rP3nkbZ4+sDP08N7i3BwjC8uJc9/rMWgEEf2+9tMLRw/49hmUEB1p59Jt2YZtuRlpf23+Mf7mNbmsztHN/d1VP+gZGTfzR3CmIMtVx2CSxOnFfpLQGeHzjqEz8u87+NI/h9QFArGWtry2tjg/Nybi8qjpcwIHDt+9fs3Rbb8s/WGrT6/+J3b9bmZtPXHuQm09fSLasW5V6KE9vn0GjZ75xpWQo/s3rQsaMuJBeioRVZWVvrp4WUVZiVN37/gbEY8sOfrHJrG2romFhIiyU+4RkY1TVzU1tfwHmQ0NDUMmTffs0ef4rq2/frbU1TtAJBb3GTH+7KHd0xd+bGHj4NjN4+HkNy+d3bB84cNLxsx8Y9L8RQ8vyUq9R0TWjl38+gy8fv5UyJ4/jC0sh0ycfi305MYVi6wcu8xasjIt4c6Zg7vc/Hq6eAd49uwTG3H5rc+/Mza3JKI9G9ae3Lt94PipLl7+//y5ZdPnSx27eZpYSLKS7xGRgYnpe6t/JKK8zPSVc6YQjzdx7jvE4+368evIC2cGT5ymqp8hdF7oLeiMLOwcK0qKvXv1J6KC3GwimvLm4oHjphDRgc0/1tc3EJFYR6emqsIzsLdnUG9mZ1rooT3mNnYzP1hRXlRYVysVaIg0tbQzkxKJaM7yLxt3OT6+JCPpro1zV+ZxVkoyEdk4u9TW1NTWVI+Y9vrLb39ARA318kNbNzxIT3H19pfJ6vjq6gPGTBaKNB9J7uYTuOLXXQ8vMTKzeGSdrPvJRDRryadGZpaBA4fNHeQfdz180Phpu35aLRAI5y77SqylnXz7FhHpGxmbW9nI6+pEYnHQ4JE8Hu9BesrJvdt7jxg3a8lnRCStqfpjzcrM5EQjM4us1CRnd+/XPviUeZWNKxbVVFXMWvKZV6++MWGXFA0NWjo6bfPjAvh/0FvQGeVmpMrlMpsurkSUcS+BiGy7uBBRcX6OvK7Wys6RiJjf7M7uPswmibduMpOM90b3JSITS6t3V32vpaOXcT9RoCFy8+3ROPgjS0oK8yrKSns4uTBfZt2/p6mlY2ppnRwfQ0R2Xd2Y5TJZHRFpamkRUdLtKFtn18dLi4jEOro2Tq4PL1EXCh5ZJys1WUdf38jMkoj4fHUej6dUKPIy08uKColo5exJRKSppTPxjYUegb2IKDslycLWgTmWdvvqFSIKHjaKGaqyrIx50fysjDqp1Cu4X+OrJNy6QUTbvv2MviU1Pj942Ci/foNb44cD8AzoLeiMMpMTicjW2YWIMpITeDyetYMzEWUkJRKRbVdXIkq6fYuI7N26M5uoC9SJ6N2vfjQ2l4i1tM2sbZmz9TKTEqwcnPh8/v8G//9LmAmWlaMTEcnlsnu3o2ycuhBRZvI9IrLv2o1ZHnn+lL6xibVj16rystyMtEETmt7h1pz9hOmJd2yd/63Dq6EhSqXSPTCYqbcRL8/qNXwMEZlb2zK9WFFaUlFW6tnz30KqrakmIi0dXeZY2rXQEG09fUc39+grFxq/Y/9+Q9QFTt0853+6tqaqylRixexKBVAB9BZ0Rpn37zXOsdKT7pjb2Gloiokog+mzLq5EJK2uIqLQQ3uUSuWEOe+6+QSqCzWObts0bMqM8uJiNTXeS6/OldXV5mWl9x01sXHkx5cw85j4yKtmljZnDu4uLy4K7D+MiLJSEokoKuw8L5wXfurv/OzMd778kc/nS2uqiSg5Lub80f2GpuZePfs+nPyZ+wmL83MKcrL4AvXLJw5npySf/utPRzePAWOnqAuElrYOl04cNjA1Ewg0zhzcPefjVcz8j4is7B2ZzR3cPIjo4Jb1PQaOvHbuRNb9e/NWrBFqiDKTE5jdm40v5BHU+8LRAxePH7KwsQvZ+8fM91fo6Bu0wc8K4FHoLeiMMpMTdfT1DU3M6+vrs1Lu+/UZ2Licr64usXcioiETX0m4FXls+6+GpuYT5rxrYmn13lc/Hvhl3bZvPtPWM5j27lIiyk65r1AorJ26No78+BI33x6+fQZFh11Iuh1tZmVDRMyxrozke9p6+iG7ttbU1Nh3cV2y7jfPnn2IyMRCMmDM5CshR/du+HbKW+8/klxH36Crvt9T3lrk+TOGJua2zq7bv/tCS1tvyKTpE+a8JxBqENGCNRt2fPfFX5t/VBdo9Bk59t/AaclEZGn/73l9nkG9J81fGHpw790b1yQOzgvXrPfrO4Rpeh19fUMTs8YXmvbOkvo62YVjB+SyOlsnF5QWqAzOg4f2qEXnwSsUiqqKsiaWNyjU+E1coagp1mJ+j7NIqVTOG+QfOGg4M+lh0W9fLrt84vCPR84Zm0tU+bo4Dx6eG+ZbwHnlxUXvju7z+HIrB+fs1OTHl8//dC1zjIdFBTnZ0poqC1t7dmPcvHQm4uwJp26eKi4tgBeB3gLO09bT+2j9H48vb6iv56s38X+4lb2zSnI9Tdb9BCKytG3uLS3ayJWQv7t6+M5ZxvKcD6BFsJ8Q2qO2vl8GsA77CeG54f6EAADAJegtAADgEvQWAABwCXoLAAC4BL0FAABcgt4CAAAuQW8BAACXoLcAAIBL0FsAAMAl6C0AAOAS9BYAAHAJegsAALgEvQUAAFyC3oL2SKKppcbjsZ0C2pCYry7i43OU4Hmgt6A9EvD4udJqtlNAG0qrLpeItNhOAZyE3oL2yEffpKpeznYKaEMaavyu2npspwBOQm9BezTS3C61puJORTHbQaBN7MtKGmJmo6UuZDsIcBI+7xjaKYVSufD2FRcdfStNbVN88HGHIFM0FNRKLxRlT5A4DTCxYjsOcBV6C9q13Vn3zhVmi/nqWTVVbGdpQ0pSNjQ0qHfo8xQ0+GrShgZPPeOJEkcvPRO24wCHobeAA+oUDXKlgu0Ubej+/ftr1qzZunUr20HakpK01QVsh4COoCP/fQcdhoYaX4P4bKdoQxJD4xH9B2rz8Wsd4Nkw3wIAAC7B+YQA7CstLT137hzbKQC4Ab0FwL7CwsIOfnALoPWgtwDYZ2ZmNm/ePLZTAHADjm8BAACXYL4FwL6ysrKTJ0+ynQKAG9BbAOwrKCjYuXMn2ykAuAG9BcA+ExOTV155he0UANyA41sAAMAlmG8BsK+oqOjAgQNspwDgBvQWAPtKSkqOHDnCdgoAbkBvAbDPyMhowoQJbKcA4AYc3wIAAC7BfAuAfUVFRbt372Y7BQA3oLcA2FdSUnL8+HG2UwBwA3oLgH24fgug+XB8CwAAuATzLQD2FRUV7du3j+0UANyA3gJgX0lJybFjx9hOAcAN6C0A9hkaGo4bN47tFADcgONbAADAJZhvAbCvtLT09OnTbKcA4Ab0FgD7CgsLt2/fznYKAG5AbwGwT0dHJzAwkO0UANyA41sAAMAlmG8BsK+2tvb+/ftspwDgBvQWAPsyMzNXrFjBdgoAbkBvAbBPQ0PD1taW7RQA3IDjWwAAwCWYbwGwD8e3AJoPvQXAPhzfAmg+9BYA+3R1dXv27Ml2CgBuwPEtAADgEsy3ANhXWVkZFhbGdgoAbkBvAbAvNzf3559/ZjsFADegtwDYh+NbAM2H41sAAMAlmG8BsK+ysvLq1atspwDgBvQWAPtyc3PXr1/PdgoAbkBvAbBPV1e3V69ebKcA4AYc3wJgzapVq44dO0ZEzD9DHo/HPI6KimI7GkD7hfkWAGumTZtmZWXFNBZTWkSEDz4GeDr0FgBrHB0d/f39H97noaur+9prr7EaCqC9Q28BsGnq1Kk2NjaNX7q5uQUEBLCaCKC9Q28BsMnR0dHPz495bGRkNGvWLLYTAbR36C0Alk2bNs3a2pqIXFxcfH192Y4D0N6htwBYZm9v7+fnp6OjM2PGDLazAHAAzoOH9uXwg/thJXlEypSqCrazqI5CqZDL5BoaGmwHUSl9odBZS/8V6672WrpsZwEuQW9BO7I0PtxEqGkh0rIQafHVeGzHgbZVKZcV1EkvFT14x8EjwNCM7TjAGegtaC/ejwuz09Txx++vzufPzMTxlo4DTa3ZDgLcgONb0C6cyEs31xCjtDqnV21cjuamShvkbAcBbkBvQbtwrSTPSChiOwWwhsfjxZWXsJ0CuAG9Be1CAyktNLXYTgGscRDrPqitZjsFcAN6C9qFjOpKtiMAm6SKhsp6GdspgBvQWwAAwCXoLQAA4BL0FgAAcAl6CwAAuAS9BQAAXILeAgAALkFvAQAAl6C3AACAS9BbAADAJegtAADgEvQWAABwiTrbAQDao5rqqtvXwhQN9T2HvMR2FgD4fzDfAmjC3ZtXN36yMCbi0osMkp+VkRAd2cyVb18PmzvI/8zBXa0+ckt9/e7rH0wZJsWdjqG9Qm8BtIlroSHvTx5681JoM9fPSk6UVlem3o1r9ZFbpKGhIeVubF5mekVZWVuMD/DisJ8QoE1Iq6tatP6Qya8aWVh19+vR6iO3CJ/P//TX3VUV5WYS67Z7FYAXgd4CrmpoaDi5b3vYiSN5D7J0dPU9gnpPeXOxroFhTVXF/k3f37h4VlpZaWZlM+zl1/qNmkhE6Ul3P5k5ftjUmbmZacm3Y4QikV/fgVPfWiISi5kBH6Sn7N34bUL0dT5fYGJp1fhCJ/dt3/3TmjEz35g0fxERSaur5w7y1TU0+uVEOLPCzUuhJ/duy0hOUOMLnLq5T35zcXZK8u9rPiWi0wd2nj6w01Ri/f3Bs095L0e3bTr4209ENHTyjFcXLXtK1LCTx5ocubykeP+m72+FnautrpE4OL/06tweA4c1vmuJg7NdF5eYiMsyqXTKW+/v+ulrU0vrdQfP8Hg8IroScmTzqo99+wxctPbnGcFuCoWCiDafua6lo0dEaffuHNj0fdLtaB5PrYuH96T5i+y7dkuOj/l87lQbZ5fVO48yb2H5zPGT3ljg1bMv85388OWRk+YvGjPzjbb8XwA6KewnBE5SKpXrly3Yt/Hbgtxs+65uAqEw8twp4lG9XL7mvdnnDu8TCITOnr75OdlbV39yav+Oxg1P7duRn50ZOHCYhkgUemjv7vVrmOV52Zmfz5sWE35RJNaysLHLTk1qZpJT+3f8+NE7Sbejza3tTcwtb18LqywrNbGU2Lt2JyJzG7seg4Z7B/d/+iDmNvbWTl0fHbmpqE2OXFVe9vm8qZePHxJr69q7uT9ITd74ycLzx/Y3DvUgNTnuWphvn0EeQX2GTplh5dilICfrXuxN5tnzRw8Q0ZCJ04nIp/dAdYGgccPk+Jgv3ngl7nq4pZ2jubXd7Wthq+a/kpGc4Nzdy9TSOjM5MS87k+m2jKS7F44dYLa6FhpCRM7dPJv5PQRoEcy3gJOiLodGXQ41NDH/9LfdxuYS5m98XX3DKyFHUhPibLu4rdy8WyjSTLod/cUb0w5v/XnguKnMhmbWtl9tP6yhKa4oK1kwut+VkCOvLVnJ5/MPbPq+prI8eNiouctWqwsEV0KObV714TNjlBUV7v95HY/H+/Cn37v792RiSOwciWjAmMm/J8R79ujz6qJlzxynx8BhFaVFO9d9+fDCJqN29fR7fOQj234peJA1YNyUWUs+4/F4WSlJn7w2/sCmH/q+NJFZQU1NbdnPO60cnJkvB094Zds3K6+EHHPx8s9Ou58cd0vi4NzNP4iIFq7ZMH9Yj6ryfw9ubf/mc3ld7dtfrAsaPJKIzh/d/8falYe3bly09uegwSOO7dgcdfHMyOlzLv1zkIhuhV8sKcw3NDG7Fhqixufbu7q38KcK0CyYbwEnRV+5QESDJ77ClBYRMW0RFxlBRH1HTRCKNImoi4ePha19TVVF5v1/50+6BkYammIi0tU3NLaU1MvlpYV5SqUy9uolIpr0xkJmtqGpJW5OjNuR4XK5zD0wmCmtxhitosmoTa4ZfeU8EdXW1Ozd8M2e9WuvnDiiqaVdVV5WkJ35byoH58bSIqLgoaM0tXQiz52S1UovHD1AREMnTX982KK8BxnJCXx19bSE+D3r1+5ZvzbzfiIRpdy9TURBQ0cR0Y2LZ2W10ojTJ7T19BUNDZePH85ITsjNSHMPDNbU0mqtbwXAwzDfAk4qKy4gIlOrR88dqCwrISIDY5PGJTr6hrkZaVUVZXqGRo+sLBBqEFGDvL62pqpOKlXj8xtbsJnKiwqJyFRi8wJvpVkaozb5bGlRIRFFnP7nkeVCkUZdnZSIROL/VyEisbjPyHGnD+yMOHsi7NQxLV294KGjHh+2rLiIiBrq60P2bvt/wwpFRGRl72Tj7HL/TuzpA7tqqirmfbL6nz+3XPj7r1ppDRH1HIzr3qCtoLeAk8TaukRUVlTwyHIdfUMiqigpaVxSVlhARLp6Bk8ZTVNLRygSyWpry0uKH683NTU1IlIolU3E0NElotLCR2M0UioUzX5PLfPwyGJt7YqSum/2hljaOTyyWmV506ezDxr/8ukDO3f/tFZaXTly+hxmYvcITS1tItI3Ntn4z5UmBwkaNDIzOfHQ1vXaevo9Bo2oldbsXPflqf07hSKRT++BL/b+AJ4I+wmBk1x9AonozMHdjZ2RFHeLiNx8ApgT5OSyOuaIS0FOlo6+/uNnPTzC1tmViA7+9lN9fT0RyWprG5/SNTAiovTEO8yXV0OPNz7l4u1HRDERF5lXZ85QkNXVMl1IRLmZaUSkUCiYYVvF4yO7evszR7nkchkR1cvlKc+6DszC1t49IFhaXammpjZ4wstNr2Njr2dkXFZUeObgbmZJeUlxXmZ64wpBQ0YwL9d31EShhqjX8LEisVa9rM6nV3/sJIS2g/kWcFLv4aPPHNz1IDX5gylDJXZOVeVlBTlZ3+wN6Tl01Mn9O+/fiV0ydYSxueX9+Bgimjhv0cPnyDVp/Jx31i6YfeHYgagr54zMzLPu/+98wq5evupCjbjI8A9fHsmcedH4lMTOsc9LEy4fP/Tl/FckDs48Hi87Jem1JSsHjJ3i4NZdjc+Piwz/aPpoaVXlsg3bzaxtW+W9Pz7yuNffjom4dPXM8btR10wtrfOz0nl8/g+HQoUaoqeMM2jCtLjIcJ/eA5+0d1RNTW3Km4t/+3LZznWrzvz1p6aWdk56Snf/novW/sysYGwu6eLpm3w7etC4qUQk1tLuPXzs2UO7g7CTENoS5lvASUKR5ic/7+w/drJIrJWRnCCT1QYPG6Uh1hRqiJZt2N57xLjamur78TFm1nbzVqwZOG7KMwd0Dwh+Z9X3EgfnmsqKmspKz6A+jU8Zmpi/88U6S1uH/JxsvkAwY/Hyhzec/dEXU95830RinZOeUpyf6+ITyJwBYWppPefjVUZmFrkZqUqFUiDSaK33/vjIVg7OK37d7dWzr0xam5oQJxJrBw8d/cxdlN69+htbSIZOfvUp6/QZOf691T/Zu3Yvzs3JSkk2t7LzCOz98Ao9B7/k3at/4+Vugye+oqWr5xHU+wnjAbQCnrKpvfYAKvbKjTPTbboaCFrtlztwy4WiBxKR1gwbF7aDAAdgPyGAKpw7sv/mpTNNPiXS1Frw9XqVJwLgKvQWgCrkpKfEXQ9v8inmPAsAaCb0FoAqvLpoWXNunAEAz4TzMgAAgEvQWwAAwCXoLQAA4BL0FgAAcAl6CwAAuAS9BQAAXILeAgAALkFvAQAAl6C3AACAS3C/DGBZXl5ebGysQFTHIx7bWYA1Gmp8kRqf7RTADegtYEFiYmJsbGxMTExsbCyPx/P09BS+1LtYJtUXCNmOBuzIq6320jNmOwVwAz7HBFShtra2sahiY2Pt7Ow8PT29vLw8PT3NzMyIaGdmYqVc5mtgynZSYMfhnJSY1et9bR18fX19fX3t7e3ZTgTtF3oL2mzBtjQAACAASURBVAqzA5DpqoyMjMai8vT0FIma+Bze0VePv+/krcHHzqJO52Jhto5AOFVPEvWf8vJyHx8fPz8/Hx8fR0dHtgNC+4Legtb0+A5Apqu6du36zG0r5LLZ0ecmSZxsxPhcj85CrlCcL8zWURcsdvZ+eHlJSUl0dPTNmzejo6OLi4t9/+Pk5MReWGgv0FvwQhp3AMbFxd26devxHYAtUl0v/yklNqw4x0fftFhW2zaR2yOFUiGrkzU5De3AKutlCqVytIX9VKsuT1mtrKyscR5WWFjY2GHOzs4qDAvtCHoLWqzJHYBeXl4eHh6t8ptXpmhIqa6QKRpaIyw3ZGdnb9u2bcWKFWwHUSkjochCpMXnteA80vLy8sYOy8vL8/X1DQgI8Pb27tLlac0HHQx6C5rl3r17TFHFxMS0dAcgPFNSUtLKlSv37t3LdhAuqaysjIqKiomJuX79em5urq+vr5+fn6+vLzqsw8N58NA0hUIRExNz69Yt5r82NjZeXl79+/dfsGDBc+wABGh1Ojo6/fr169evX2OH3bx58++//2Y6LCgoyNPTE/sSOyTMt+B/KisrG4sqPj7ey8vL29ub+a+mpibb6TqypKSkb775ZuvWrWwH6QiYDouPjw8LCysoKPD7j4ODA9vRoHWgtzq7wsLCW7duRUdH37p1y9TUVF1dnSkqDw8PtqN1IthP2EbKy8tv/qe0tNTPz8/f39/X19fOzo7taPD8sJ+wM8rOzmaKKjo6uq6uztvb28fHZ+LEiTjJmC1qamq2trZsp+iA9PT0Bg4cOHDgQCIqLS29efPmjRs39uzZIxQKnZ2dAwIC/P39sd+bczDf6ixSU1OjoqKio6Ojo6NFIpGPjw9TV1ZWVmxHA8y3VK2wsDAyMjIyMvLGjRsikcjf3z8gICAgIEBHB9cOcgB6qyNjuurGjRtRUVESicTNzc3Hx8fHx8fYGDeCa1+Sk5M3b9783XffsR2kM8rIyLhx4wZTYxKJJCAgoGfPnv7+/mzngidCb3U0aWlpzIlVN2/eNDAw8PX1ZXbo6+vrsx0NngjzrXYiMTExMjIyNTX1+PHjAQEBQUFBPXr0wEmJ7Q16qyPIzMy8cePGzZs3o6KidHV1mQtZ/Pz8DAwM2I4GzYLeaoeuX79+9erVa9eulZSU9PiPoaEh27kAvcVZJSUlkZGR169fj4yMNDMzc3JyYi66NDIyYjsatFhSUtK33367ZcsWtoNAE4qLi6/9x9jYuH///t7e3tiRyCL0FpfI5XKmq65fv15SUhIQEBAYGBgQEGBubs52NHghmG9xRVJS0q1bty5cuBAbGxv8H1NTfP6OSqG3OCA2Npapq/j4eKarAgMDcc56R5KcnLxly5ZvvvmG7SDQXDKZLPw/enp6PXv27NWrl4+PD9u5OgX0VjtVUFBw9erV8PDwzMxMsVjM1JW3t3czNgXuwXyL05KTkyMiIsLCwhISEoKDgwcMGBAUFKSrq8t2rg4L1x23L1FRUcxfcBUVFUFBQUOHDg0ODu5sH28BwC3Ozs7Ozs4zZ86USqXh4eGJiYlr1qxxdHTs379/3759cYlkq8N8i315eXkRERHh4eEREREeHh49e/YMDg7GbsBOJTk5efv27V999RXbQaDVMIfBLl26pKGh0a9fv759+3br1o3tUB0Eeos18fHxFy9evH//fnJyMtNVPXv2FAqFbOcCFmA/YQeWkpJy8eLFS5cu5efn9+3bd/DgwTgX8QWht1Tt2rVrFy5cuHjxorm5eb9+/fr3749bfAJ6qzMoKiq6dOlScnLyyZMnhw4dOnToUF9fX7ZDcRJ6SxXq6+svXrzI1BXzKVb9+vXDzZagEe7z1KlUVVWdPn36zJkzaWlpgwcPHjp0KD5+oUXQW21ILpefO3cuJCTk+vXrzNSqX79+OMkCHof5VudUXFx89uzZ06dPFxQUMDMwfIB4c6C32sSlS5dCQkIuXbo0bdo0X1/f4OBgthNBu4be6uTy8vJOnz4dExOTl5c3duzYcePG4VD3U6C3WlNMTExISMjJkyf9/f1HjBgxaNAgthMBNyQnJ69fv37Dhg1sBwGWJSUlHT169MiRI4MHDx43bhwu2WwSeqsVZGdn//333ydPnjQ1NR0xYsTw4cPFYjHboYBLMN+CR5w4ceLIkSOlpaXjxo0bO3astrY224naEVx3/EIuXbq0f/9+gUDg4eGxefNmS0tLthMBQEcwcuTIkSNHpqenHzlyZOHChTY2NjNmzMC5xwz01nPavXv3n3/+6ebmNnPmzMDAQLbjAOdpaWmxHQHaHTs7u0WLFhHRsWPH3n//fWtr6zlz5nTv3p3tXCxDb7VMWVnZjh07/vzzz9mzZ//5558mJiZsJ4IOorq6mu0I0H6NGTNmzJgxV65cWb9+vUgkevvttzvzmYforeaqqan55ZdfMjIy/P39b968yXYc6Ggw34Jn6t27d+/evcPDw7/66itra+ulS5fq6emxHYoFamwH4IYdO3YMHTpUIpFs2LDh/9q77/imqvcP4E+SNk3SdO89oFAKpXvQMlp2gbK3bAVEUUBFcSAo6g9FRJYMRRThi0xBFMoqq2WUtnSwuvfeTZu0Wff3x8WIpQtIepL0eb948Wpubm4+TU/y5Jx77r3z5s0jHQdpIexvoU4KDQ09cODAoEGDJk2a1D3n8mDd6sDly5fDw8M5HM6NGzdmzZpFOg5CCAEAjB49Ojo6mqKoKVOmpKenk47TpXCcsE1isXjNmjU2NjanT5/GS+kglWIymU5OTqRTIM0ze/bskJCQ3bt3e3h4dJ+hIOxvte7WrVvTpk2bMGHC6tWrsWghVZPL5Xl5eaRTII3k7Oy8cePGmpqajRs3ks7SRbC/1YrDhw/HxsaePn2adBCEEOqUFStWxMXFTZ8+/ejRo6SzqBz2t1r64osvKIrasWMH6SCoG2EwGHZ2dqRTIM0WGBj4wQcfvPrqq6SDqBzWrf84duyYsbHx7NmzSQdB3QtFUUVFRaRTII3n5+f3+eefr169mnQQ1cK69a+ffvpJR0dn+fLlpIOgbgf7W0hZ7Ozsxo8fv2nTJtJBVAjr1hNXrlwpKyubNGkS6SCoO8L+FlKiQYMGyeXyCxcukA6iKjgv44kvv/wyKiqKdArUTTEYDAaDQToF0h5vvPHGjBkzRo4cSTqISmB/CwBg3759kydP1tHBKo7IoCgKryiElMjAwCAkJOTUqVOkg6gE1i0AgD///HP8+PGkUyCEkNKMHDny/PnzpFOoBNYtKCws1NfXt7e3Jx0EIYSUxtvbOycnh3QKlcC6Bfn5+X369CGdAnVrTCbT2tqadAqkVdhstoODQ0VFBekgyod1C0QiEZ7JCZEll8tLS0tJp0DaxtTUVCQSkU6hfIxuuzd4woQJhYWF9C5xekIXAJibm2vriDBSQ8uWLbt79+7TLZCeoJGYmEg6GtJgvr6+LaanUhQVEhKiNacB6r79rUWLFnE4HAaDwWQymUwmg8GgKMrf3590LtSNLF261Nzc/OlJ8AwGoztfxxYphbu7u+LgCpq5ufmSJUtI51Ka7lu3JkyY0OIMBba2tnPnziWXCHU73t7effr0eXrMg81md5+rUSAVmTVrFofDUdykKMrLy6t///5EQylT961b9F9XT0+P/pmiKB8fH/p7CkJdZt68eebm5vTPFEU5OztHRESQDoU0W2RkpKOjo+KmmZnZ/PnziSZSsm5dtyZNmqTocllZWeHpdFHX8/HxUXS5eDzenDlzSCdC2mD27Nn0l3KKojw9Pfv160c6kTJ167pFd7nYbDa9ZwtnwyMi5s2bZ2ZmBgA9evQYM2YM6ThIG0RGRjo5OVEUZWZmtmDBAtJxlKy7161JkyY5OTlhZwsR5Ovr6+npyeFwXnnlFdJZkPaYN28eh8Px9PT09PQknUXJOp4H/3thRlpDTY2kuasidbWqyiqBQODs4kw6iKpY6/HM2Zwh5nZufGPSWTp2rjT3gaBaJJVWSbW2yT1L2CgsKipy6+VGOkiXstXTN9Jlh5rZ9DM0I52lYxfK8u8LqppksnKxxhwRlZGeYW9vz+VxSQfpLFNdvd58kxn2HbwR2qtbWQ11y5KvhpnbWehx+Tq6KgiJuoKcgiKRoLipMdzcfoKtK+k4bWqWyZYnX+vJN9Jn6VrqcWXQTY8s7FYKhQ0VYpGnodlcR/WdEiWj5CtSbjhw+TyWjqUeT44tU2UaJJIKsehaZdFu7zAXfaO2Vmuzbj2qr96WlTLfSX0bE3pefxRnBZpYTbHrSTpIK+QU9WripbHWLvZcPuksqKudKclxNzBRz9JFUdQbSVcHmFr3MjAhnaW7kFPUb/mPV/b07t3Ga976/i0ZRW3JSppur44fcOiFTbLtcb2yOKOhlnSQVmzJvDfQzA6LVvcUaeOSUleZVFtOOkgrdufc9zI2x6LVlZgMxjS7nt9lJsnb6Fa1XreS6yp1GUwuC69HpW0cePwrFYWkU7TiQnlBH/xo6MaceIbRFep4xeeL5QW99DVgx7CW4enoshiMlPrKVu9tvW4ViBoceXiqWS1kz+GXqd9e5ZzG+n6GZky84G83ZsfRr5I0kU7RUnmz0I6rz8O9+yQ48wzzhIJW72q9btVLxTJKruJUiAAdJrNUJCSdoqVmuUwgkZBOgUjSYTILRY2kU7TULJfXSsSkU3RTMqDq2njxu/vxWwghhDQL1i2EEEKaBOsWQgghTYJ1CyGEkCbBuoUQQkiTYN1CCCGkSbBuIYQQ0iRYtxBCCGkSrFsIIYQ0CdYthBBCmgTrFkIIIU2CdUsJMh8k/7blq4cJd0gHQd1XXsajvw/+VF9TTToIQiqnFnXr/95a9N6M0aLGJ6f+LSvIe5QYRzrUc7hy+tj5owfqqls/5X6HUu7ELB4ecOH4QWXnQq37Y9/OpaOCsh6m0Dcb6mrjr114+c3WVlasmBi+Y+2qzqysrCdV2LPhw8M7vxU1tH7+7M6QSMR3oqPEzf+elB1bZhdTUcsk69l29fLI1y2ZTJb1MLk0P7e+thYAbl86++70UfHXLpHO1XUKMh6LGgXZD1NJB+kuMh8mN9bXFWZnAEBVWfFbkYNP7vvh5TdbVV5aVVaSkZrU8ZrKe1Il+njuxO0fr5SImxVLsGV2MRW1TLKebVcvj/yVIVks1qe7DzXU11nZOQCAqLGBdKKuNnL6XDMb+37+waSDdBeLP/wy4/4930HDAEAqlkiUdKGKHh6eq7f8aG5t2+GaSnxSJRI1tryMCLbMLqailknWs+3q5Smnbn298tXUO7ErN273HzICABKuXz71y64NPx+n792xdtXtS+c+3LY/Pyvt0NaNfoOHCxvqsx6mcDjczccvLB0ZJJfLAWDPhTv3Yq7u2/gpAJw/euD80QOWdg7fHb8IAHXVVUd2fXcv5nJTo9DO1W3c3MXBw0Z3Jlj8tUvnDu/Py3jEZOn27Os5fdk7zr08ACDp5rUTP20vzExnc7megaGz3lptZmkDAFs+eDPjftK4Oa9dPnm4tqrC1tl15rL3+gYMoLcmk8nO/f5LzN9/lBYVGBga9x8waMaydwxNTJ9+xtz0h5/Mn+zW33fdnv/RS9YunJLz+MHXh/+2c+5x6cThc7/vryovM7O0GjxuyoT5S0/t33V871YAGDV93txVHwGAsKH+yK7v7l69KBIIrOwdR89aEBY5VbHl0TPnl+TnZKQksTkc/yHDZr6xmsPjKeWPqEFuXzq3Y+0qxStWX1v97pSRW05e4hsZA8Dlk7/v37R+wsJlAWEjPpk/2c7VzbmXe9LN62KR6P3vf/pj/66H8bcAYOXG7S59+r07fRQA5Gc8njPAHQC2nr5iZmkjlUrPHNh77a8TtZXlphbWg8ZOipy3REenvTdLWnL8htfnAICjm/tXB04BwOLhAW6eXha29gnXo8VNTb36+8x79xNLW4eq8pJWn3Tx8ABRo2DCwmUxf5+qqSqf/OryiQuXtdUYAICiqL//93P0H7/XlJdZ2TtWV1YowtCb+uXGfTrz/7Z9ffbw/oWr1w+bPJN+uf74aWdiTHR9dZWptc2gMZPGzXnt/ZkRNZVlALB0ZBAAvP7p15WlxZ1sme38sipuCGon/tql79cs77BlTluy4tk/98PEOFW0TAA49/svz37wcvUNctIeHN31XXpKIoPB7NXfZ9rrq1x69wWAfV9/euXU0b7+IcW5WYL6WhtH5zGzFgwaM4neWvsfUC3ebj9+9XGLdjUwYsLLv87KGSccMDISAO5efTIUe/XM8ZxH93PTHwJAs0h4L/aqsblFH78g+t6E65cENdXBw8aEjZ/G1TfwHTRMR/fJ5UQtbO1c+vQDAGtH5+DhET6h4fQg72dLZl7/6wSPb+ji4VmUnbHjk5XRp490mCrqyK/fr1menpJo7eBiYW2bcjtGUFsDAPHXLmx+7/W89Edu/X0MTUxvXzq74fU5woZ6+lH11VW/79jk3Nujf9Cg3McPv313aXlxAf0xse2jFb/v2FReUujS20OXzY67HAXPc4Xe+3dv/vLtZ3XVld4DBnN4/KqyYgCwdnRx6NlbsY5UItn49quXT/6uq8t28/IrKy786atPoo78+u8v9fuvZYX5QcNG63E4l04cPrRt43Mk0BZ9fAMBIP7qRfpmzLnTImHDjXOn6Ju3Lv0NACEjx9E3i7IzUm/H+A0e3n/AYHefgF79fYzNLem79PS43iFDAIDHNwweHhE8PEJPj0tR1PaPV574cVtzk6hHXy9ho+DEj9v2bFjTfiS+kYnHM/2SlNsxty6e6x88yM61Z9LNa5vffV0qlbb6pIqHnDmwt7ePfx+foEFjJ7bfGH7b8tXvOzZVlhbbuvQUCRuFgrrOvHSC2pr1r824eOKQWNzs4uEpFNQl37ymo6PjExquq8cBAP8hI4KHR1jY2j1vy2z1l+1MJG3Sy8u38y2zxZ9bRS1TocUHb8b9pM+XvpJ6J9bWuYe1g3PK7ZgNr7+Sl/FIsX5O2oO+AcEevgGFWel7Nnx49c9jnWkGLd5uz7YrZbzMSupv+Q8Zvv8bzr2Ya1KJRFBbk3zrOgBcOX104er192KvNotEYeOnMZlPaqSFrf3nPx9jc568V1du3P766OCGuloA6O3lP3TC9H2P7nsFD6a/sADAH/t/KC8qGDppxsLV6xkMRkFW+icLJh/dtWXIuKksFqutSLWVFUd2bmYwGB9s3dcvIAQAinKz7Jx7AMChbd9QFPXm+k3Bw8fIZLLN7y1NuR1z+eSRyHmL6ccufH99+ITpii+qN8//NXHhsoTrlxKuXzK1sP507yFzazt6g4bGpm0FeFZBVjoABIaPXvLJVwDQJBQCQPCw0fU1lQc2f0Gvc+viX9mPUp16eazbc4jN4aanJH6+dPbJn3YOmzSTXsHKwenLX07qcXn1tdUrxofdOPvHgtXr2nkdtJKRqZlbf9+MlMSsh6k9PDyvnzkBAFdPH4uYuaCmojwtKd7JrY+dcw/6mxOTyfxo5wF7Vzf6sVMXv12UnUl/x+IbGc9d+VHSzWvmNrbLN2yhV4i/dinh+iWnXh6f7j6ox+UJGxs+XTT11oW/xr6yiO6st8rOucfclR99OGd8i+Ub9h21cnBSdLuzHiT19vJ/9kkV5r+zlu4VAcCNs3+01RjKigouHPtNV4/z6e6DLu79ZDLZB7PHlubndvjSndq/q7yowDModNXGHWwOV9wkqquuAoC5qz6Kiz5f09y0+OMv9A2M6JU72TJ12Xrt/LKd+5NqCUNj0860TMX6T/+5VdQyFVp88P7yzWeS5qY3P988YMRYAIg+deTnr9ed/GnHqq930ivMWfHB4LGTAeDm+TM/rF/954G9YeOndfgB1eLt1mq7ennKqVs8fb5PaFhcdNSDhNu5aQ/lMhnfyPhm1F+zl79/6+JZAAgZGalY2Sc0XPHadUbijWj6U/7w9m/oJVx9fkNdbXlhvo2TS1uPSomLlUjE/YMH0kWL/mShJytWFBcaGpsEDYug964NGjMp5XbM4+S7kfCkblnY2tM/0J2/8qICAEi8cQUARkx9hS5aig12nmfQQJaOTkzUaTZHL2LWInp/XgupcTcBYEjkFPol6tXf18bJpSQvJz8znaXDAgBDEzM9Lo9+h5jb2pXk5dRUlCoidR8hI8ZlpCTGX7sgk0kLczL5RsZFuVlpyfE5jx9QFBUycqxiTTtXN8W7qDPo9sbh8U78uJ1eQveHsh+mdubToQUzmyd/Gmf3vjmPH5QVFbb/UR40PELxczuN4XHiHQAYMHyMi3s/uhmz9Tid+u1iogFgyuK36W2yOVxFa29fO2F6eHi+2C+rlTrfMlv8uTv0ki3z6Q/eytKivIxHLB2dnEf3cx7dBwCxuAkAFFMZAYDJfPJteMDIcXu//Ki8qEBQW9PhB9Tzvt1ejNLmZYSMHBsXHZVw9eKDhNsWtvbTlqz4Yf3q6NNHU25dt7J3VLRsAOA+5/6YmsoKuua3WM7m6LXzqLrKCgCwtHNssby+rgYADM0sGIwnY3wGxiYA0FjXyjCLLpsNAFKpBABqq8oBwNL+xYfs7V16vv/dj/u//ezSicPRp47SOzBarCOorQYAE3MLxRIDY9OSvJyG+lojU7Nn4ukBgEzS7UZjACBo+Ojfvv8y/tql+poaBoOx4qtt//f2wiunj5YV5ANA8IgxijU5PP3n2jL9h05Lik9Lin96uS67U4WhLWw2BwBkHe1pfzptO42hpopu3s/dGmsqX/CB7YR5duVO/rJaqfMt83kb50u2zKc/eGurKgFAJpWePbz/6XXYrW2KwWDoGxrVVVU2Ngg6/IB63rfbi1Fa3fIaMJjHN7x+9g+pRDJz+erAoaP/t+ObI7u2SCXi4BFjO7GB/6DkcsXPPD6/vrr5m8NnbZ1dO78FnoEhANRUlLdYbmhkAgD1NVWKJTUVFQDANzbpYIN8QwCorWy5wRaYDCYAwFP5n9Y3YMDX//v7xtk/fvl2w/G9W70GDKK/LysYGJsCQH31v0eP1laUK2IjBUNj034BA1Jux1QUF3oNGNzHN9Bv0LA7l6IkEnFvLz8zq44n9T1N/p/2ZgAAC9//bNikGSoI3vqTtqqdxmBsag4A9B7vZzGYTACgqFa2r29gUFfVXFtR3tYQNyWnnjdM+79Fd6MRLZOrzwcAY3OLHWdudLiyuLlJUFMNAPp8gxduBm21qxejtOO3dNl6/mEjpBKJrh4nbNwUHV3doRNnSMXNLfZDdoirbwAAJfk59N9MKpX28Qmg93LRs0KlEklWJw4ocffxB4Ckm1fTU+/RS3LSHoibmyztHc0sbeqrqxKuX6aPiaOnePT162Cybx/fIAC4cPyQohYqtkyTSsT0OB4AFOfnCBsb6CctzstWrFNamM9iscIip3oGhgBAWWF+i2fx8A2kd2zQhzvci71aXlxgYGz89B5yRBswIpJuDyOmvAIAI6fNoVvI04PSHeLo8wGgqrRE3CSi24O7dyAAnD/yq+LcE+nJCcpN/uyTtrpaO43BqbcHANyM+oveaUpR1NPHxxiZmgIAPf5TX1udevem4q4+PoH0Xi56fYlETK8GAFx9fbrpthoJW2bnqX/LtHF0MTIzr62suHD8EL2krrqqxf5R+g9NUdTp/bvkcrmdcw8DY5MXaAbtt6sXo8zjt0JGjr3+14kBI8bSkz6HTphx+pfd9q69nms/kKtHPyaLlRoXu2bOeFGD4KPtv0xa9GbSzWu3Lvz1MOG2pa1DWUEug8XacuJS+wP6ds49Bo+bcv2vE1+8/oqdqxuDwSjMSl+wet3QiTOmvb5y9+cfbP9kZc9+3pWlxZUlRVb2jmHjp7UfbFDE+AvHDxZlZ7w3Y5Sdc8+Gutry4gK6F8jh8gAg+db1QWMmGZtb2PfoVZiV/v7MMaYWVrlpDxTfmEoL89+fMbpHP29DY5OU2zd02Ho9PPq3fA1HRZ47ciDzQfLqmWPMrW0z7ycBwNQlqxRTLpGC/5DhP3/DMbWw7D9gED3J0L5Hr5K87MChozq/ESNTM0s7h/KigtUzxnANDEZPnztozISLxw8W5Wa9M3W4vYtbfU11eXHBhl9O0FOEleLZJ221+bXTGDwDQ+n9/x/Pn2Tn0lMoqK8qK1E80DMgtCQv55tVrzn06F2Qld4k/PcAmkmvvpl082rclfOP78VZ2TuVFebpsjmbT1zU0dFx6+9bnJf97TtLrRwcHXr0XvLxl50Mo6yXRWuof8tkMpkzlr2z94uPDmzecOHYb1x9fnFuVr+AEMWkDAD4dfOG6NNHaysq6G79tNdXvlgzaL9dvRhlni/Dwy/Y2NxixNTZ9E1jc4uA8FEDRj7fIKGlrcNrH24ws7Ipycum5JQuR8/e1W3t7kPeIUPEoqbsR6kcHj901HiqozEWAHh1zeczlr1rYedQnJtVVVbi7htE7zAcGDFh+YYtds49M+8nCRsaQkZFfvzDb/SXgnawOdxPdh4Inzidw9PPy3gkFjeFjo7U43EBIGjYaJ6BUU1FOX2qquUbvuvt7S9qFNRVV46b85q9S096CzKppG/AgLz0h/fv3nTu5fHet7ue3SXO1uN8tP2XQWMmNQkbM+8nWTk4L1m7UdUDVhqKq6/vOzBs+OTZil2VI6e+4hkYatDRkG8Lb37+nVMvj7qaypqKMr6RiR6X9/Gu38InTGdzuNmPUpuahMHDx+gbGCo3fIsnbXWd9hvDqo07BkaM5/D4lcVF9q496QMQaVOWvBUyKpKlo1uUm+0/ZFjQUwc72jn3WLfnsM/AcIlYkpv2kMPjh46OlMukADD99VXeIUNkMklJXjbdY+t8GPQ0jWiZg8dOfvurrS59+lWVFBdkZVjbO/cPGvT0ClYOzqX5eQ2COjdPn9Wb99LH5r5AM2i/Xb0YBkW1Muz4W0FagVAw1KJTE42QBikUNVypKNrpPYR0YKLXdgAAIABJREFUkP94LKj5LiNpkXMf0kEQMRXNouPFWb/6DScd5D8KRA0fPbj1pqtnJ9bVHvRxx8o6RviFXakssuPoz3N0f/Yu8ud5emHpqff+2LejrXsXrF7f6kRzhF5Mk1C49aO32rp32KSZ9BdShLpYN2yZGly36qsrU+/EtnWv4uzyCCmFTCZpp731Dx7U1l0IqVQ3bJkaXLf8h4w4eOsx6RSou9A3MML2htSQ0lvmqx98/uoHnytxg0pH/jomCCGEUOdh3UIIIaRJsG4hhBDSJFi3EEIIaRKsWwghhDQJ1i2EEEKaBOsWQgghTYJ1CyGEkCbBuoUQQkiTtF63mBQw/zmTMdImDIrSZarhlxX1TIW6DgNA758Lw6sPCoCNLZMQJgVMaL0Mtf4nMWVz6rvlNba1Xq1UbKh+F0wyY3MrxCLSKRBJdVKxgY7atUwLNqe8GVsmGXVSsXkbF1lsvW458wyEMqmKUyECqpub+vKVcwkcJTJlcwx0dEXY5LqxymZRXwO1a5kcJsuRx6+TNHdiXaRkjVKJC6/1q4u1Xrf6GJpyWazHghoVB0NdSiKXX60qnuHQi3SQllgMRqS1y6XyAtJBEDFR5flzW7vSElkMBmOSjetFbJld7kF9lYEuu7dB61fabHPo9kuPAXdryx7UV6syG+o6tZLmA/mPf/QdSjpI6ybaurrqG/1VkkM6COpqjVLJT7kPdnqFqec+zuGWjoEmVieLs0gH6Ubu11cl11V94RHc1gqtX+9YYd2jO0WiBmNdPZ76DT0rC0VRFEUx1fI9oxQclk5mQ62Bju77br52XD7pOO05VJCWWFMhpmR2XH73GqmmQCaXsVhqNzFBpbgsnayGWh5L9+0e/XvyjUnHac/xosxb1aXNcpkjl9+gOS1TJpOxmKw2JjeoI6FUUicV23P46/oEtrNaB3ULAAqEgqzG+mpJk7ITqotHjx7l5OSMGTOGdBBVMdDRc+bx3dT7c0GhokmYKxKUNQvFcjnpLF2noqIiKipq7ty5pIN0Kb6OrhPXoK2xIHVTI27KFtaXNgmb5TLSWTrr119/HTt2rLm5OekgnWXG5rjyDB14Bu2v1vF1Ix14Bh1uRaOdS04X5ZZNtu1BOggCALDg8Cw4PNIpulp6g+xqUtrkD7ARqi8TNseP3fr0NrV1JClt6LR5PbXuw01rB8cQQghpJaxbCCGENAnWLdDR0TEw0OaBUKQR+Hy1njKDNJGZmZlWzjjTwl/pebFYLKlUYyYIIW3FZrNJR0Daprm5WSvbFdYtMDIyqq2tJZ0CdXfV1XisJFIygUBgaNj6KSc0GtYtcHFxefz4MekUqLvj8brdLEqkUrW1tY2NjVi3tJOpqSmbzc7NzSUdBHVrQqGQdASkVVJSUnr1UruTuikF1i0AgLFjx964cYN0CoQQUpq4uLjw8HDSKVQC6xYAwMSJE+Pi4kinQN0Xg8Gws7MjnQJplfT09IiICNIpVALrFtBDhb6+vseOHSMdBHVTFEUVFRWRToG0x7FjxwYMGKCrfhfbUwqsW08sXLjw4MGDhYWFpIOg7ojBYGjl/nNEhEAg2Llz58KFC0kHURWsW//as2fPe++9RzoF6o4oiqqvryedAmmJtWvXbt68mXQKFcK69S9ra+uvv/767bffJh0EIYRe0P/+97+goCA/Pz/SQVQI69Z/ODk5vfHGG++//z7pIKh7YTAYLi4upFMgjbdly5b8/PxZs2aRDqJaWLdacnd3nzVrVmRkJJ78CXUZiqJycvBaz+ilHDhwoGfPnmvWrCEdROWwbrXCx8dnz549ixcvjomJIZ0FIYQ69u2339bU1ERGRpIO0hWwbrXO1tZ2//79x44d++abb0hnQdqPwWC4urqSToE0UlNT07x581xdXVesWEE6SxfButWerVu3urq6Dh8+HDteSKUoisrOziadAmme8+fPT5gw4YMPPpg8eTLpLF1Hh3QAdTd16tRhw4atX7/+zp07c+fOtbS0JJ0IIYSgsbHxxx9/LC8vP3/+POksXQ37Wx0zMTHZunWrn5/f/PnzN2/eLJfLSSdC2obJZDo5OZFOgTTGoUOHIiIivL29v/rqK9JZCMC61VlhYWHnzp2zsbGZO3fuDz/8IBaLSSdC2kMul+fl5ZFOgTTA5cuXly5dWlZWdv369bCwMNJxyMC69Xxmz5596NAhPT29IUOGbNmyRSAQkE6EEOoWEhIS5s6de/78+U8//fSdd94hHYckBkVRpDNoqoMHD8bGxpqbm8+aNcvDw4N0HKTBMjIy9uzZ8+2335IOgtTR1atXf/755169ek2ePBk/arBuKcHZs2cPHz6sq6s7f/78IUOGkI6DNFJ6evq6desOHz5MOghSL6dOnTp48KCTk9OiRYv69u1LOo66wPmEL2vMmDFjxoxJTk6+cuXKmjVrIiMjx40b179/f9K5EEKaKisr6/jx4ydOnJg4ceKmTZvwHGAtYN1SDi8vLy8vrzfeeOPMmTNbtmypra2lCxjOm0edxOfzSUdA5EVFRR0/fry+vn7q1Km3bt1isVikE6kjrFvKxGazp0yZMmXKlPz8/DNnzsyfP9/Z2TkyMnLMmDGkoyF119DQQDoCIqakpOTYsWMnTpwYOHDgm2++6ePjQzqRWsP9W6oVFxd35syZqKio6dOnBwQEdNt5q6h96enpW7du3blzJ+kgqEsJBIKoqKioqCgDAwMfH58pU6Zgt7szsG51BblcfvHixQsXLly/fj08PHzYsGHh4eFsNpt0LqQucF5GtyKTyc6fPx8VFZWSkjJ69OjRo0d7e3uTDqVJsG51KblcfuXKlcuXL1+5ciUgIGDYsGFDhw41MDAgnQsRhnWrm7h27dq5c+eio6NHjRo1evTo0NBQ0ok0EtYtYmJjYy9fvhwdHd27d++hQ4cOGzbM3NycdChERmZm5s8//9w9z9nTHdy8eTM+Pv7IkSNBQUEREREjRowgnUizYd0iLz4+Pjo6uri4uLy8PDQ0NDQ0FAcNuhvsb2kfiURy9erVK1euXLlyxd/fPyIiYujQoRwOh3QubYDzCcnz9/f39/cHgLS0tNjY2O3bt2dmZob+w9jYmHRA1BX09fVJR0BKUFtbe/Xq1ejo6Li4uLCwsPDw8PXr1+PObOXC/pY6amhoiP2Hvb39wIEDQ0ND8fwuWgz7W5quqKiI7lrl5uaGhYUNHToU912pDtYtdXf//v2YmJjY2NiSkpLQ0NCBAwcGBARgJ0zLYN3SUAkJCTdu3IiNjTUyMurbt294eDgO8ncBrFsao6amJjY2Ni4uLjY21srKKigoKDg4ODAwkMFgkI6GXlZGRsa2bdu2b99OOgjqWE1NTcw/+vXrRw+HuLq6ks7VjWDd0khpaWl37ty5fft2XFxcQEBAcHBwUFCQu7s76VzoBWF/S/09ePAgNjY2JiamuLh44D9wngURWLc0Xlxc3O3bt+/cuVNcXEx3woKCgmxsbEjnQs8B+1vqqba29s6dO+np6adPn7a1taUH6vG87MThfEKNFxgYGBgYCAD19fV0J+ynn34yMjJyd3enZypaWFiQzog6QFFUXV0d6RToiYSEhJs3b96+fbu0tDQoKCg8PHzOnDkmJiakc6EnsL+lnQoLC+P/wePx/P39/fz8/P39zczMSEdDrcBxQuJyc3Pv3LlDlytvb+8BAwYEBwfj2Lt6wrql/fLy8uLj4xMSEuLj4w0NDf3/gZMSiZs2bVpmZiaTyQQABoMhl8sZDAZFUYmJiaSjdQt1dXVxcXH0nEAOhxMUFBQSEhIcHKyjgwNRag3rVveSk5Oj6IeZm5uHhIT07dvXx8cH+2FEREdHf/bZZ42NjU8vdHNzw46X6kil0jt37sTFxd29e7e0tDQwMHDAgAFBQUHW1tako6HOwrrVfWVmZiYnJ8fFxd27d4++jIKvr6+vry++gbvSggUL7t+/r7ipp6f39ttvz5gxg2goLZSUlBQXFxcXF5eamhoUFBQYGBgQENC7d2/SudCLwLqFgB7cv3fvXmJiYmJiIoPB8PX19fPz8/HxcXR0JB1Ny126dOnzzz8XCoX0TTc3twMHDujq6pLOpQ0eP34cHx9Pd608PDzoGUx4SUYtgHULtVRSUpKYmJiQkHDv3j2hUDh69GhbW1sfH59evXqRjqadFi1alJKSAgAsFuvdd9+dPn066UQaLDMzMz4+/u7du/Hx8fb29v7+/nTXCs8QqE2wbqH2VFZW3r9/nx5LLCws9Pb29vHxof/H83Qoi6LL5ejoeOzYMRaLRTqRhsnNzVXUKnNzc39//4CAAH9/f7x2sLbCuoU6SygUJiUl3bt3j/6/f//+dAHz8fHBD4iXtHDhwgcPHqxatWrWrFmks2iG3NzchISEhISErKwsqVSqqFU4S7Y7wLqFXlBycjJdwB4+fGhsbOzl5eXt7e3l5WVvb99lGe5Ul+YKBdWS5i57RhWhj7cbP348PSdec/FZusa67B76hh6Gyp+hqqhVCQkJfD7fz88Pj0rsnrBuISXIysqiy1hycnJTU5PXP/r166eiZ6xoFq1KuWHG5thx+boa/lmvTdhMVmlTIwAY6+q966aEGRA5OTmJiYnx8fFVVVVVVVV+/8CLg3dnWLeQklVWVib/4/Hjx6NGjbK2tqbLmLKGE8uahF+k3Y2wcjJl41lN1VRMZTEw4D033xbL165dm5qaeurUqXYem52drehXGRkZ+fr6+vv7+/r6Yq1CNKxbSIWkUmlqampiYiJdxqysrJ53OHHFihVbt25tsXBO/IXZ9r2waKm5S+UFLvqGrzj8e4zU0qVLExMTeTzetWvXWqycmZlJ96sSExNNTEwU/SpTU9MuD47UHdYt1HWeHk4UiUSKGtbOcGJwcLCnp+emTZsU+9tvVpUcL8qcbu/WhcHRixBKJbty7h8LigCAioqKpUuX5ubmMplMiqISEhLoWqXoV5mbmyv6VXgGW9Q+rFuIjKqqKkUNe/ToET2QSJcxAwMDxWr+/v4URbm6uq5bt44ub4cK0opEDYPN7YjGR52yIytli9eg/NSHGzZsKCwspBdSFBUeHp6QkGBpaanoV+E8QNR5WLcQeTKZjB5IpMuYhYUFXcN++OGH8vJyeh0rK6vXXntt0qRJ27KTKYoKMsGTUWmAvbkPBhTVn/xhb0VFxdPLTU1Njx8/bmhoSC4a0mB42mNEHovFok+NSN/Mzs5OTk6+e/fu0x92ZWVl27Zty8nJ0Zk4jFxS9NwOHTpUX1bGYDCePlBdLBZj0UIvDPtbSH35+vq2OJ5JR0fHZvHMsLAw7G9phL25D4ZUNBUlJKekpAgEgrq6OqFQSBcwehcXQi8A+1tI3dFfrfT19U1MTMzNzSV8g048CKmLgQMH9hg1lp6akZmZSZ++WbGvC6EXgHULqakxY8ZwuVwjIyMrKytPT09vb+/evXvb2dnR+7dIp0PPzcLCwsLCYsCAAaSDII2HdQupqbNnzwJAaWkpXg8MIfQ0PEEOUmtYtBBCLWDdQgghpEmwbiGEENIkWLcQQghpEqxbCCGENAnWLYQQQpoE6xZCL0Lc3BR15NcD331JOghC3Q7WLdQtpKfe+2zxzEXh3ismDa0oLvxj386lo4KyHqa88AYFdTUHv/+/1LgY+mZtZcWKieE71q5SXmQ1UlaQ9ygxjnQKhJ7AuoW0X01F+aZVS7Ieprh7+zv27G1ha5/5MLmxvq4wO0NZT1FVXlpVVpKRmqSsDaqP25fOvjt9VPy1S6SDIPQEni8Dab97N6+IGgXj5y2ZvuwdesniD7/MuH/Pd5DSTi3fw8Nz9ZYfza1tlbVB9SFqbCAdAaH/wLqFtNzXK19NvRMLAH8e2Pvngb1fH/77181fPIy/BQArN273HzLi3O+/HNq6cc7KD2PP/1mcm21sbjlq2pyR0+bSD7996dyJn7ZVlBTr6uj29PSa+eZ7Tm59WjxFWnL8htfnAICjm/tXB05dPvn7/k3rW6xjZmWz9dQVAKirrjqy67t7MZebGoV2rm7j5i4OHja6w99i8fAAUaNgwsJlMX+fqqkqn/zq8okLlwHA7ctRZ37dU5ybxeHzfULDZ77xrqGJKQCsnhlRkpfjN3j4o8Q4uVzq6tF/6pIVvTx96K0V5Wb9vvPbR4lxcrmsh0f/aUtW9PLyAwD6pfAbPFzYUJ/1MIXD4U5duvLnr9cBwPmjB84fPWBp5/Dd8YtK+ssg9IJwnBBpuR59vawcnADA1snVO2QIh8fr1d/H2NyyxWoHv/8/PQ4vaGhEfXX1ge++vHn+DL1cKhHLpNJent4GJiapd2K/XvmauEnU4rF8IxMP/2DFTUNTUxf3vvQ/59596YVTFr8FAA11tZ8tmXn9rxM8vqGLh2dRdsaOT1ZGnz7Syd/lzIG9vX38+/gEDRo7EQCijvy645OVxfk5rh6eXK7+9b9ObFj2iqixUbF+YU6G3+BhNk4uD+Nv/9+b8+lx0Yriws+WzL4Xc8XK3snJrc+jxLiv3lqQ9TBV8aiE65cENdXBw8aEjZ9m59LDpU8/ALB2dA4eHuETGv6cLz9Cyof9LaTlpi5+m8Fg/LFv5+DIKeNeeZVeUpSdeffqhadXCxkV+cb6TQDgHzbiu9XLrv51MmRUJACEjh4/MGICvc6WD5YnXL/0MDHOO2TI04+1c+4xd+VHH84ZT98MCBsZEDaS/vns4f25aQ+8Q8MGj50MAH/s/6G8qGDopBkLV69nMBgFWemfLJh8dNeWIeOmslisDn+X+e+sHTZ5Jv1zXVXlkZ2bOTz9DT8ft3FyoShq12fv3zx/5uqZYxEzF9DrrPl+n4WtPQD8vPHT6NNHz/3+6+KPvji5b6dQUDd00oxF738GAKd/3X1s9/cnftz6/paf6EdZ2Np//vMxNodL3xw6Yfq+R/e9ggfPXfXRy/0pEFIOrFsIAQBY/LNrytW9HwBUFBfQN2sqy/78dW9qXGx1eRl9wd7yf+7qUEFW+rFdW3gGRq9+8Dm9JPFGNAA0CYWHt39DL+Hq8xvqassL822cXDrcYNDwCMXPyXdiJBKxsYXlldNH6SX0jqine05MnSe1cGDEhOjTRzMfJAPA/bibADBy6hz6riFjpxzb/f3jpHjFo3xCwxVFCyE1hHULof/Q1WMDgFQsAYBGQd26RTNqKstc+3j29Q3KenQ/L/1hs7DlOGGrJBLxrs/el0jEiz/+0sTiybBkTWUFACgGIRXYHL3ObJPD01f8XFdZQQ/6nT28/z+b0uM8+0C+kQkAiAQCAGioqwEAYzML+i4DE1MAEDc1ScTN9BIuj9eZMAiRgnULoTbdvXqxprLMf8iIlRu3A8Cp/bvy0h928qqVx/duy8947D9kBD3eSOPx+fXVzd8cPmvr7PqS2Xh8AwAIHj5m+YbvOly5qrwEALgGBnQNq6ksq6up4hsZA0BtZRkAcHg8XXZ7tZOSy18yMELKgvMyEGpTk7ARACxt7embGamJACCXyxQrSMTiVh/4OOnu2UP7DIyNF77/n4mFfXwC6L1cEokYAKQSydPDes/F3TcAABJuRCu2kJP2oFkkfHodabOYHpb8++A+AOjj4w8AHv6BAKAYXTx/9CAAePgFt/YkAABcfQMAKMnPAQC5XC6VSl8sMELKgv0thNrUu78fAFw4frCsKL+6vDTn8QMAKMnPBgAOlwcAlSVFhdkZ9q5uTz9K1CjY/fkaulv27btL6IVsPc7a3YcmLXoz6ea1Wxf+ephw29LWoawgl8FibTlxqdXBvfbZOfcYFDHxxrlTny2e4ejWRyqVFOdkznrrfcWkDABY++p0K3uHsoJ8YUM9z8Bo7OxXAWDC/GXx1y5F/f7r43vxDAbkPH6gw9ab/Nrytp7I1aMfk8VKjYtdM2e8qEHw0fZf6PmZCJGC/S2E2uTSp9/ij780s7JJuXUDGIzVW360dXLNfnRfIhHrGxgFhI3kGxk/e7Koy6eOVpYUAYCgtjbn8QP6X276QwCwd3Vbu/uQd8gQsagp+1Eqh8cPHTX+hYfgXvv4y2mvr7Swtc/PfFxVUuzuG+jU0/3pFazs7AuzMwHAb/DwdXv/R88ttHV2/eSH3/oFhJTkZxflZnn4BX3ywwHnXh5tPYulrcNrH24ws7Ipycum5JRu53bFIaQ6jE4O1iOkJrZlJ1MUFWRiTTqIWqOPO956+oqZpQ3BGHtzH3zc27+HvhHBDEj74DghQuSlp977Y9+Otu5dsHq9lZ1D1yZCSH1h3UKIvPrqSvpkVK0SNQq6Ng5Cag3rFkLk+Q8ZcfDWYyVucNPv55S4NYTUCs7LQAghpEmwbiGEENIkWLcQQghpEqxbCCGENAnWLYQQQpoE6xZCCCFNgnULIYSQJsG6hRBCSJNg3UIIIaRJsG4hhBDSJFi3kIYx1eGIZXjtXc3AAODr6JJOgbQN1i2kYVz0DYubGkmnQB0TyqTV4iYrPR7pIEjbYN1CGibE1Lq0qVEgFZMOgjoQX1023tqFdAqkhbBuIQ3DYDA29Rv4R3F2g1RCOgtq0+3qUqFcutC5zcsoI/TC8HrHSCMVixrfSrnmyjO05fI5LLwcj7rQZTCLmxrkFLAYjLXuAaTjIO2EdQtpsKsVhRmNdeXNQtJBXlZjY2NaWpqvry/pIC/LUEfPQo/jpm/sZ2JJOgvSWli3ECIvPT193bp1hw8fJh0EIQ2A+7cQQghpEqxbCCGENAnWLYTIYzAYdnZ2pFMgpBmwbiFEHkVRRUVFpFMgpBmwbiFEHoPB0NXF8yEh1ClYtxAij6IoiQQPo0aoU7BuIUQeg8EwNDQknQIhzYB1CyHyKIqqr68nnQIhzYB1CyHyGAyGq6sr6RQIaQasWwiRR1FUdnY26RQIaQasWwghhDQJ1i2E1AKXyyUdASHNgHULIbUgEolIR0BIM2DdQog8BoNhaYkX/kCoU7BuIUQeRVHl5eWkUyCkGbBuIYQQ0iRYtxAij8lkOjk5kU6BkGbAuoUQeXK5PC8vj3QKhDQD1i2EEEKaBOsWQuQxmUwXFxfSKRDSDFi3ECJPLpfn5OSQToGQZsC6hRBCSJNg3UKIPBwnRKjzsG4hRB6OEyLUeVi3EEIIaRKsWwiRx2Aw7OzsSKdASDNg3UKIPIqiioqKSKdASDNg3UIIIaRJsG4hRB6DwdDV1SWdAiHNgHULIfIoipJIJKRTIKQZsG4hRB6eDx6hzsO6hRB5eD54hDoP6xZCCCFNgnULIbXA5/NJR0BIM2DdQkgtNDQ0kI6AkGbAuoUQeTgvA6HOw7qFEHk4LwOhzsO6hRB5DAbD2dmZdAqENAPWLYTIoygqNzeXdAqENAPWLYTIYzAYJiYmpFMgpBkYFEWRzoBQNzV9+nSxWAwAYrG4vr7e3NwcAEQi0fnz50lHQ0h9YX8LIWKmTJlSUlJSWFhYXl7e1NRUWFhYWFiIB3Ih1D6sWwgRM2PGDHt7+6eXMBiMoUOHkkuEkAbAuoUQSVOnTmWxWIqbDg4Os2bNIpoIIXWHdQshkmbNmuXg4KC4OXLkSFNTU6KJEFJ3WLcQImz27Nl6enp0Z2vatGmk4yCk7rBuIUTY5MmTbW1tAWDUqFFmZmak4yCk7ljr168nnQEhDSOUSXSZrCpxU3xteVpDbZ1EbMPRrxI3xVSVvNjPzWydTF1q0iuznI1MX2Y7VeKmmzWlIqnUUo/bIJWwmaxO/DYIaRg8fguh51DS1Ph/afENMqmPkUVRU0NRc6NYKuWwdCzY3Ca5rKJZSPznSnGTkS67h75Ro1SS21gfbmG/wKmPRC7XZeLgCtISWLcQ6lhyXeXRwgxrjn50RUGjTEo6zvPpxTe21OPacfgLnNxZDKxeSONh3UKoA3lCwccPbpaLm0gHeSkcJmugme2Knl56OHiINBzWLYTalCusO1GUfbmiQKotbxMnroETz+AT9wDSQRB6cVi3EGpdk0y6PPlavkjbLkPMY7IGW9i909OHdBCEXhAOdiPUColc/k16ovYVLQAQymXR5YVxNWWkgyD0grC/hVBLjVLJl2nx8bXlpIOokD5LZ5iFw/Ie/UkHQei5YX8LoZY+fHAzQauLFgA0yqQxVcVnS/BilUjzYN1C6D9EMmm1uLk7jEJUS5orJZo9SRJ1T1i3EPqXnKKOFGaUi0Wkg3SR40WZNyqLSKdA6Plg3ULoX0cLM04WZ5FO0XWa5LKfch9WNneXOo20A9YthP6VXF/VJJeRTtGm5I+/vrv8Y+Vus0EqLW0SKnebCKkU1i2E/mXN4ZGO0J769Cy+i0MnVnwOApmYhacuRBoF2ytCTxQKG2LUeGePRNDYVFLOd3FS+pb35NxvlqlvLxOhFnRIB0BIXRwrzqyTSlS3/dKL1/OOnWnIymNxuVbhA3qveI2po5N76GTJxRt93lmSvvMXQUaOnrmp+ztLzIN96YeUx8Tl/nZCkJmjZ25qN3Y4APBdHZUerLxZ+EhQ7W1sofQtI6QK2N9CqCtk7j2Y+tl3XBurPqvfcJw2tvDU+cLT5wFA1tTckJX7YOMO6xGDe729SCIQPP7+R/ohhafPJ6/5isXV6/Pe6xaDgjL3HgQAfWWPEwKALpNprKun9M0ipCLY30LoiUBTq3NlearYcvW9+zkHjjtOj+z99qsAQMnluQdPNpdXAYBUKNLhcf13fKlnagwAgrSs4rOXAUBUUp62dZ/l4OD+X37AYDAAoCErryE7j21kqPR4IpnMWV/5m0VIRbBuIfRETGWJirZccOJvYDAsBweLa2pFZZX5R/6UNTVbDA4CgMbcAn1XR7poAYBM1KRraAAARWcuyqVStzfm00ULAKQNjXwX5Q8SAkC9pDmmsnigua0qNo6Q0mHdQuiJymZVTQevf5TJ4ujFv/UJUBQA8Bxsvb74wLhvbwBoyMk3D/JVrNlYUMxztAOA2tRHHEtznr0NvZyiqMa8QnoXl9JxWTr1UrEqtoz1JwStAAADeklEQVSQKmDdQuiJQFPr5PoqVWyZkkotBwe5LZsvKqvQMzHmWFswmEwAkDYKm8ur9P/pRVFyeWNugW3EUAAQ19TqmZkotiBIz5YJRaqYlAEAFmxusKm1KraMkCrgvAyEnoiwVv4UcxrHykKQkcM2NTbu25tra8X453iphpx8AOA729M3RcVl8maxvrMDAOgaGYpKy6l/pqfnHjoJAPqqqVs2XH1TNkcVW0ZIFbBuIfREVXOTqWqm1dmMDmvIzk9a81Xx2ejcQyezfv6dXt6YUwAAiv4WXcb0ne0BwHJgoLiq5sFX28qv3b7/xdbya7cAgO+s/MmEAFAkalTFZhFSERwnROgJW46+LpOlii3bTxglrq0vPhddHZ/CtbF0XTCdXt6Qk6/D1+dYmNE36TJGFyeHaeOaqmpKL1wrv37HYlCQZVhI3f00HX2VnM7DnW+sis0ipCJ43UiE/nW6JHtndirpFF3KmWv4rWeooS6bdBCEOgv7Wwj9a4KN6/366mttn+2p/PqdB19te3Y5k60rF7d+ro2A3RuVOL6Xsfu3wlNRzxVg4NE9uob8tja42KUvFi2kWbC/hdB/bM1MOluW19a7QiZqEtfWP7tcLpEwdXVbfYiehSlTR2lfECX1AmljK5cdaScAx8qc0caZc0112CvcfAbgZEKkUbC/hdB/zLTvFVNVUtfG8UwsLofLJTn1TtfQgD4wWSn6GJph0UIaB/tbCLXUKJW8kxqTI2ylX6VN5jj0nufoTjoFQs8N58Ej1JK+ju4sezdDndaH3bSDM48/0lIlR4MhpGpYtxBqRZiF/TgrFz2Gdr5BLNjcb/qGqvlFMhFqC44TItSmW1UlR4oyHgpqSAdRpnmO7oPNbB15SttJhlAXw7qFUHtkFDU/4WKDVCzU/CsCm+ty7Hn8b/qFkg6C0EvBuoVQB6qaRadKchpkkr9Lc0lneUEGOrpLXPqJpNKJtq6ksyD0srBuIdRZlysKDuan6TCZhaIG2X/fOBQwGECpz880Y122oQ6bw9R5r5ePMw+vDIm0BNYthJ5PkajBjsuPKsu7U13mom/oZWR+pbLoXm35UAsHb/X4+VplUYNUEmnj4mloVtEsstDjkn7NEFImrFsIIYQ0iXZO80UIIaStsG4hhBDSJFi3EEIIaRKsWwghhDQJ1i2EEEKaBOsWQgghTfL/F52WllwNdsoAAAAASUVORK5CYII=",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.constants import START, END\n",
        "from langchain_opentutorial.graphs import visualize_graph\n",
        "\n",
        "# Create graph\n",
        "builder = StateGraph(ResearchGraphState)\n",
        "\n",
        "# Define nodes\n",
        "builder.add_node(\"create_analysts\", create_analysts)\n",
        "builder.add_node(\"human_feedback\", human_feedback)\n",
        "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
        "builder.add_node(\"write_report\", write_report)\n",
        "builder.add_node(\"write_introduction\", write_introduction)\n",
        "builder.add_node(\"write_conclusion\", write_conclusion)\n",
        "builder.add_node(\"finalize_report\", finalize_report)\n",
        "\n",
        "# Define edges\n",
        "builder.add_edge(START, \"create_analysts\")\n",
        "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
        "builder.add_conditional_edges(\n",
        "    \"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"]\n",
        ")\n",
        "\n",
        "# Report generation from interviews\n",
        "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
        "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
        "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
        "\n",
        "# Final report assembly\n",
        "builder.add_edge(\n",
        "    [\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\"\n",
        ")\n",
        "builder.add_edge(\"finalize_report\", END)\n",
        "\n",
        "# Compile graph\n",
        "memory = MemorySaver()\n",
        "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
        "\n",
        "# Visualize the workflow\n",
        "visualize_graph(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4444392d",
      "metadata": {},
      "source": [
        "The graph structure implements:\n",
        "\n",
        "**Core Workflow Stages**\n",
        "- Analyst Creation\n",
        "- Human Feedback Integration\n",
        "- Parallel Interview Execution\n",
        "- Report Generation\n",
        "- Final Assembly\n",
        "\n",
        "**Key Components**\n",
        "- State Management using ResearchGraphState\n",
        "- Memory persistence with MemorySaver\n",
        "- Conditional routing based on human feedback\n",
        "- Parallel processing of interviews\n",
        "- Synchronized report assembly\n",
        "\n",
        "**Flow Control**\n",
        "- Starts with analyst creation\n",
        "- Allows for human feedback and iteration\n",
        "- Conducts parallel interviews\n",
        "- Generates report components simultaneously\n",
        "- Assembles final report with all components\n",
        "\n",
        "This implementation creates a robust workflow for automated research with human oversight and parallel processing capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd98ba7",
      "metadata": {},
      "source": [
        "### Executing the Report Writing  Graph\n",
        "\n",
        " Here's how to run the graph with the specified parameters: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "32489294",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mcreate_analysts\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "affiliation='OpenAI Research Labs' name='Dr. Clara Jensen' role='Modular RAG Specialist' description='Dr. Jensen focuses on the architectural differences between Modular RAG and Naive RAG, emphasizing the modularity aspect that allows for more scalable and adaptable AI systems. She is interested in how modularity impacts the ease of updates and integration of new components, making AI systems more robust at the production level.'\n",
            "affiliation='Tech Innovations Journal' name='Mr. Alex Patel' role='AI Production Efficiency Analyst' description='Mr. Patel analyzes the benefits of implementing Modular RAG in production environments. His focus is on the efficiency gains, such as reduced computational overhead and improved response times, that Modular RAG offers over Naive RAG when deployed in real-world applications.'\n",
            "affiliation='Future Tech Enterprises' name='Ms. Emily Tran' role='AI System Integration Consultant' description=\"Ms. Tran's expertise lies in the integration of AI systems within existing technological infrastructures. She provides insights into how Modular RAG can be seamlessly integrated into current workflows, highlighting its adaptability and the ease with which it can be customized to meet specific production needs compared to Naive RAG.\"\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36m__interrupt__\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Set input parameters\n",
        "max_analysts = 3\n",
        "topic = \"Explain how Modular RAG differs from traditional Naive RAG and the benefits of using it at the production level.\"\n",
        "\n",
        "# Configure execution settings\n",
        "config = RunnableConfig(\n",
        "    recursion_limit=30,\n",
        "    configurable={\"thread_id\": random_uuid()},\n",
        ")\n",
        "\n",
        "# Prepare input data\n",
        "inputs = {\"topic\": topic, \"max_analysts\": max_analysts}\n",
        "\n",
        "# Execute graph until first breakpoint\n",
        "invoke_graph(graph, inputs, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2794ed52",
      "metadata": {},
      "source": [
        "Let's add `human_feedback` to customize the analyst team and continue the graph execution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "43f717a3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '82ce81ef-fef9-4fd6-8792-110ca8ce00f4',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1eff4c3d-61f8-6f44-8002-9a149fe150f5'}}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add new analyst with human feedback\n",
        "graph.update_state(\n",
        "    config,\n",
        "    {\"human_analyst_feedback\": \"Add Prof. Jeffrey Hinton as a head of AI analyst\"},\n",
        "    as_node=\"human_feedback\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "af4526f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mcreate_analysts\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "affiliation='University of Toronto and Google' name='Prof. Jeffrey Hinton' role='Head of AI Analyst' description='Prof. Hinton leads the discussion on cutting-edge AI developments, focusing on improving efficiency and scalability in AI systems. His interest lies in bridging fundamental AI research with practical, production-level applications, particularly in the context of RAG models.'\n",
            "affiliation='AI Research Lab, XYZ Corporation' name='Dr. Emily Chen' role='Analyst on Modular RAG vs. Naive RAG' description='Dr. Chen specializes in the differences between Modular and Naive RAG models. Her focus is on the architectural variations and their implications for performance and adaptability in production environments. She examines the benefits of modular design in terms of flexibility and maintenance.'\n",
            "affiliation='Tech Innovation Institute' name='Mr. Alan Thompson' role='Analyst on Production-Level Benefits' description='Mr. Thompson explores the advantages of implementing Modular RAG in production scenarios. His analysis includes operational efficiency, cost-effectiveness, and the ability to integrate modular AI systems with existing infrastructures, highlighting the scalability and robustness of Modular RAG.'\n",
            "affiliation='Institute of Computational Learning' name='Dr. Sofia Martinez' role='Analyst on AI System Scalability' description=\"Dr. Martinez investigates the scalability of AI systems, with a focus on how Modular RAG can enhance scalability compared to traditional methods. Her work emphasizes the modular approach's ability to support larger datasets and more complex tasks without significant performance degradation.\"\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36m__interrupt__\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Continue graph execution\n",
        "invoke_graph(graph, None, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f53e4c9",
      "metadata": {},
      "source": [
        "Let's complete the human feedback phase and resume the graph execution: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "05725a6d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '82ce81ef-fef9-4fd6-8792-110ca8ce00f4',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1eff4c3d-b56e-6e08-8004-2cf6f6cec82e'}}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# End human feedback phase\n",
        "graph.update_state(config, {\"human_analyst_feedback\": None}, as_node=\"human_feedback\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e2f4ee1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello, I'm Alex, an analyst keen to delve into the intricate details of AI systems, particularly the nuances in Retrieval-Augmented Generation (RAG) models. Prof. Hinton, could you please explain how Modular RAG differs from traditional Naive RAG, and what are the specific benefits of using Modular RAG at the production level?\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello, my name is Alex Johnson, and I'm an analyst specializing in AI and machine learning technologies. I'm interested in learning more about the scalability of AI systems and specifically how Modular RAG can enhance scalability compared to traditional methods. \n",
            "\n",
            "Dr. Martinez, could you explain how Modular RAG differs from traditional Naive RAG in terms of system design and scalability?\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello, I'm Alex, an analyst exploring the differences between Modular RAG and Naive RAG models. I'm particularly interested in their architectural variations and how these differences impact performance and adaptability in production environments. Could you explain the key differences between Modular RAG and Naive RAG, and how these differences translate to specific benefits in production?\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello, Mr. Thompson. I'm Emily Carter, an analyst keen to delve into the nuances of Modular RAG and its production-level benefits. Let's start with the basics: Could you explain how Modular RAG differs from traditional Naive RAG?\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
            "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. Modular RAG is an advanced form of Retrieval-Augmented Generation that leverages a modular design to separate and optimize various components of the system. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. Seamless Integration: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\"/>\n",
            "Naive RAG established the groundwork for retrieval-augmented systems by combining document retrieval with language model generation. For example, in a question-answering task, RECALL ensures that a RAG system accurately incorporates all relevant points from retrieved documents into the generated answer. Vector databases play a crucial role in the operation of RAG systems, providing the infrastructure required for storing and retrieving high-dimensional embeddings of contextual information needed for LLMs. These embeddings capture the semantic and contextual meaning of unstructured data, enabling precise similarity searches that underpin the effectiveness of retrieval-augmented generation. By integrating retrieval into generation, RAG systems deliver more accurate and context-aware outputs, making them effective for applications requiring current or specialized knowledge.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.superteams.ai/blog/how-to-implement-naive-rag-advanced-rag-and-modular-rag\"/>\n",
            "Naive RAG is a paradigm that combines information retrieval with natural language generation to produce responses to queries or prompts. In Naive RAG, retrieval is typically performed using retrieval models that rank the indexed data based on its relevance to the input query. These models generate text based on the input query and the retrieved context, aiming to produce coherent and contextually relevant responses. Advanced RAG models may fine-tune embeddings to capture task-specific semantics or domain knowledge, thereby improving the quality of retrieved information and generated responses. Dynamic embedding techniques enable RAG models to adaptively adjust embeddings during inference based on the context of the query or retrieved information.\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
            "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. Modular RAG is an advanced form of Retrieval-Augmented Generation that leverages a modular design to separate and optimize various components of the system. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. Seamless Integration: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.superteams.ai/blog/how-to-implement-naive-rag-advanced-rag-and-modular-rag\"/>\n",
            "Naive RAG is a paradigm that combines information retrieval with natural language generation to produce responses to queries or prompts. In Naive RAG, retrieval is typically performed using retrieval models that rank the indexed data based on its relevance to the input query. These models generate text based on the input query and the retrieved context, aiming to produce coherent and contextually relevant responses. Advanced RAG models may fine-tune embeddings to capture task-specific semantics or domain knowledge, thereby improving the quality of retrieved information and generated responses. Dynamic embedding techniques enable RAG models to adaptively adjust embeddings during inference based on the context of the query or retrieved information.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\"/>\n",
            "Retrieval-augmented generation (RAG) has emerged as a promising solution incorporating knowledge from external databases. RAG enhances LLMs by retrieving relevant document chunks from the external knowledge base through semantic similarity calculation. The Naive RAG follows a traditional process that includes indexing, retrieval, and generation, also characterized as a “Retrieve-Read” framework. Retrieval: Upon receipt of a user query, the RAG system employs the same encoding model utilized during the indexing phase to transform the query into a vector representation. RAG enhances LLMs by retrieving relevant document chunks from the external knowledge base through semantic similarity calculation. Naive RAG has several limitations, including Retrieval Challenges and Generation Difficulties.\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
            "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. Modular RAG is an advanced form of Retrieval-Augmented Generation that leverages a modular design to separate and optimize various components of the system. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. Seamless Integration: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\"/>\n",
            "Naive RAG established the groundwork for retrieval-augmented systems by combining document retrieval with language model generation. For example, in a question-answering task, RECALL ensures that a RAG system accurately incorporates all relevant points from retrieved documents into the generated answer. Vector databases play a crucial role in the operation of RAG systems, providing the infrastructure required for storing and retrieving high-dimensional embeddings of contextual information needed for LLMs. These embeddings capture the semantic and contextual meaning of unstructured data, enabling precise similarity searches that underpin the effectiveness of retrieval-augmented generation. By integrating retrieval into generation, RAG systems deliver more accurate and context-aware outputs, making them effective for applications requiring current or specialized knowledge.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://www.techsling.com/how-are-modular-and-advanced-rags-different/\"/>\n",
            "There are three different kinds of RAG, naive, advanced and modular. Large language models (LLMs) have transformed AI, excelling in natural language tasks such as those performed by ChatGPT, Bard, and Claude. ... Key Differences between Modular and Advanced RAG Flexibility and Modularity. ... Benefits of Advanced RAG Optimized Performance.\n",
            "</Document>\n",
            "==================================================\n",
            "MuPDF error: syntax error: expected object number\n",
            "\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document source=\"http://arxiv.org/abs/2502.11228v1\" date=\"2025-02-16\" authors=\"Mohammad Reza Rezaei, Adji Bousso Dieng\"/>\n",
            "<Title>\n",
            "Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
            "for domain-specific question-answering (QA) tasks by leveraging external\n",
            "knowledge sources. However, traditional RAG systems primarily focus on\n",
            "relevance-based retrieval and often struggle with redundancy, especially when\n",
            "reasoning requires connecting information from multiple sources. This paper\n",
            "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
            "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
            "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
            "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
            "semantic diversity in document retrieval. It then uses an LLM judge that\n",
            "evaluates candidate answers, generated after a reasoning step, and outputs a\n",
            "score that the retriever uses to balance relevance and diversity among the\n",
            "retrieved documents during each iteration. Experiments on three challenging\n",
            "datasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's\n",
            "effectiveness in multi-hop reasoning tasks. The framework achieves significant\n",
            "accuracy improvements over traditional single-step and multi-step RAG\n",
            "approaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on\n",
            "2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current\n",
            "best baseline. The benefits of Vendi-RAG are even more pronounced as the number\n",
            "of retrieved documents increases. Finally, we evaluated Vendi-RAG across\n",
            "different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and\n",
            "observed consistent improvements, demonstrating that the framework's advantages\n",
            "are model-agnostic.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "Vendi-RAG: Adaptively Trading-Off Diversity And\n",
            "Quality Significantly Improves Retrieval\n",
            "Augmented Generation With LLMs\n",
            "Mohammad R. Rezaei1, 3 and Adji Bousso Dieng2, 3\n",
            "1Institute of Biomedical Engineering, University of Toronto\n",
            "2Department of Computer Science, Princeton University\n",
            "3Vertaix\n",
            "February 18, 2025\n",
            "Abstract\n",
            "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
            "for domain-specific question-answering (QA) tasks by leveraging external\n",
            "knowledge sources. However, traditional RAG systems primarily focus on\n",
            "relevance-based retrieval and often struggle with redundancy, especially when\n",
            "reasoning requires connecting information from multiple sources. This paper\n",
            "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
            "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
            "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
            "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
            "semantic diversity in document retrieval. It then uses an LLM judge that eval-\n",
            "uates candidate answers, generated after a reasoning step, and outputs a\n",
            "score that the retriever uses to balance relevance and diversity among the\n",
            "retrieved documents during each iteration. Experiments on three challenging\n",
            "datasets—HotpotQA, MuSiQue, and 2WikiMultiHopQA—demonstrate Vendi-\n",
            "RAG’s effectiveness in multi-hop reasoning tasks. The framework achieves\n",
            "significant accuracy improvements over traditional single-step and multi-step\n",
            "RAG approaches, with accuracy increases reaching up to +4.2% on HotpotQA,\n",
            "+4.1% on 2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-\n",
            "RAG, the current best baseline. The benefits of Vendi-RAG are even more\n",
            "pronounced as the number of retrieved documents increases. Finally, we eval-\n",
            "uated Vendi-RAG across different LLM backbones, including GPT-3.5, GPT-4,\n",
            "and GPT-4o-mini, and observed consistent improvements, demonstrating that\n",
            "the framework’s advantages are model-agnostic.\n",
            "Keywords: RAG, LLMs, Question Answering, NLP, Diversity, Vendi Scoring\n",
            "1\n",
            "Introduction\n",
            "Retrieval-augmented generation (RAG) has emerged as a transformative framework\n",
            "for enhancing the performance of large language models (LLMs) in domain-specific\n",
            "tasks such as question-answering (QA). By retrieving relevant information from\n",
            "external sources beyond the training set, RAG enables LLMs to answer specialized\n",
            "1\n",
            "arXiv:2502.11228v1  [cs.CL]  16 Feb 2025\n",
            "Retrieval\n",
            "Query\n",
            "Answer\n",
            "LLM Judge \n",
            "Quality Check\n",
            "Rewritten  \n",
            "Query\n",
            "Final \n",
            "Answer\n",
            "Vendi Score\n",
            "Vendi Score\n",
            "Diversity  \n",
            "weight s\n",
            "Decision Block \n",
            "s > threshold Thr \n",
            "Iteration < N\n",
            "…\n",
            "Reasoning\n",
            "Figure 1: The process begins with an initial retrieval step, where a diverse set of\n",
            "documents is retrieved using the Vendi Score, ensuring broad semantic coverage.\n",
            "Next, leveraging a reasoning step to construct a coherent path to the final answer,\n",
            "the LLM generates an answer, which then undergoes quality assessment by an LLM\n",
            "judge. Based on the answer quality, the retriever is adjusted to balance diversity and\n",
            "relevance: high-quality answers limit the emphasis on diversity, while low-quality\n",
            "answers prompt the retriever to prioritize diversity more heavily. This adjustment\n",
            "is controlled by an adaptive parameter, s, which is updated over iterations. The\n",
            "process continues until the answer quality reaches an optimal threshold, denoted\n",
            "by Thr. Finally, the highest-quality responses and documents are selected, ensuring\n",
            "both diversity and accuracy.\n",
            "queries more effectively (Achiam et al., 2023; Team et al., 2023; Jiang et al., 2024).\n",
            "This approach has been particularly successful in single-hop QA, where a question\n",
            "can be answered using information from a single document Raiaan et al. (2024);\n",
            "Kwiatkowski et al. (2019). For instance, answering a question such as \"Which\n",
            "country is filmmaker Sembene Ousmane from?\" only requires retrieving relevant\n",
            "information from a single document containing this fact.\n",
            "However, multi-hop QA introduces sign\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2401.08406v3\" date=\"2024-01-30\" authors=\"Angels Balaguer, Vinamra Benara, Renato Luiz de Freitas Cunha, Roberto de M. Estevão Filho, Todd Hendry, Daniel Holstein, Jennifer Marsman, Nick Mecklenburg, Sara Malvar, Leonardo O. Nunes, Rafael Padilha, Morris Sharp, Bruno Silva, Swati Sharma, Vijay Aski, Ranveer Chandra\"/>\n",
            "<Title>\n",
            "RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "There are two common ways in which developers are incorporating proprietary\n",
            "and domain-specific data when building applications of Large Language Models\n",
            "(LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the\n",
            "prompt with the external data, while fine-Tuning incorporates the additional\n",
            "knowledge into the model itself. However, the pros and cons of both approaches\n",
            "are not well understood. In this paper, we propose a pipeline for fine-tuning\n",
            "and RAG, and present the tradeoffs of both for multiple popular LLMs, including\n",
            "Llama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages,\n",
            "including extracting information from PDFs, generating questions and answers,\n",
            "using them for fine-tuning, and leveraging GPT-4 for evaluating the results. We\n",
            "propose metrics to assess the performance of different stages of the RAG and\n",
            "fine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset.\n",
            "Agriculture as an industry has not seen much penetration of AI, and we study a\n",
            "potentially disruptive application - what if we could provide location-specific\n",
            "insights to a farmer? Our results show the effectiveness of our dataset\n",
            "generation pipeline in capturing geographic-specific knowledge, and the\n",
            "quantitative and qualitative benefits of RAG and fine-tuning. We see an\n",
            "accuracy increase of over 6 p.p. when fine-tuning the model and this is\n",
            "cumulative with RAG, which increases accuracy by 5 p.p. further. In one\n",
            "particular experiment, we also demonstrate that the fine-tuned model leverages\n",
            "information from across geographies to answer specific questions, increasing\n",
            "answer similarity from 47% to 72%. Overall, the results point to how systems\n",
            "built using LLMs can be adapted to respond and incorporate knowledge across a\n",
            "dimension that is critical for a specific industry, paving the way for further\n",
            "applications of LLMs in other industrial domains.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE\n",
            "STUDY ON AGRICULTURE\n",
            "Microsoft\n",
            "Angels Balaguer, Vinamra Benara, Renato Cunha, Roberto Estevão, Todd Hendry, Daniel Holstein,\n",
            "Jennifer Marsman, Nick Mecklenburg, Sara Malvar, Leonardo O. Nunes, Rafael Padilha, Morris Sharp,\n",
            "Bruno Silva, Swati Sharma, Vijay Aski, Ranveer Chandra\n",
            "ABSTRACT\n",
            "There are two common ways in which developers are incorporating proprietary and domain-specific\n",
            "data when building applications of Large Language Models (LLMs): Retrieval-Augmented Genera-\n",
            "tion (RAG) and Fine-Tuning. RAG augments the prompt with the external data, while fine-Tuning\n",
            "incorporates the additional knowledge into the model itself. However, the pros and cons of both\n",
            "approaches are not well understood. In this paper, we propose a pipeline for fine-tuning and RAG, and\n",
            "present the tradeoffs of both for multiple popular LLMs, including Llama2-13B, GPT-3.5, and GPT-4.\n",
            "Our pipeline consists of multiple stages, including extracting information from PDFs, generating\n",
            "questions and answers, using them for fine-tuning, and leveraging GPT-4 for evaluating the results.\n",
            "We propose metrics to assess the performance of different stages of the RAG and fine-Tuning pipeline.\n",
            "We conduct an in-depth study on an agricultural dataset. Agriculture as an industry has not seen\n",
            "much penetration of AI, and we study a potentially disruptive application - what if we could provide\n",
            "location-specific insights to a farmer? Our results show the effectiveness of our dataset generation\n",
            "pipeline in capturing geographic-specific knowledge, and the quantitative and qualitative benefits of\n",
            "RAG and fine-tuning. We see an accuracy increase of over 6 p.p. when fine-tuning the model and this\n",
            "is cumulative with RAG, which increases accuracy by 5 p.p. further. In one particular experiment,\n",
            "we also demonstrate that the fine-tuned model leverages information from across geographies to\n",
            "answer specific questions, increasing answer similarity from 47% to 72%. Overall, the results point\n",
            "to how systems built using LLMs can be adapted to respond and incorporate knowledge across a\n",
            "dimension that is critical for a specific industry, paving the way for further applications of LLMs in\n",
            "other industrial domains.\n",
            "Keywords GPT-4 · Agriculture · Retrieval Augmented Generation · Fine-tuning\n",
            "1\n",
            "Introduction\n",
            "Over the past few years, artificial intelligence and natural language processing have seen significant advancements,\n",
            "leading to the development of powerful large language models (LLMs) such as the Generative Pre-trained Transformer\n",
            "(GPT). The technology driving LLMs, including advanced deep learning techniques, large-scale transformers, and\n",
            "vast amounts of data, have propelled their rapid evolution. Models like GPT-4 (OpenAI, 2023) and Llama 2 (Touvron\n",
            "et al., 2023b) have demonstrated exceptional performance across numerous tasks and domains, often without specific\n",
            "prompts. These models surpass their predecessors and hold immense potential in various fields like coding, medicine,\n",
            "law, agriculture, and psychology, closely approaching human-level expertise (Bubeck et al., 2023; Nori et al., 2023;\n",
            "Demszky et al., 2023). As LLM research continues, it is critical to identify their limitations and address the challenges\n",
            "of developing more comprehensive artificial general intelligence (AGI) systems. Moreover, the machine learning\n",
            "community must move beyond traditional benchmarking datasets and evaluate LLMs in ways that closely resemble\n",
            "human cognitive ability assessments.\n",
            "The adoption of Artificial Intelligence (AI) copilots across various industries is revolutionizing the way businesses\n",
            "operate and interact with their environment. These AI copilots, powered by LLMs, provide invaluable assistance in\n",
            "arXiv:2401.08406v3  [cs.CL]  30 Jan 2024\n",
            "data processing and decision-making processes. In healthcare, for example, AI copilots are being leveraged to predict\n",
            "patient risks and improve diagnostic accuracy (Kim et al., 2023; Thirunavukarasu et al., 2023; Alo\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
            "<Title>\n",
            "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
            "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
            "increasing demands of application scenarios have driven the evolution of RAG,\n",
            "leading to the integration of advanced retrievers, LLMs and other complementary\n",
            "technologies, which in turn has amplified the intricacy of RAG systems.\n",
            "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process of\n",
            "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
            "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
            "decomposing complex RAG systems into independent modules and specialized\n",
            "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a more advanced\n",
            "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
            "extensive research, this paper further identifies prevalent RAG\n",
            "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
            "analysis of their respective implementation nuances. Modular RAG presents\n",
            "innovative opportunities for the conceptualization and deployment of RAG\n",
            "systems. Finally, the paper explores the potential emergence of new operators\n",
            "and paradigms, establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment of RAG\n",
            "technologies.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "1\n",
            "Modular RAG: Transforming RAG Systems into\n",
            "LEGO-like Reconfigurable Frameworks\n",
            "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
            "Abstract—Retrieval-augmented\n",
            "Generation\n",
            "(RAG)\n",
            "has\n",
            "markedly enhanced the capabilities of Large Language Models\n",
            "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
            "demands of application scenarios have driven the evolution\n",
            "of RAG, leading to the integration of advanced retrievers,\n",
            "LLMs and other complementary technologies, which in turn\n",
            "has amplified the intricacy of RAG systems. However, the rapid\n",
            "advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process\n",
            "of “retrieve-then-generate”. In this context, this paper examines\n",
            "the limitations of the existing RAG paradigm and introduces\n",
            "the modular RAG framework. By decomposing complex RAG\n",
            "systems into independent modules and specialized operators, it\n",
            "facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a\n",
            "more advanced design that integrates routing, scheduling, and\n",
            "fusion mechanisms. Drawing on extensive research, this paper\n",
            "further identifies prevalent RAG patterns—linear, conditional,\n",
            "branching, and looping—and offers a comprehensive analysis\n",
            "of their respective implementation nuances. Modular RAG\n",
            "presents\n",
            "innovative\n",
            "opportunities\n",
            "for\n",
            "the\n",
            "conceptualization\n",
            "and deployment of RAG systems. Finally, the paper explores\n",
            "the potential emergence of new operators and paradigms,\n",
            "establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment\n",
            "of RAG technologies.\n",
            "Index Terms—Retrieval-augmented generation, large language\n",
            "model, modular system, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE Language Models (LLMs) have demonstrated\n",
            "remarkable capabilities, yet they still face numerous\n",
            "challenges, such as hallucination and the lag in information up-\n",
            "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
            "ing external knowledge bases, provides LLMs with important\n",
            "contextual information, significantly enhancing their perfor-\n",
            "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
            "an enhancement method, has been widely applied in various\n",
            "practical application scenarios, including knowledge question\n",
            "answering, recommendation systems, customer service, and\n",
            "personal assistants. [3]–[6]\n",
            "During the nascent stages of RAG , its core framework is\n",
            "constituted by indexing, retrieval, and generation, a paradigm\n",
            "referred to as Naive RAG [7]. However, as the complexity\n",
            "of tasks and the demands of applications have escalated, the\n",
            "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
            "Systems, Tongji University, Shanghai, 201210, China.\n",
            "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
            "Computer Science, Fudan University, Shanghai, 200438, China.\n",
            "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
            "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
            "Wang. E-mail: carter.whfcarter@gmail.com)\n",
            "limitations of Naive RAG have become increasingly apparent.\n",
            "As depicted in Figure 1, it predominantly hinges on the\n",
            "straightforward similarity of chunks, result in poor perfor-\n",
            "mance when confronted with complex queries and chunks with\n",
            "substantial variability. The primary challenges of Naive RAG\n",
            "include: 1) Shallow Understanding of Queries. The semantic\n",
            "similarity between a query and document chunk is not always\n",
            "highly consistent. Relying solely on similarity calculations\n",
            "for retrieval lacks an in-depth exploration of the relationship\n",
            "between the query and the document [8]. 2) Retrieval Re-\n",
            "dundancy and Noise. Feeding all retrieved chunks directly\n",
            "into LLMs is not always beneficial. Research indicates that\n",
            "an excess of redundant and noisy information may interfere\n",
            "with the LLM’s identification of key information, thereby\n",
            "increasing the risk of generating erroneous and hallucinated\n",
            "responses. [9]\n",
            "To overcome the aforementioned limitations, \n",
            "</Content>\n",
            "</Document>\n",
            "==================================================\n",
            "ArXiv search error: module 'fitz' has no attribute 'fitz'\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Error>Failed to retrieve ArXiv search results.</Error>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document href=\"https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\"/>\n",
            "Retrieval-augmented generation (RAG) has emerged as a promising solution incorporating knowledge from external databases. RAG enhances LLMs by retrieving relevant document chunks from the external knowledge base through semantic similarity calculation. The Naive RAG follows a traditional process that includes indexing, retrieval, and generation, also characterized as a “Retrieve-Read” framework. Retrieval: Upon receipt of a user query, the RAG system employs the same encoding model utilized during the indexing phase to transform the query into a vector representation. RAG enhances LLMs by retrieving relevant document chunks from the external knowledge base through semantic similarity calculation. Naive RAG has several limitations, including Retrieval Challenges and Generation Difficulties.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
            "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. Modular RAG is an advanced form of Retrieval-Augmented Generation that leverages a modular design to separate and optimize various components of the system. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. Seamless Integration: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document href=\"https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches\"/>\n",
            "Naive RAG established the groundwork for retrieval-augmented systems by combining document retrieval with language model generation. For example, in a question-answering task, RECALL ensures that a RAG system accurately incorporates all relevant points from retrieved documents into the generated answer. Vector databases play a crucial role in the operation of RAG systems, providing the infrastructure required for storing and retrieving high-dimensional embeddings of contextual information needed for LLMs. These embeddings capture the semantic and contextual meaning of unstructured data, enabling precise similarity searches that underpin the effectiveness of retrieval-augmented generation. By integrating retrieval into generation, RAG systems deliver more accurate and context-aware outputs, making them effective for applications requiring current or specialized knowledge.\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
            "<Title>\n",
            "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
            "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
            "increasing demands of application scenarios have driven the evolution of RAG,\n",
            "leading to the integration of advanced retrievers, LLMs and other complementary\n",
            "technologies, which in turn has amplified the intricacy of RAG systems.\n",
            "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process of\n",
            "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
            "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
            "decomposing complex RAG systems into independent modules and specialized\n",
            "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a more advanced\n",
            "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
            "extensive research, this paper further identifies prevalent RAG\n",
            "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
            "analysis of their respective implementation nuances. Modular RAG presents\n",
            "innovative opportunities for the conceptualization and deployment of RAG\n",
            "systems. Finally, the paper explores the potential emergence of new operators\n",
            "and paradigms, establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment of RAG\n",
            "technologies.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "1\n",
            "Modular RAG: Transforming RAG Systems into\n",
            "LEGO-like Reconfigurable Frameworks\n",
            "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
            "Abstract—Retrieval-augmented\n",
            "Generation\n",
            "(RAG)\n",
            "has\n",
            "markedly enhanced the capabilities of Large Language Models\n",
            "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
            "demands of application scenarios have driven the evolution\n",
            "of RAG, leading to the integration of advanced retrievers,\n",
            "LLMs and other complementary technologies, which in turn\n",
            "has amplified the intricacy of RAG systems. However, the rapid\n",
            "advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process\n",
            "of “retrieve-then-generate”. In this context, this paper examines\n",
            "the limitations of the existing RAG paradigm and introduces\n",
            "the modular RAG framework. By decomposing complex RAG\n",
            "systems into independent modules and specialized operators, it\n",
            "facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a\n",
            "more advanced design that integrates routing, scheduling, and\n",
            "fusion mechanisms. Drawing on extensive research, this paper\n",
            "further identifies prevalent RAG patterns—linear, conditional,\n",
            "branching, and looping—and offers a comprehensive analysis\n",
            "of their respective implementation nuances. Modular RAG\n",
            "presents\n",
            "innovative\n",
            "opportunities\n",
            "for\n",
            "the\n",
            "conceptualization\n",
            "and deployment of RAG systems. Finally, the paper explores\n",
            "the potential emergence of new operators and paradigms,\n",
            "establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment\n",
            "of RAG technologies.\n",
            "Index Terms—Retrieval-augmented generation, large language\n",
            "model, modular system, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE Language Models (LLMs) have demonstrated\n",
            "remarkable capabilities, yet they still face numerous\n",
            "challenges, such as hallucination and the lag in information up-\n",
            "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
            "ing external knowledge bases, provides LLMs with important\n",
            "contextual information, significantly enhancing their perfor-\n",
            "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
            "an enhancement method, has been widely applied in various\n",
            "practical application scenarios, including knowledge question\n",
            "answering, recommendation systems, customer service, and\n",
            "personal assistants. [3]–[6]\n",
            "During the nascent stages of RAG , its core framework is\n",
            "constituted by indexing, retrieval, and generation, a paradigm\n",
            "referred to as Naive RAG [7]. However, as the complexity\n",
            "of tasks and the demands of applications have escalated, the\n",
            "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
            "Systems, Tongji University, Shanghai, 201210, China.\n",
            "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
            "Computer Science, Fudan University, Shanghai, 200438, China.\n",
            "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
            "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
            "Wang. E-mail: carter.whfcarter@gmail.com)\n",
            "limitations of Naive RAG have become increasingly apparent.\n",
            "As depicted in Figure 1, it predominantly hinges on the\n",
            "straightforward similarity of chunks, result in poor perfor-\n",
            "mance when confronted with complex queries and chunks with\n",
            "substantial variability. The primary challenges of Naive RAG\n",
            "include: 1) Shallow Understanding of Queries. The semantic\n",
            "similarity between a query and document chunk is not always\n",
            "highly consistent. Relying solely on similarity calculations\n",
            "for retrieval lacks an in-depth exploration of the relationship\n",
            "between the query and the document [8]. 2) Retrieval Re-\n",
            "dundancy and Noise. Feeding all retrieved chunks directly\n",
            "into LLMs is not always beneficial. Research indicates that\n",
            "an excess of redundant and noisy information may interfere\n",
            "with the LLM’s identification of key information, thereby\n",
            "increasing the risk of generating erroneous and hallucinated\n",
            "responses. [9]\n",
            "To overcome the aforementioned limitations, \n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2406.00944v2\" date=\"2024-10-17\" authors=\"Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng\"/>\n",
            "<Title>\n",
            "A Theory for Token-Level Harmonization in Retrieval-Augmented Generation\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance\n",
            "large language models (LLMs). Studies show that while RAG provides valuable\n",
            "external information (benefit), it may also mislead LLMs (detriment) with noisy\n",
            "or incorrect retrieved texts. Although many existing methods attempt to\n",
            "preserve benefit and avoid detriment, they lack a theoretical explanation for\n",
            "RAG. The benefit and detriment in the next token prediction of RAG remain a\n",
            "black box that cannot be quantified or compared in an explainable manner, so\n",
            "existing methods are data-driven, need additional utility evaluators or\n",
            "post-hoc. This paper takes the first step towards providing a theory to explain\n",
            "and trade off the benefit and detriment in RAG. First, we model RAG as the\n",
            "fusion between distribution of LLMs knowledge and distribution of retrieved\n",
            "texts. Then, we formalize the trade-off between the value of external knowledge\n",
            "(benefit) and its potential risk of misleading LLMs (detriment) in next token\n",
            "prediction of RAG by distribution difference in this fusion. Finally, we prove\n",
            "that the actual effect of RAG on the token, which is the comparison between\n",
            "benefit and detriment, can be predicted without any training or accessing the\n",
            "utility of retrieval. Based on our theory, we propose a practical novel method,\n",
            "Tok-RAG, which achieves collaborative generation between the pure LLM and RAG\n",
            "at token level to preserve benefit and avoid detriment. Experiments in\n",
            "real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\n",
            "effectiveness of our method and support our theoretical findings.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "A THEORY FOR TOKEN-LEVEL HARMONIZATION IN\n",
            "RETRIEVAL-AUGMENTED GENERATION\n",
            "Shicheng Xu\n",
            "Liang Pang∗Huawei Shen\n",
            "Xueqi Cheng\n",
            "CAS Key Laboratory of AI Safety, Institute of Computing Technology, CAS\n",
            "{xushicheng21s,pangliang,shenhuawei,cxq}@ict.ac.cn\n",
            "ABSTRACT\n",
            "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance large\n",
            "language models (LLMs). Studies show that while RAG provides valuable external\n",
            "information (benefit), it may also mislead LLMs (detriment) with noisy or incorrect\n",
            "retrieved texts. Although many existing methods attempt to preserve benefit and\n",
            "avoid detriment, they lack a theoretical explanation for RAG. The benefit and\n",
            "detriment in the next token prediction of RAG remain a ’black box’ that cannot\n",
            "be quantified or compared in an explainable manner, so existing methods are data-\n",
            "driven, need additional utility evaluators or post-hoc. This paper takes the first step\n",
            "towards providing a theory to explain and trade off the benefit and detriment in\n",
            "RAG. First, we model RAG as the fusion between distribution of LLM’s knowledge\n",
            "and distribution of retrieved texts. Then, we formalize the trade-off between the\n",
            "value of external knowledge (benefit) and its potential risk of misleading LLMs\n",
            "(detriment) in next token prediction of RAG by distribution difference in this\n",
            "fusion. Finally, we prove that the actual effect of RAG on the token, which is the\n",
            "comparison between benefit and detriment, can be predicted without any training or\n",
            "accessing the utility of retrieval. Based on our theory, we propose a practical novel\n",
            "method, Tok-RAG, which achieves collaborative generation between the pure\n",
            "LLM and RAG at token level to preserve benefit and avoid detriment. Experiments\n",
            "in real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\n",
            "effectiveness of our method and support our theoretical findings.\n",
            "1\n",
            "INTRODUCTION\n",
            "Retrieval-augmented generation (RAG) has shown promising performance in enhancing Large\n",
            "Language Models (LLMs) by integrating retrieved texts (Xu et al., 2023; Shi et al., 2023; Asai et al.,\n",
            "2023; Ram et al., 2023). Studies indicate that while RAG provides LLMs with valuable additional\n",
            "knowledge (benefit), it also poses a risk of misleading them (detriment) due to noisy or incorrect\n",
            "retrieved texts (Ram et al., 2023; Xu et al., 2024b;a; Jin et al., 2024a; Xie et al., 2023; Jin et al.,\n",
            "2024b). Existing methods attempt to preserve benefit and avoid detriment by adding utility evaluators\n",
            "for retrieval, prompt engineering, or fine-tuning LLMs (Asai et al., 2023; Ding et al., 2024; Xu et al.,\n",
            "2024b; Yoran et al., 2024; Ren et al., 2023; Feng et al., 2023; Mallen et al., 2022; Jiang et al., 2023).\n",
            "However, existing methods are data-driven, need evaluator for utility of retrieved texts or post-hoc. A\n",
            "theory-based method, focusing on core principles of RAG is urgently needed, which is crucial for\n",
            "consistent and reliable improvements without relying on additional training or utility evaluators and\n",
            "improving our understanding for RAG.\n",
            "This paper takes the first step in providing a theoretical framework to explain and trade off the benefit\n",
            "and detriment at token level in RAG and proposes a novel method to preserve benefit and avoid\n",
            "detriment based on our theoretical findings. Specifically, this paper pioneers in modeling next token\n",
            "prediction in RAG as the fusion between the distribution of LLM’s knowledge and the distribution\n",
            "of retrieved texts as shown in Figure 1. Our theoretical derivation based on this formalizes the core\n",
            "of this fusion as the subtraction between two terms measured by the distribution difference: one is\n",
            "distribution completion and the other is distribution contradiction. Further analysis indicates that\n",
            "the distribution completion measures how much out-of-distribution knowledge that retrieved texts\n",
            "∗Corresponding author\n",
            "1\n",
            "arXiv:2406.00944v2  [cs.CL]  17 Oct 2024\n",
            "Query\n",
            "Wole\n",
            "Query\n",
            "Ernst\n",
            "Soyinka\n",
            "…\n",
            "LLM’s \n",
            "Distribution\n",
            "Retrieved \n",
            "Distribution \n",
            "Fusion\n",
            "Distribution\n",
            "Difference\n",
            "Olanipekun\n",
            "LLM’s \n",
            "Dis\n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2502.11228v1\" date=\"2025-02-16\" authors=\"Mohammad Reza Rezaei, Adji Bousso Dieng\"/>\n",
            "<Title>\n",
            "Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
            "for domain-specific question-answering (QA) tasks by leveraging external\n",
            "knowledge sources. However, traditional RAG systems primarily focus on\n",
            "relevance-based retrieval and often struggle with redundancy, especially when\n",
            "reasoning requires connecting information from multiple sources. This paper\n",
            "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
            "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
            "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
            "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
            "semantic diversity in document retrieval. It then uses an LLM judge that\n",
            "evaluates candidate answers, generated after a reasoning step, and outputs a\n",
            "score that the retriever uses to balance relevance and diversity among the\n",
            "retrieved documents during each iteration. Experiments on three challenging\n",
            "datasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's\n",
            "effectiveness in multi-hop reasoning tasks. The framework achieves significant\n",
            "accuracy improvements over traditional single-step and multi-step RAG\n",
            "approaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on\n",
            "2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current\n",
            "best baseline. The benefits of Vendi-RAG are even more pronounced as the number\n",
            "of retrieved documents increases. Finally, we evaluated Vendi-RAG across\n",
            "different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and\n",
            "observed consistent improvements, demonstrating that the framework's advantages\n",
            "are model-agnostic.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "Vendi-RAG: Adaptively Trading-Off Diversity And\n",
            "Quality Significantly Improves Retrieval\n",
            "Augmented Generation With LLMs\n",
            "Mohammad R. Rezaei1, 3 and Adji Bousso Dieng2, 3\n",
            "1Institute of Biomedical Engineering, University of Toronto\n",
            "2Department of Computer Science, Princeton University\n",
            "3Vertaix\n",
            "February 18, 2025\n",
            "Abstract\n",
            "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
            "for domain-specific question-answering (QA) tasks by leveraging external\n",
            "knowledge sources. However, traditional RAG systems primarily focus on\n",
            "relevance-based retrieval and often struggle with redundancy, especially when\n",
            "reasoning requires connecting information from multiple sources. This paper\n",
            "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
            "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
            "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
            "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
            "semantic diversity in document retrieval. It then uses an LLM judge that eval-\n",
            "uates candidate answers, generated after a reasoning step, and outputs a\n",
            "score that the retriever uses to balance relevance and diversity among the\n",
            "retrieved documents during each iteration. Experiments on three challenging\n",
            "datasets—HotpotQA, MuSiQue, and 2WikiMultiHopQA—demonstrate Vendi-\n",
            "RAG’s effectiveness in multi-hop reasoning tasks. The framework achieves\n",
            "significant accuracy improvements over traditional single-step and multi-step\n",
            "RAG approaches, with accuracy increases reaching up to +4.2% on HotpotQA,\n",
            "+4.1% on 2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-\n",
            "RAG, the current best baseline. The benefits of Vendi-RAG are even more\n",
            "pronounced as the number of retrieved documents increases. Finally, we eval-\n",
            "uated Vendi-RAG across different LLM backbones, including GPT-3.5, GPT-4,\n",
            "and GPT-4o-mini, and observed consistent improvements, demonstrating that\n",
            "the framework’s advantages are model-agnostic.\n",
            "Keywords: RAG, LLMs, Question Answering, NLP, Diversity, Vendi Scoring\n",
            "1\n",
            "Introduction\n",
            "Retrieval-augmented generation (RAG) has emerged as a transformative framework\n",
            "for enhancing the performance of large language models (LLMs) in domain-specific\n",
            "tasks such as question-answering (QA). By retrieving relevant information from\n",
            "external sources beyond the training set, RAG enables LLMs to answer specialized\n",
            "1\n",
            "arXiv:2502.11228v1  [cs.CL]  16 Feb 2025\n",
            "Retrieval\n",
            "Query\n",
            "Answer\n",
            "LLM Judge \n",
            "Quality Check\n",
            "Rewritten  \n",
            "Query\n",
            "Final \n",
            "Answer\n",
            "Vendi Score\n",
            "Vendi Score\n",
            "Diversity  \n",
            "weight s\n",
            "Decision Block \n",
            "s > threshold Thr \n",
            "Iteration < N\n",
            "…\n",
            "Reasoning\n",
            "Figure 1: The process begins with an initial retrieval step, where a diverse set of\n",
            "documents is retrieved using the Vendi Score, ensuring broad semantic coverage.\n",
            "Next, leveraging a reasoning step to construct a coherent path to the final answer,\n",
            "the LLM generates an answer, which then undergoes quality assessment by an LLM\n",
            "judge. Based on the answer quality, the retriever is adjusted to balance diversity and\n",
            "relevance: high-quality answers limit the emphasis on diversity, while low-quality\n",
            "answers prompt the retriever to prioritize diversity more heavily. This adjustment\n",
            "is controlled by an adaptive parameter, s, which is updated over iterations. The\n",
            "process continues until the answer quality reaches an optimal threshold, denoted\n",
            "by Thr. Finally, the highest-quality responses and documents are selected, ensuring\n",
            "both diversity and accuracy.\n",
            "queries more effectively (Achiam et al., 2023; Team et al., 2023; Jiang et al., 2024).\n",
            "This approach has been particularly successful in single-hop QA, where a question\n",
            "can be answered using information from a single document Raiaan et al. (2024);\n",
            "Kwiatkowski et al. (2019). For instance, answering a question such as \"Which\n",
            "country is filmmaker Sembene Ousmane from?\" only requires retrieving relevant\n",
            "information from a single document containing this fact.\n",
            "However, multi-hop QA introduces sign\n",
            "</Content>\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
            "<Title>\n",
            "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
            "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
            "increasing demands of application scenarios have driven the evolution of RAG,\n",
            "leading to the integration of advanced retrievers, LLMs and other complementary\n",
            "technologies, which in turn has amplified the intricacy of RAG systems.\n",
            "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process of\n",
            "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
            "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
            "decomposing complex RAG systems into independent modules and specialized\n",
            "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a more advanced\n",
            "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
            "extensive research, this paper further identifies prevalent RAG\n",
            "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
            "analysis of their respective implementation nuances. Modular RAG presents\n",
            "innovative opportunities for the conceptualization and deployment of RAG\n",
            "systems. Finally, the paper explores the potential emergence of new operators\n",
            "and paradigms, establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment of RAG\n",
            "technologies.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "1\n",
            "Modular RAG: Transforming RAG Systems into\n",
            "LEGO-like Reconfigurable Frameworks\n",
            "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
            "Abstract—Retrieval-augmented\n",
            "Generation\n",
            "(RAG)\n",
            "has\n",
            "markedly enhanced the capabilities of Large Language Models\n",
            "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
            "demands of application scenarios have driven the evolution\n",
            "of RAG, leading to the integration of advanced retrievers,\n",
            "LLMs and other complementary technologies, which in turn\n",
            "has amplified the intricacy of RAG systems. However, the rapid\n",
            "advancements are outpacing the foundational RAG paradigm,\n",
            "with many methods struggling to be unified under the process\n",
            "of “retrieve-then-generate”. In this context, this paper examines\n",
            "the limitations of the existing RAG paradigm and introduces\n",
            "the modular RAG framework. By decomposing complex RAG\n",
            "systems into independent modules and specialized operators, it\n",
            "facilitates a highly reconfigurable framework. Modular RAG\n",
            "transcends the traditional linear architecture, embracing a\n",
            "more advanced design that integrates routing, scheduling, and\n",
            "fusion mechanisms. Drawing on extensive research, this paper\n",
            "further identifies prevalent RAG patterns—linear, conditional,\n",
            "branching, and looping—and offers a comprehensive analysis\n",
            "of their respective implementation nuances. Modular RAG\n",
            "presents\n",
            "innovative\n",
            "opportunities\n",
            "for\n",
            "the\n",
            "conceptualization\n",
            "and deployment of RAG systems. Finally, the paper explores\n",
            "the potential emergence of new operators and paradigms,\n",
            "establishing a solid theoretical foundation and a practical\n",
            "roadmap for the continued evolution and practical deployment\n",
            "of RAG technologies.\n",
            "Index Terms—Retrieval-augmented generation, large language\n",
            "model, modular system, information retrieval\n",
            "I. INTRODUCTION\n",
            "L\n",
            "ARGE Language Models (LLMs) have demonstrated\n",
            "remarkable capabilities, yet they still face numerous\n",
            "challenges, such as hallucination and the lag in information up-\n",
            "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
            "ing external knowledge bases, provides LLMs with important\n",
            "contextual information, significantly enhancing their perfor-\n",
            "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
            "an enhancement method, has been widely applied in various\n",
            "practical application scenarios, including knowledge question\n",
            "answering, recommendation systems, customer service, and\n",
            "personal assistants. [3]–[6]\n",
            "During the nascent stages of RAG , its core framework is\n",
            "constituted by indexing, retrieval, and generation, a paradigm\n",
            "referred to as Naive RAG [7]. However, as the complexity\n",
            "of tasks and the demands of applications have escalated, the\n",
            "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
            "Systems, Tongji University, Shanghai, 201210, China.\n",
            "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
            "Computer Science, Fudan University, Shanghai, 200438, China.\n",
            "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
            "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
            "Wang. E-mail: carter.whfcarter@gmail.com)\n",
            "limitations of Naive RAG have become increasingly apparent.\n",
            "As depicted in Figure 1, it predominantly hinges on the\n",
            "straightforward similarity of chunks, result in poor perfor-\n",
            "mance when confronted with complex queries and chunks with\n",
            "substantial variability. The primary challenges of Naive RAG\n",
            "include: 1) Shallow Understanding of Queries. The semantic\n",
            "similarity between a query and document chunk is not always\n",
            "highly consistent. Relying solely on similarity calculations\n",
            "for retrieval lacks an in-depth exploration of the relationship\n",
            "between the query and the document [8]. 2) Retrieval Re-\n",
            "dundancy and Noise. Feeding all retrieved chunks directly\n",
            "into LLMs is not always beneficial. Research indicates that\n",
            "an excess of redundant and noisy information may interfere\n",
            "with the LLM’s identification of key information, thereby\n",
            "increasing the risk of generating erroneous and hallucinated\n",
            "responses. [9]\n",
            "To overcome the aforementioned limitations, \n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2410.09584v1\" date=\"2024-10-12\" authors=\"Guanting Dong, Xiaoshuai Song, Yutao Zhu, Runqi Qiao, Zhicheng Dou, Ji-Rong Wen\"/>\n",
            "<Title>\n",
            "Toward General Instruction-Following Alignment for Retrieval-Augmented Generation\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Following natural instructions is crucial for the effective application of\n",
            "Retrieval-Augmented Generation (RAG) systems. Despite recent advancements in\n",
            "Large Language Models (LLMs), research on assessing and improving\n",
            "instruction-following (IF) alignment within the RAG domain remains limited. To\n",
            "address this issue, we propose VIF-RAG, the first automated, scalable, and\n",
            "verifiable synthetic pipeline for instruction-following alignment in RAG\n",
            "systems. We start by manually crafting a minimal set of atomic instructions\n",
            "(<100) and developing combination rules to synthesize and verify complex\n",
            "instructions for a seed set. We then use supervised models for instruction\n",
            "rewriting while simultaneously generating code to automate the verification of\n",
            "instruction quality via a Python executor. Finally, we integrate these\n",
            "instructions with extensive RAG and general data samples, scaling up to a\n",
            "high-quality VIF-RAG-QA dataset (>100k) through automated processes. To further\n",
            "bridge the gap in instruction-following auto-evaluation for RAG systems, we\n",
            "introduce FollowRAG Benchmark, which includes approximately 3K test samples,\n",
            "covering 22 categories of general instruction constraints and four\n",
            "knowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG\n",
            "can seamlessly integrate with different RAG benchmarks. Using FollowRAG and\n",
            "eight widely-used IF and foundational abilities benchmarks for LLMs, we\n",
            "demonstrate that VIF-RAG markedly enhances LLM performance across a broad range\n",
            "of general instruction constraints while effectively leveraging its\n",
            "capabilities in RAG scenarios. Further analysis offers practical insights for\n",
            "achieving IF alignment in RAG systems. Our code and datasets are released at\n",
            "https://FollowRAG.github.io.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "Toward General Instruction-Following Alignment for Retrieval-Augmented\n",
            "Generation\n",
            "Guanting Dong1, Xiaoshuai Song2, Yutao Zhu1, Runqi Qiao2, Zhicheng Dou1*, Ji-Rong Wen1\n",
            "1Gaoling School of Artificial Intelligence, Renmin University of China.\n",
            "2School of Artificial Intelligence, Beijing University of Posts and Telecommunications\n",
            "{dongguanting,dou}@ruc.edu.cn\n",
            "Abstract\n",
            "Following natural instructions is crucial for the effective\n",
            "application of Retrieval-Augmented Generation (RAG) sys-\n",
            "tems. Despite recent advancements in Large Language Mod-\n",
            "els (LLMs), research on assessing and improving instruction-\n",
            "following (IF) alignment within the RAG domain remains\n",
            "limited. To address this issue, we propose VIF-RAG, the\n",
            "first automated, scalable, and verifiable synthetic pipeline for\n",
            "instruction-following alignment in RAG systems. We start\n",
            "by manually crafting a minimal set of atomic instructions\n",
            "(<100) and developing combination rules to synthesize and\n",
            "verify complex instructions for a seed set. We then use su-\n",
            "pervised models for instruction rewriting while simultane-\n",
            "ously generating code to automate the verification of instruc-\n",
            "tion quality via a Python executor. Finally, we integrate these\n",
            "instructions with extensive RAG and general data samples,\n",
            "scaling up to a high-quality VIF-RAG-QA dataset (>100k)\n",
            "through automated processes. To further bridge the gap in\n",
            "instruction-following auto-evaluation for RAG systems, we\n",
            "introduce FollowRAG Benchmark, which includes approx-\n",
            "imately 3K test samples, covering 22 categories of gen-\n",
            "eral instruction constraints and four knowledge-intensive QA\n",
            "datasets. Due to its robust pipeline design, FollowRAG can\n",
            "seamlessly integrate with different RAG benchmarks. Using\n",
            "FollowRAG and eight widely-used IF and foundational abil-\n",
            "ities benchmarks for LLMs, we demonstrate that VIF-RAG\n",
            "markedly enhances LLM performance across a broad range\n",
            "of general instruction constraints while effectively leveraging\n",
            "its capabilities in RAG scenarios. Further analysis offers prac-\n",
            "tical insights for achieving IF alignment in RAG systems. Our\n",
            "code and datasets are released at https://FollowRAG.github.\n",
            "io.\n",
            "1. Introduction\n",
            "The advancement of Large Language Models (LLMs) (Ope-\n",
            "nAI 2023; Yang et al. 2024) has profoundly revolution-\n",
            "ized a variety of real-world tasks expressed in natural lan-\n",
            "guage (Wei et al. 2022; Luo et al. 2023). However, they still\n",
            "suffer from hallucinations and factual inconsistencies (Bang\n",
            "et al. 2023), impacting the authenticity of generated answers.\n",
            "Retrieval-Augmented Generation (RAG) has gained recog-\n",
            "nition as a promising solution, empowering LLMs to lever-\n",
            "age reliable information from retrieved documents, thereby\n",
            "*Corresponding author\n",
            "Copyright © 2025, Association for the Advancement of Artificial\n",
            "Intelligence (www.aaai.org). All rights reserved.\n",
            "Instruction-Following Task under RAG Scenario\n",
            "Retrieval-Augmented Generation Task\n",
            "Instruction-Following Task\n",
            "Query\n",
            "Instruction\n",
            "Query\n",
            "Instruction\n",
            "Query\n",
            "LLMs\n",
            "Docs\n",
            "LLMs\n",
            "LLMs\n",
            "Docs\n",
            "Figure 1: The task format of instruction-following tasks for\n",
            "LLMs in RAG scenarios.\n",
            "returning high-quality responses (Guu et al. 2020; Lewis\n",
            "et al. 2020).\n",
            "In real-world interaction scenarios, users often deviate\n",
            "from standard templates when posing questions, instead of\n",
            "imposing diverse instructions on model outputs to meet spe-\n",
            "cific task requirements (Jiang et al. 2023b; Chung et al.\n",
            "2024). Consequently, improving instruction-following (IF)\n",
            "capabilities is foundational to the effective application of\n",
            "LLM and RAG systems. The core goal of IF is to enable\n",
            "models to adapt to the diverse intents of users, which has\n",
            "garnered widespread attention in the LLM community.\n",
            "Existing efforts on instruction-following alignment pri-\n",
            "marily focus on multi-grained evaluation (Zhou et al. 2023a;\n",
            "Jiang et al. 2024a; Wen et al. 2024) and high-quality in-\n",
            "struction data synthesis (Sun et al. 2024a; Zhao et al. 2024)\n",
            "to enhance LLMs’ natural instruction-following capabilities.\n",
            "However, in complex RAG scenarios, \n",
            "</Content>\n",
            "</Document>\n",
            "\n",
            "---\n",
            "\n",
            "<Document source=\"http://arxiv.org/abs/2501.09136v3\" date=\"2025-02-04\" authors=\"Aditi Singh, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei\"/>\n",
            "<Title>\n",
            "Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG\n",
            "</Title>\n",
            "\n",
            "<Summary>\n",
            "Large Language Models (LLMs) have revolutionized artificial intelligence (AI)\n",
            "by enabling human like text generation and natural language understanding.\n",
            "However, their reliance on static training data limits their ability to respond\n",
            "to dynamic, real time queries, resulting in outdated or inaccurate outputs.\n",
            "Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs\n",
            "by integrating real time data retrieval to provide contextually relevant and\n",
            "up-to-date responses. Despite its promise, traditional RAG systems are\n",
            "constrained by static workflows and lack the adaptability required for\n",
            "multistep reasoning and complex task management.\n",
            "  Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these\n",
            "limitations by embedding autonomous AI agents into the RAG pipeline. These\n",
            "agents leverage agentic design patterns reflection, planning, tool use, and\n",
            "multiagent collaboration to dynamically manage retrieval strategies,\n",
            "iteratively refine contextual understanding, and adapt workflows to meet\n",
            "complex task requirements. This integration enables Agentic RAG systems to\n",
            "deliver unparalleled flexibility, scalability, and context awareness across\n",
            "diverse applications.\n",
            "  This survey provides a comprehensive exploration of Agentic RAG, beginning\n",
            "with its foundational principles and the evolution of RAG paradigms. It\n",
            "presents a detailed taxonomy of Agentic RAG architectures, highlights key\n",
            "applications in industries such as healthcare, finance, and education, and\n",
            "examines practical implementation strategies. Additionally, it addresses\n",
            "challenges in scaling these systems, ensuring ethical decision making, and\n",
            "optimizing performance for real-world applications, while providing detailed\n",
            "insights into frameworks and tools for implementing Agentic RAG.\n",
            "</Summary>\n",
            "\n",
            "<Content>\n",
            "AGENTIC RETRIEVAL-AUGMENTED GENERATION: A SURVEY ON\n",
            "AGENTIC RAG\n",
            "Aditi Singh\n",
            "Department of Computer Science\n",
            "Cleveland State University\n",
            "Cleveland, OH, USA\n",
            "a.singh22@csuohio.edu\n",
            "Abul Ehtesham\n",
            "The Davey Tree Expert Company\n",
            "Kent, OH, USA\n",
            "abul.ehtesham@davey.com\n",
            "Saket Kumar\n",
            "The MathWorks Inc\n",
            "Natick, MA, USA\n",
            "saketk@mathworks.com\n",
            "Tala Talaei Khoei\n",
            "Khoury College of Computer Science\n",
            "Roux Institute at Northeastern University\n",
            "Portland, ME, USA\n",
            "t.talaeikhoei@northeastern.edu\n",
            "ABSTRACT\n",
            "Large Language Models (LLMs) have revolutionized artificial intelligence (AI) by enabling human-\n",
            "like text generation and natural language understanding. However, their reliance on static training\n",
            "data limits their ability to respond to dynamic, real-time queries, resulting in outdated or inaccurate\n",
            "outputs. Retrieval-Augmented Generation (RAG) has emerged as a solution, enhancing LLMs by\n",
            "integrating real-time data retrieval to provide contextually relevant and up-to-date responses. Despite\n",
            "its promise, traditional RAG systems are constrained by static workflows and lack the adaptability\n",
            "required for multi-step reasoning and complex task management.\n",
            "Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these limitations by embedding\n",
            "autonomous AI agents into the RAG pipeline. These agents leverage agentic design patterns reflec-\n",
            "tion, planning, tool use, and multi-agent collaboration to dynamically manage retrieval strategies,\n",
            "iteratively refine contextual understanding, and adapt workflows through clearly defined operational\n",
            "structures ranging from sequential steps to adaptive collaboration. This integration enables Agentic\n",
            "RAG systems to deliver unparalleled flexibility, scalability, and context-awareness across diverse\n",
            "applications.\n",
            "This survey provides a comprehensive exploration of Agentic RAG, beginning with its foundational\n",
            "principles and the evolution of RAG paradigms. It presents a detailed taxonomy of Agentic RAG archi-\n",
            "tectures, highlights key applications in industries such as healthcare, finance, and education, and exam-\n",
            "ines practical implementation strategies. Additionally, it addresses challenges in scaling these systems,\n",
            "ensuring ethical decision-making, and optimizing performance for real-world applications, while\n",
            "providing detailed insights into frameworks and tools for implementing Agentic RAG 1. The GitHub\n",
            "link for this survey is available at: https://github.com/asinghcsu/AgenticRAG-Survey.\n",
            "Keywords Large Language Models (LLMs) · Artificial Intelligence (AI) · Natural Language Understanding ·\n",
            "Retrieval-Augmented Generation (RAG) · Agentic RAG · Autonomous AI Agents · Reflection · Planning · Tool\n",
            "Use · Multi-Agent Collaboration · Agentic Patterns · Contextual Understanding · Dynamic Adaptability · Scalability ·\n",
            "Real-Time Data Retrieval · Taxonomy of Agentic RAG · Healthcare Applications · Finance Applications · Educational\n",
            "Applications · Ethical AI Decision-Making · Performance Optimization · Multi-Step Reasoning\n",
            "1GitHub link: https://github.com/asinghcsu/AgenticRAG-Survey\n",
            "arXiv:2501.09136v3  [cs.AI]  4 Feb 2025\n",
            "1\n",
            "Introduction\n",
            "Large Language Models (LLMs) [1, 2] [3], such as OpenAI’s GPT-4, Google’s PaLM, and Meta’s LLaMA, have signifi-\n",
            "cantly transformed artificial intelligence (AI) with their ability to generate human-like text and perform complex natural\n",
            "language processing tasks. These models have driven innovation across diverse domains, including conversational\n",
            "agents [4], automated content creation, and real-time translation. Recent advancements have extended their capabilities\n",
            "to multimodal tasks, such as text-to-image and text-to-video generation [5], enabling the creation and editing of videos\n",
            "and images from detailed prompts [6], which broadens the potential applications of generative AI.\n",
            "Despite these advancements, LLMs face significant limitations due to their reliance on static pre-training data. This\n",
            "reliance often results in outdated information, hallucinated responses [7], and an inability to adapt to dynamic, re\n",
            "</Content>\n",
            "</Document>\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36manswer_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: expert\n",
            "\n",
            "Certainly, Prof. Hinton. Here's a detailed comparison:\n",
            "\n",
            "**Differences between Modular RAG and Naive RAG:**\n",
            "\n",
            "1. **Architecture:**\n",
            "   - **Naive RAG:** Operates on a straightforward \"retrieve-then-generate\" principle. It combines document retrieval with language model generation in a relatively static manner, which may lead to inefficiencies and suboptimal integration with the generative model [5].\n",
            "   - **Modular RAG:** Utilizes a modular design, breaking down the retrieval and generation processes into distinct, interchangeable modules. This allows for a more flexible and reconfigurable framework, facilitating the integration of advanced retrievers, LLMs, and other technologies [4][6].\n",
            "\n",
            "2. **Flexibility:**\n",
            "   - **Naive RAG:** Has a monolithic structure that lacks flexibility, often resulting in retrieval redundancy and noise [4].\n",
            "   - **Modular RAG:** Features independent modules and specialized operators, enhancing flexibility. It supports advanced designs integrating routing, scheduling, and fusion mechanisms [4].\n",
            "\n",
            "**Benefits of using Modular RAG at the production level:**\n",
            "\n",
            "1. **Enhanced Performance:**\n",
            "   - Modular RAG's design allows for the optimization of various components, improving the coherence and relevance of generated responses. This results in more accurate and context-aware outputs, which is crucial for applications requiring current or specialized knowledge [5][6].\n",
            "\n",
            "2. **Scalability and Reconfigurability:**\n",
            "   - By decomposing complex systems into modules, Modular RAG makes it easier to scale and reconfigure the system as needed, adapting to new requirements or integrating new technologies without overhauling the entire system [4].\n",
            "\n",
            "3. **Reduced Redundancy and Noise:**\n",
            "   - The modular approach allows for better management of retrieval processes, reducing the introduction of redundant or noisy data into the generative model, which can interfere with key information identification [4].\n",
            "\n",
            "4. **Innovative Opportunities:**\n",
            "   - Modular RAG opens up possibilities for new operators and paradigms, setting a solid theoretical foundation and practical roadmap for the continued evolution and deployment of RAG technologies [4].\n",
            "\n",
            "In summary, Modular RAG offers a more dynamic and efficient framework compared to Naive RAG, making it well-suited for production environments where adaptability and precision are paramount.\n",
            "\n",
            "**Sources:**\n",
            "[4] Document by Yunfan Gao et al., \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\"\n",
            "[5] TechSling article on the differences between Modular and Advanced RAG\n",
            "[6] Zilliz blog on advancing LLMs with Modular and Advanced RAG approaches\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36manswer_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: expert\n",
            "\n",
            "Certainly, Dr. Chen. The key differences between Modular RAG and Naive RAG primarily lie in their architectural designs and the flexibility that Modular RAG introduces.\n",
            "\n",
            "1. **Architectural Design**: \n",
            "   - **Naive RAG** operates on a monolithic framework where the retrieval and generation processes are tightly coupled. It typically follows a \"Retrieve-Read\" framework where the same encoding model is used for both indexing and retrieval, leading to a lack of flexibility and potential inefficiencies in how retrieval processes interface with the generative model [3].\n",
            "   - **Modular RAG**, on the other hand, employs a modular design, separating the retrieval and generation components into distinct, interchangeable modules. This separation allows for optimization of each component individually and facilitates seamless integration between various retrieval modules and the generative models [1].\n",
            "\n",
            "2. **Benefits in Production**:\n",
            "   - **Flexibility and Adaptability**: The modular structure of Modular RAG allows developers to swap or update individual components without disrupting the entire system. This adaptability is particularly beneficial in production environments where frequent updates or domain-specific tuning might be necessary to maintain performance and relevance [1].\n",
            "   - **Improved Integration**: With Modular RAG, generative models can integrate more effectively with different retrieval modules. This results in enhanced coherence and relevance of the generated responses as the system can better align the retrieval output with the generative input [1].\n",
            "   - **Dynamic Embeddings**: Advanced RAG models, including Modular RAG, utilize dynamic embedding techniques that enable adaptive adjustment of embeddings during inference. This capability allows for better capture of task-specific semantics or domain knowledge, which improves the quality of both retrieved information and generated responses [2].\n",
            "\n",
            "These architectural enhancements make Modular RAG more suited for dynamic and complex production environments where flexibility, maintainability, and high performance are critical.\n",
            "\n",
            "Sources:\n",
            "[1] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
            "[2] https://www.superteams.ai/blog/how-to-implement-naive-rag-advanced-rag-and-modular-rag\n",
            "[3] https://www.marktechpost.com/2024/04/01/evolution-of-rags-naive-rag-advanced-rag-and-modular-rag-architectures/\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Thank you so much for your help, Prof. Hinton!\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Thank you, Dr. Chen, for the detailed explanation. Could you provide a specific example or case study where Modular RAG has been successfully implemented in a production environment, highlighting its advantages over Naive RAG?\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Resume graph execution\n",
        "invoke_graph(graph, None, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f589f94",
      "metadata": {},
      "source": [
        "Here's how to display the final research report: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "f076b709",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Modular RAG: A Paradigm Shift in AI System Design\n",
              "\n",
              "## Introduction\n",
              "\n",
              "In an era where the demand for scalable, efficient, and adaptable artificial intelligence (AI) systems continues to rise, Modular Retrieval-Augmented Generation (RAG) systems are emerging as a transformative solution. The landscape of AI, particularly with the evolution of large language models (LLMs), is rapidly advancing, necessitating novel approaches to overcome the limitations of traditional systems. This report delves into the significant advancements brought by Modular RAG, contrasting it with Naive RAG systems and exploring its benefits at the production level.\n",
              "\n",
              "We begin by examining the foundational role of Naive RAG systems, which integrate document retrieval with language generation but often falter due to their inflexibility and inefficiency in handling diverse datasets. Advanced RAG techniques address these challenges by leveraging dynamic embeddings and vector databases, enhancing semantic understanding and retrieval accuracy.\n",
              "\n",
              "The heart of our analysis lies in the introduction of Modular RAG frameworks, which decompose complex RAG systems into independent modules. This modularity allows for reconfigurable designs, improving scalability and facilitating the integration of advanced technologies such as routing and scheduling mechanisms. We also explore the FlashRAG toolkit, a modular resource that standardizes RAG research, and the integration of graph-based systems to enhance knowledge-based tasks.\n",
              "\n",
              "Lastly, we discuss the practical implications and challenges of deploying Modular RAG at scale, highlighting its potential to revolutionize AI applications across various domains. Through this exploration, we aim to illustrate how Modular RAG aligns with the vision of sustainable and adaptable AI systems, paving the way for future innovations.\n",
              "\n",
              "---\n",
              "\n",
              "## Main Idea\n",
              "\n",
              "\n",
              "\n",
              "### Background\n",
              "\n",
              "The emergence of Retrieval-Augmented Generation (RAG) systems has significantly influenced the development of AI, particularly in enhancing the capabilities of large language models (LLMs) for handling complex, knowledge-intensive tasks. Initially, RAG systems were exemplified by Naive RAG, which combined document retrieval with language generation to provide contextually relevant responses. However, these systems often struggled with dynamic datasets and specific semantic requirements, leading to inefficiencies and challenges in scalability [1][2]. The evolution of RAG into Modular RAG represents a groundbreaking shift, introducing a framework that decomposes RAG systems into flexible and independent modules. This modularity is key to enhancing scalability and adaptability, aligning with the vision of sustainable AI systems that can efficiently evolve in production environments [3][4]. The development of toolkits like FlashRAG further supports this evolution by offering a standardized platform for implementing and comparing RAG methods, thereby facilitating research and practical deployment [5].\n",
              "\n",
              "### Related Work\n",
              "\n",
              "Prior studies laid the groundwork for RAG systems, with Naive RAG establishing the foundational integration of retrieval and generation. These early models demonstrated the potential of AI systems to draw on external information sources, yet they faced notable limitations, including inflexibility and inefficiency in processing diverse datasets [1]. Advanced RAG models addressed some of these challenges by employing dynamic embedding techniques and vector databases, which improved the semantic understanding and adaptability of the systems [2]. The introduction of graph-based RAG systems further enhanced these capabilities by leveraging graph structures for more accurate information retrieval and generation [5]. The transition to Modular RAG builds on these advancements by offering a reconfigurable framework that supports various RAG patterns, such as linear, conditional, branching, and looping, each with its specific implementation nuances [4].\n",
              "\n",
              "### Problem Definition\n",
              "\n",
              "The primary challenge addressed by this research is the limitations of traditional Naive RAG systems in adapting to diverse and dynamic datasets. Specifically, these systems struggle with inflexibility, inefficiency, and a lack of semantic relevance, which impact their scalability and effectiveness in real-world applications [1][2][3]. The research aims to explore how Modular RAG can overcome these limitations by providing a flexible and scalable architecture that supports the evolving demands of AI systems. This involves developing modular frameworks that decompose complex RAG systems into independent modules, allowing for more efficient design and maintenance [4][5]. Additionally, the research seeks to address practical challenges related to data management and integration, ensuring that Modular RAG systems can be effectively deployed at the production level [6][7].\n",
              "\n",
              "### Methodology\n",
              "\n",
              "Modular RAG systems are designed by breaking down traditional RAG processes into independent modules and specialized operators, facilitating greater flexibility and adaptability. This approach enables the integration of advanced design features such as routing, scheduling, and fusion mechanisms, which are crucial for handling complex application scenarios [3][4]. The methodology involves implementing various RAG patterns—linear, conditional, branching, and looping—each with its specific nuances, allowing for tailored solutions to specific task requirements [4][5]. The comprehensive framework provided by toolkits like FlashRAG supports the reproduction of existing RAG methods and the development of new algorithms, ensuring consistency and facilitating comparative studies among researchers [5]. Additionally, theoretical frameworks are explored to understand the trade-offs between the benefits and detriments of retrieved texts, offering a structured approach to optimizing RAG performance [4].\n",
              "\n",
              "### Implementation Details\n",
              "\n",
              "The practical implementation of Modular RAG involves utilizing software frameworks and computational resources that support modular architecture. FlashRAG, a modular toolkit, provides a standardized platform for implementing and comparing RAG methods, offering a customizable environment for researchers to develop and test RAG algorithms [5]. The toolkit includes 12 advanced RAG methods and 32 benchmark datasets, enabling researchers to optimize their RAG processes and ensuring consistency in evaluations [3][5]. Additionally, the use of vector databases and dynamic embedding techniques enhances the retrieval and generation processes, making them more context-aware and accurate [2]. The modular architecture also supports end-to-end training across its components, marking a significant advancement over traditional RAG systems [3].\n",
              "\n",
              "### Experiments\n",
              "\n",
              "Experimental protocols for Modular RAG systems involve evaluating their performance across various application scenarios and datasets. The use of comprehensive toolkits like FlashRAG facilitates the implementation of standardized evaluation metrics and procedures, ensuring consistency in testing and comparison [5]. Experiments focus on assessing the scalability, adaptability, and efficiency of Modular RAG systems, particularly in handling diverse and dynamic datasets. Evaluation metrics include measures of retrieval accuracy, response coherence, and system scalability. Additionally, experiments explore the integration of fair ranking mechanisms to ensure equitable exposure of relevant items, thereby promoting fairness and reducing potential biases in RAG systems [3]. Theoretical studies further support experimental findings by modeling the trade-offs between the benefits and detriments of retrieved texts, offering insights into optimizing RAG performance [4].\n",
              "\n",
              "### Results\n",
              "\n",
              "The results of implementing Modular RAG systems demonstrate significant improvements in flexibility, scalability, and efficiency compared to traditional Naive RAG models. Modular RAG's reconfigurable design allows for seamless integration and optimization of independent modules, resulting in enhanced adaptability to diverse application scenarios [4][5]. The use of dynamic embeddings and vector databases further improves retrieval accuracy and context-awareness, making Modular RAG systems more effective for knowledge-intensive applications [2]. The incorporation of graph-based approaches enhances real-time data integration and contextual understanding, addressing limitations related to static knowledge bases [5]. Moreover, the integration of fair ranking mechanisms ensures equitable exposure of relevant items, promoting fairness and reducing biases [3]. Overall, Modular RAG presents a compelling evolution in AI system design, offering a more adaptable and efficient framework for deploying AI solutions at scale.\n",
              "\n",
              "### Sources\n",
              "\n",
              "[1] https://www.superteams.ai/blog/how-to-implement-naive-rag-advanced-rag-and-modular-rag  \n",
              "[2] https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches  \n",
              "[3] http://arxiv.org/abs/2407.21059v1  \n",
              "[4] http://arxiv.org/abs/2406.00944v2  \n",
              "[5] http://arxiv.org/abs/2405.13576v1  \n",
              "[6] https://medium.com/aingineer/a-comprehensive-guide-to-implementing-modular-rag-for-scalable-ai-systems-3fb47c46dc8e  \n",
              "[7] https://medium.com/@sahin.samia/modular-rag-using-llms-what-is-it-and-how-does-it-work-d482ebb3d372\n",
              "\n",
              "---\n",
              "\n",
              "## Conclusion\n",
              "\n",
              "The evolution from Naive to Modular Retrieval-Augmented Generation (RAG) systems represents a significant leap forward in the scalability and adaptability of artificial intelligence. Naive RAG laid the initial groundwork by integrating document retrieval with language generation, but its limitations in handling dynamic datasets and inflexibility necessitated advancements. Advanced RAG techniques addressed these issues by employing dynamic embeddings and vector databases, enhancing semantic understanding and adaptability.\n",
              "\n",
              "Modular RAG frameworks mark a transformative advancement by decomposing complex systems into independent modules, allowing for a reconfigurable and scalable architecture. This modularity not only supports diverse RAG patterns, such as linear, conditional, branching, and looping, but also facilitates the integration of advanced technologies like routing and scheduling mechanisms. Toolkits like FlashRAG further standardize RAG research, offering a comprehensive environment for algorithm development and comparison.\n",
              "\n",
              "Graph-based RAG systems and theoretical insights into benefit-detriment trade-offs provide additional layers of sophistication, improving real-time data integration and contextual understanding. However, challenges persist, particularly in data management and ensuring fair ranking.\n",
              "\n",
              "Overall, Modular RAG aligns with the vision of creating sustainable and adaptable AI systems, promising significant benefits in production environments. Continued research and innovation in this field are essential to fully realizing its potential and overcoming existing challenges."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "# Get final graph state\n",
        "final_state = graph.get_state(config)\n",
        "\n",
        "# Retrieve final report\n",
        "report = final_state.values.get(\"final_report\")\n",
        "\n",
        "# Display report in markdown format\n",
        "display(Markdown(report))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "d81f0bfe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Modular RAG: A Paradigm Shift in AI System Design\n",
            "\n",
            "## Introduction\n",
            "\n",
            "In an era where the demand for scalable, efficient, and adaptable artificial intelligence (AI) systems continues to rise, Modular Retrieval-Augmented Generation (RAG) systems are emerging as a transformative solution. The landscape of AI, particularly with the evolution of large language models (LLMs), is rapidly advancing, necessitating novel approaches to overcome the limitations of traditional systems. This report delves into the significant advancements brought by Modular RAG, contrasting it with Naive RAG systems and exploring its benefits at the production level.\n",
            "\n",
            "We begin by examining the foundational role of Naive RAG systems, which integrate document retrieval with language generation but often falter due to their inflexibility and inefficiency in handling diverse datasets. Advanced RAG techniques address these challenges by leveraging dynamic embeddings and vector databases, enhancing semantic understanding and retrieval accuracy.\n",
            "\n",
            "The heart of our analysis lies in the introduction of Modular RAG frameworks, which decompose complex RAG systems into independent modules. This modularity allows for reconfigurable designs, improving scalability and facilitating the integration of advanced technologies such as routing and scheduling mechanisms. We also explore the FlashRAG toolkit, a modular resource that standardizes RAG research, and the integration of graph-based systems to enhance knowledge-based tasks.\n",
            "\n",
            "Lastly, we discuss the practical implications and challenges of deploying Modular RAG at scale, highlighting its potential to revolutionize AI applications across various domains. Through this exploration, we aim to illustrate how Modular RAG aligns with the vision of sustainable and adaptable AI systems, paving the way for future innovations.\n",
            "\n",
            "---\n",
            "\n",
            "## Main Idea\n",
            "\n",
            "\n",
            "\n",
            "### Background\n",
            "\n",
            "The emergence of Retrieval-Augmented Generation (RAG) systems has significantly influenced the development of AI, particularly in enhancing the capabilities of large language models (LLMs) for handling complex, knowledge-intensive tasks. Initially, RAG systems were exemplified by Naive RAG, which combined document retrieval with language generation to provide contextually relevant responses. However, these systems often struggled with dynamic datasets and specific semantic requirements, leading to inefficiencies and challenges in scalability [1][2]. The evolution of RAG into Modular RAG represents a groundbreaking shift, introducing a framework that decomposes RAG systems into flexible and independent modules. This modularity is key to enhancing scalability and adaptability, aligning with the vision of sustainable AI systems that can efficiently evolve in production environments [3][4]. The development of toolkits like FlashRAG further supports this evolution by offering a standardized platform for implementing and comparing RAG methods, thereby facilitating research and practical deployment [5].\n",
            "\n",
            "### Related Work\n",
            "\n",
            "Prior studies laid the groundwork for RAG systems, with Naive RAG establishing the foundational integration of retrieval and generation. These early models demonstrated the potential of AI systems to draw on external information sources, yet they faced notable limitations, including inflexibility and inefficiency in processing diverse datasets [1]. Advanced RAG models addressed some of these challenges by employing dynamic embedding techniques and vector databases, which improved the semantic understanding and adaptability of the systems [2]. The introduction of graph-based RAG systems further enhanced these capabilities by leveraging graph structures for more accurate information retrieval and generation [5]. The transition to Modular RAG builds on these advancements by offering a reconfigurable framework that supports various RAG patterns, such as linear, conditional, branching, and looping, each with its specific implementation nuances [4].\n",
            "\n",
            "### Problem Definition\n",
            "\n",
            "The primary challenge addressed by this research is the limitations of traditional Naive RAG systems in adapting to diverse and dynamic datasets. Specifically, these systems struggle with inflexibility, inefficiency, and a lack of semantic relevance, which impact their scalability and effectiveness in real-world applications [1][2][3]. The research aims to explore how Modular RAG can overcome these limitations by providing a flexible and scalable architecture that supports the evolving demands of AI systems. This involves developing modular frameworks that decompose complex RAG systems into independent modules, allowing for more efficient design and maintenance [4][5]. Additionally, the research seeks to address practical challenges related to data management and integration, ensuring that Modular RAG systems can be effectively deployed at the production level [6][7].\n",
            "\n",
            "### Methodology\n",
            "\n",
            "Modular RAG systems are designed by breaking down traditional RAG processes into independent modules and specialized operators, facilitating greater flexibility and adaptability. This approach enables the integration of advanced design features such as routing, scheduling, and fusion mechanisms, which are crucial for handling complex application scenarios [3][4]. The methodology involves implementing various RAG patterns—linear, conditional, branching, and looping—each with its specific nuances, allowing for tailored solutions to specific task requirements [4][5]. The comprehensive framework provided by toolkits like FlashRAG supports the reproduction of existing RAG methods and the development of new algorithms, ensuring consistency and facilitating comparative studies among researchers [5]. Additionally, theoretical frameworks are explored to understand the trade-offs between the benefits and detriments of retrieved texts, offering a structured approach to optimizing RAG performance [4].\n",
            "\n",
            "### Implementation Details\n",
            "\n",
            "The practical implementation of Modular RAG involves utilizing software frameworks and computational resources that support modular architecture. FlashRAG, a modular toolkit, provides a standardized platform for implementing and comparing RAG methods, offering a customizable environment for researchers to develop and test RAG algorithms [5]. The toolkit includes 12 advanced RAG methods and 32 benchmark datasets, enabling researchers to optimize their RAG processes and ensuring consistency in evaluations [3][5]. Additionally, the use of vector databases and dynamic embedding techniques enhances the retrieval and generation processes, making them more context-aware and accurate [2]. The modular architecture also supports end-to-end training across its components, marking a significant advancement over traditional RAG systems [3].\n",
            "\n",
            "### Experiments\n",
            "\n",
            "Experimental protocols for Modular RAG systems involve evaluating their performance across various application scenarios and datasets. The use of comprehensive toolkits like FlashRAG facilitates the implementation of standardized evaluation metrics and procedures, ensuring consistency in testing and comparison [5]. Experiments focus on assessing the scalability, adaptability, and efficiency of Modular RAG systems, particularly in handling diverse and dynamic datasets. Evaluation metrics include measures of retrieval accuracy, response coherence, and system scalability. Additionally, experiments explore the integration of fair ranking mechanisms to ensure equitable exposure of relevant items, thereby promoting fairness and reducing potential biases in RAG systems [3]. Theoretical studies further support experimental findings by modeling the trade-offs between the benefits and detriments of retrieved texts, offering insights into optimizing RAG performance [4].\n",
            "\n",
            "### Results\n",
            "\n",
            "The results of implementing Modular RAG systems demonstrate significant improvements in flexibility, scalability, and efficiency compared to traditional Naive RAG models. Modular RAG's reconfigurable design allows for seamless integration and optimization of independent modules, resulting in enhanced adaptability to diverse application scenarios [4][5]. The use of dynamic embeddings and vector databases further improves retrieval accuracy and context-awareness, making Modular RAG systems more effective for knowledge-intensive applications [2]. The incorporation of graph-based approaches enhances real-time data integration and contextual understanding, addressing limitations related to static knowledge bases [5]. Moreover, the integration of fair ranking mechanisms ensures equitable exposure of relevant items, promoting fairness and reducing biases [3]. Overall, Modular RAG presents a compelling evolution in AI system design, offering a more adaptable and efficient framework for deploying AI solutions at scale.\n",
            "\n",
            "### Sources\n",
            "\n",
            "[1] https://www.superteams.ai/blog/how-to-implement-naive-rag-advanced-rag-and-modular-rag  \n",
            "[2] https://zilliz.com/blog/advancing-llms-native-advanced-modular-rag-approaches  \n",
            "[3] http://arxiv.org/abs/2407.21059v1  \n",
            "[4] http://arxiv.org/abs/2406.00944v2  \n",
            "[5] http://arxiv.org/abs/2405.13576v1  \n",
            "[6] https://medium.com/aingineer/a-comprehensive-guide-to-implementing-modular-rag-for-scalable-ai-systems-3fb47c46dc8e  \n",
            "[7] https://medium.com/@sahin.samia/modular-rag-using-llms-what-is-it-and-how-does-it-work-d482ebb3d372\n",
            "\n",
            "---\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "The evolution from Naive to Modular Retrieval-Augmented Generation (RAG) systems represents a significant leap forward in the scalability and adaptability of artificial intelligence. Naive RAG laid the initial groundwork by integrating document retrieval with language generation, but its limitations in handling dynamic datasets and inflexibility necessitated advancements. Advanced RAG techniques addressed these issues by employing dynamic embeddings and vector databases, enhancing semantic understanding and adaptability.\n",
            "\n",
            "Modular RAG frameworks mark a transformative advancement by decomposing complex systems into independent modules, allowing for a reconfigurable and scalable architecture. This modularity not only supports diverse RAG patterns, such as linear, conditional, branching, and looping, but also facilitates the integration of advanced technologies like routing and scheduling mechanisms. Toolkits like FlashRAG further standardize RAG research, offering a comprehensive environment for algorithm development and comparison.\n",
            "\n",
            "Graph-based RAG systems and theoretical insights into benefit-detriment trade-offs provide additional layers of sophistication, improving real-time data integration and contextual understanding. However, challenges persist, particularly in data management and ensuring fair ranking.\n",
            "\n",
            "Overall, Modular RAG aligns with the vision of creating sustainable and adaptable AI systems, promising significant benefits in production environments. Continued research and innovation in this field are essential to fully realizing its potential and overcoming existing challenges.\n"
          ]
        }
      ],
      "source": [
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54884a88",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
